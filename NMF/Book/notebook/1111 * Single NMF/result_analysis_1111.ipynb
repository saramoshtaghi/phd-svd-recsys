{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# make_all_genres_explanations_and_figs_1111_NMF.py\n",
    "#\n",
    "# NMF concept (single-genre mode, no pairs):\n",
    "#  • ORIGINAL Top-K comes from SVD 1020 baseline files (ORIGINAL_{K}recommendation.csv)\n",
    "#  • Injection Top-K comes from NMF 1111 results (f_*_..._{K}recommendation.csv)\n",
    "#  • Computes per-dataset metrics + per-book rankings within each target genre\n",
    "#  • Saves:\n",
    "#      <OUT_BASE>/<GEN_KEY>_explanation/explanation.txt\n",
    "#      <OUT_BASE>/<GEN_KEY>_explanation/per_book_ranking.csv\n",
    "#      <OUT_BASE>/<GEN_KEY>_explanation/<gen_slug>__pos5.png\n",
    "#  • Global rollups under <OUT_BASE>/_all_genres/\n",
    "#\n",
    "# Python 3.8+\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Tuple, List\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ========= CONFIG (paths set to your request) =================================\n",
    "# ORIGINAL (baseline) Top-K — from SVD 10/20 path\n",
    "ORIG_DIR = Path(\n",
    "    \"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1020 * SVD AND/SVD_pair\"\n",
    ")\n",
    "\n",
    "# NMF injection Top-K search root (single-genre, pos5) — 11/11 path\n",
    "SEARCH_ROOT = Path(\n",
    "    \"/home/moshtasa/Research/phd-svd-recsys/NMF/Book/result/rec/top_re/1111 * NMF Single/result/5\"\n",
    ")\n",
    "\n",
    "# Output base (write explanations/figures beside NMF results)\n",
    "OUT_BASE = Path(\n",
    "    \"/home/moshtasa/Research/phd-svd-recsys/NMF/Book/result/rec/top_re/1111 * NMF Single/analysis/5\"\n",
    ")\n",
    "\n",
    "OUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Which Top-K files to consume\n",
    "K_LIST = [15, 25, 35]\n",
    "\n",
    "# Candidate synthetic user sizes (used for listing & figure legend order).\n",
    "# Files not present are skipped safely.\n",
    "N_LIST = [2, 4, 6, 25, 50, 100, 200, 300, 350, 500, 1000]\n",
    "\n",
    "# Injection filename patterns (keep broad to catch neg1/neg0/etc)\n",
    "# We’ll rglob these under SEARCH_ROOT.\n",
    "INJECTION_PATTERNS = [\n",
    "    \"f_*_{n}u_pos5_*_{k}recommendation.csv\",\n",
    "]\n",
    "\n",
    "# ========= Genre normalization ===============================================\n",
    "CANONICAL_GENRES = [\n",
    "    \"Adventure\", \"Classics\", \"Drama\", \"Fantasy\", \"Historical\", \"Horror\",\n",
    "    \"Mystery\", \"Nonfiction\", \"Romance\", \"Science Fiction\", \"Thriller\",\n",
    "    \"Children's\", \"Adult\",\n",
    "]\n",
    "\n",
    "GENRE_NORM: Dict[str, str] = {\n",
    "    # canonical (lowercased)\n",
    "    \"adventure\": \"adventure\",\n",
    "    \"classics\": \"classics\",\n",
    "    \"drama\": \"drama\",\n",
    "    \"fantasy\": \"fantasy\",\n",
    "    \"historical\": \"historical\",\n",
    "    \"horror\": \"horror\",\n",
    "    \"mystery\": \"mystery\",\n",
    "    \"nonfiction\": \"nonfiction\",\n",
    "    \"romance\": \"romance\",\n",
    "    \"science fiction\": \"science fiction\",\n",
    "    \"thriller\": \"thriller\",\n",
    "    \"children's\": \"children's\",\n",
    "    \"adult\": \"adult\",\n",
    "    # filename/typo guards\n",
    "    \"children_s\": \"children's\",\n",
    "    \"childrens\": \"children's\",\n",
    "    \"children’s\": \"children's\",\n",
    "    \"children\": \"children's\",\n",
    "    \"sci-fi\": \"science fiction\",\n",
    "    \"scifi\": \"science fiction\",\n",
    "    \"science_finction\": \"science fiction\",\n",
    "    \"adventre\": \"adventure\",\n",
    "    \"advenbture\": \"adventure\",\n",
    "}\n",
    "\n",
    "DISPLAY_MAP = {\n",
    "    \"adventure\": \"Adventure\",\n",
    "    \"classics\": \"Classics\",\n",
    "    \"drama\": \"Drama\",\n",
    "    \"fantasy\": \"Fantasy\",\n",
    "    \"historical\": \"Historical\",\n",
    "    \"horror\": \"Horror\",\n",
    "    \"mystery\": \"Mystery\",\n",
    "    \"nonfiction\": \"Nonfiction\",\n",
    "    \"romance\": \"Romance\",\n",
    "    \"science fiction\": \"Science Fiction\",\n",
    "    \"thriller\": \"Thriller\",\n",
    "    \"children's\": \"Children's\",\n",
    "    \"adult\": \"Adult\",\n",
    "}\n",
    "\n",
    "def _clean_space_lower(s: str) -> str:\n",
    "    s = re.sub(r\"\\s+\", \" \", str(s).strip())\n",
    "    return s.lower()\n",
    "\n",
    "def norm_token(s: str) -> str:\n",
    "    low = _clean_space_lower(s)\n",
    "    return GENRE_NORM.get(low, low)\n",
    "\n",
    "def display_canonical(s: str) -> str:\n",
    "    low = norm_token(s)\n",
    "    return DISPLAY_MAP.get(low, s)\n",
    "\n",
    "def slugify_token(x: str) -> str:\n",
    "    x = re.sub(r\"[^A-Za-z0-9]+\", \"_\", str(x)).strip(\"_\").lower()\n",
    "    return re.sub(r\"_+\", \"_\", x)\n",
    "\n",
    "# ========= IO helpers ========================================================\n",
    "def load_rec_csv(fp: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(fp, low_memory=False)\n",
    "    # harmonize columns for safety\n",
    "    if \"genres_all\" not in df.columns:\n",
    "        df[\"genres_all\"] = \"\"\n",
    "    for c in [\"user_id\", \"book_id\", \"rank\", \"est_score\", \"original_title\"]:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "    return df\n",
    "\n",
    "def has_genre(cell, target_canon_lc: str) -> bool:\n",
    "    if pd.isna(cell):\n",
    "        return False\n",
    "    tokens = []\n",
    "    for t in str(cell).split(\",\"):\n",
    "        t = t.strip()\n",
    "        if not t:\n",
    "            continue\n",
    "        tokens.append(norm_token(t))\n",
    "    return target_canon_lc in tokens\n",
    "\n",
    "def metrics_for_file(df: pd.DataFrame, target_disp: str):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      unique_books_in_file,\n",
    "      avg_per_user (of target-genre books),\n",
    "      unique_target_books,\n",
    "      freq (total target-genre rows),\n",
    "      users_with_target,\n",
    "      is_target_mask\n",
    "    \"\"\"\n",
    "    unique_books_in_file = df[\"book_id\"].nunique() if \"book_id\" in df.columns else 0\n",
    "    target_canon = norm_token(target_disp)\n",
    "    is_tg = df[\"genres_all\"].apply(lambda s: has_genre(s, target_canon))\n",
    "\n",
    "    if \"user_id\" in df.columns:\n",
    "        per_user = df.assign(is_tg=is_tg).groupby(\"user_id\")[\"is_tg\"].sum()\n",
    "        avg_per_user = float(per_user.mean()) if not per_user.empty else 0.0\n",
    "        users_with_target = int((per_user > 0).sum())\n",
    "    else:\n",
    "        avg_per_user = 0.0\n",
    "        users_with_target = 0\n",
    "\n",
    "    unique_tg_books = df.loc[is_tg, \"book_id\"].nunique() if \"book_id\" in df.columns else 0\n",
    "    freq = int(is_tg.sum())\n",
    "    return unique_books_in_file, avg_per_user, unique_tg_books, freq, users_with_target, is_tg\n",
    "\n",
    "def per_book_ranking(df_target_rows: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build per-book table from rows already filtered to target genre:\n",
    "      rank by freq desc, rank1_count desc, avg_rank asc\n",
    "    \"\"\"\n",
    "    if df_target_rows.empty:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"book_id\",\"rank\",\"freq\",\"users_n\",\"avg_rank\",\"avg_est_score\",\"rank1_count\",\"original_title\",\"genres_all\"\n",
    "        ])\n",
    "\n",
    "    g = df_target_rows.groupby(\"book_id\", as_index=False)\n",
    "    out = g.agg(\n",
    "        freq=(\"book_id\", \"size\"),\n",
    "        users_n=(\"user_id\", \"nunique\"),\n",
    "        avg_rank=(\"rank\", \"mean\"),\n",
    "        avg_est_score=(\"est_score\", \"mean\"),\n",
    "        rank1_count=(\"rank\", lambda s: int((s == 1).sum())),\n",
    "    )\n",
    "    # attach sample title/genres\n",
    "    for c in [\"original_title\", \"genres_all\"]:\n",
    "        smpl = df_target_rows.groupby(\"book_id\")[c].apply(\n",
    "            lambda s: s.dropna().iloc[0] if s.notna().any() else pd.NA\n",
    "        ).reset_index(name=c)\n",
    "        out = out.merge(smpl, on=\"book_id\", how=\"left\")\n",
    "\n",
    "    out = out.sort_values([\"freq\",\"rank1_count\",\"avg_rank\"], ascending=[False, False, True]).reset_index(drop=True)\n",
    "    out.insert(1, \"rank\", out.index + 1)\n",
    "    return out\n",
    "\n",
    "def extract_k(path: Path) -> Optional[int]:\n",
    "    m = re.search(r\"(\\d+)\\s*recommendation$\", path.stem)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def extract_genre_from_injection_filename(p: Path) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Accept names like (NMF results):\n",
    "      f_Adventure_2u_pos5_neg1_all_15recommendation.csv\n",
    "      f_Science_Fiction_4u_pos5_neg0_all_35recommendation.csv\n",
    "    \"\"\"\n",
    "    name = p.name\n",
    "    m = re.match(r\"^f_(.+?)_(\\d+)u_pos\\d+_.*_(\\d+)recommendation\\.csv$\", name, flags=re.IGNORECASE)\n",
    "    if not m:\n",
    "        return None\n",
    "    raw_genre = m.group(1).replace(\"_\", \" \")\n",
    "    return norm_token(raw_genre)\n",
    "\n",
    "def find_injection(target_disp: str, n: int, k: int) -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Search recursively in SEARCH_ROOT for an injection file matching target genre, n users, and K.\n",
    "    \"\"\"\n",
    "    target_canon = norm_token(target_disp)\n",
    "    for pat in INJECTION_PATTERNS:\n",
    "        patt = pat.format(n=n, k=k)\n",
    "        for p in SEARCH_ROOT.rglob(patt):\n",
    "            g = extract_genre_from_injection_filename(p)\n",
    "            if g and g == target_canon:\n",
    "                return p\n",
    "    return None\n",
    "\n",
    "def genre_key_disp(genre_name: str) -> Tuple[str, str]:\n",
    "    disp = display_canonical(genre_name)\n",
    "    key  = re.sub(r\"[^\\w\\-]+\", \"_\", disp)\n",
    "    return key, disp\n",
    "\n",
    "# ========= Plotting ==========================================================\n",
    "def plot_genre_pos_three_bins(G_disp: str,\n",
    "                              data_by_k: Dict[int, Dict[str, float]],\n",
    "                              out_png: Path):\n",
    "    \"\"\"\n",
    "    data_by_k: {K: {\"Original\": v0, \"2\": v2, \"4\": v4, ...}}\n",
    "    \"\"\"\n",
    "    ks = sorted(data_by_k.keys())\n",
    "    if not ks:\n",
    "        return\n",
    "    groups = [\"Original\"] + [str(x) for x in N_LIST]\n",
    "    # include only groups that appear at least once\n",
    "    present_groups = [g for g in groups if any(g in data_by_k.get(k, {}) for k in ks)]\n",
    "\n",
    "    width = 0.8 / max(1, len(present_groups))\n",
    "    x = list(range(len(ks)))\n",
    "    plt.figure(figsize=(8.4, 4.4), dpi=160)\n",
    "\n",
    "    for j, g in enumerate(present_groups):\n",
    "        offs = [i + (j - (len(present_groups)-1)/2)*width for i in x]\n",
    "        vals = [float(data_by_k.get(k, {}).get(g, 0.0)) for k in ks]\n",
    "        plt.bar(offs, vals, width=width, label=(\"n=\"+g if g!=\"Original\" else \"Original\"))\n",
    "\n",
    "    plt.xticks(x, [f\"Top-{k}\" for k in ks])\n",
    "    plt.ylabel(\"Avg # of genre-books in Top-K per user\")\n",
    "    plt.title(f\"{G_disp} — POS=5 (NMF injections)\")\n",
    "    plt.legend(ncol=min(4, len(present_groups)), fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_png)\n",
    "    plt.close()\n",
    "\n",
    "# ========= MAIN per-genre ====================================================\n",
    "def process_one_genre(target_genre: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Processes one genre; returns dict with:\n",
    "      {\n",
    "        'disp': display name,\n",
    "        'original_uniques': {K: unique_tg_books, ...},\n",
    "        'injection_uniques': {(N,K): unique_tg_books, ...},\n",
    "        'out_dir': Path,\n",
    "        'per_book_rows': [ ... rows with 'genre' ... ]\n",
    "      }\n",
    "    Also writes the figure into the same OUT_DIR.\n",
    "    \"\"\"\n",
    "    GEN_KEY, GEN_DISP = genre_key_disp(target_genre)\n",
    "    OUT_DIR = OUT_BASE / f\"{GEN_KEY}_explanation\"\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    original_uniques: Dict[int, int] = {}\n",
    "    injection_uniques: Dict[Tuple[int,int], int] = {}\n",
    "    per_book_rows: List[Dict] = []\n",
    "    data_by_k: Dict[int, Dict[str, float]] = {k: {} for k in K_LIST}\n",
    "\n",
    "    # ORIGINAL\n",
    "    for K in K_LIST:\n",
    "        fp = ORIG_DIR / f\"ORIGINAL_{K}recommendation.csv\"\n",
    "        if not fp.exists():\n",
    "            print(f\"[warn][{GEN_DISP}] Missing ORIGINAL for K={K}: {fp}\")\n",
    "            continue\n",
    "        df = load_rec_csv(fp)\n",
    "        uniq_all, avg_user, uniq_tg, freq, users_with_tg, is_tg = metrics_for_file(df, GEN_DISP)\n",
    "        print(f\"[{GEN_DISP}] [{K}], {fp} -> {uniq_all} books -> {GEN_DISP}: avg/user={avg_user:.2f}, unique={uniq_tg}\")\n",
    "        original_uniques[K] = uniq_tg\n",
    "        data_by_k[K][\"Original\"] = avg_user\n",
    "\n",
    "        ranked = per_book_ranking(df.loc[is_tg].copy())\n",
    "        for _, r in ranked.iterrows():\n",
    "            per_book_rows.append({\n",
    "                \"genre\": GEN_DISP,\n",
    "                \"dataset\": f\"original{K}\",\n",
    "                \"book_id\": int(r[\"book_id\"]),\n",
    "                \"rank\": int(r[\"rank\"]),\n",
    "                \"freq\": int(r[\"freq\"]),\n",
    "                \"users_n\": int(r[\"users_n\"]),\n",
    "                \"avg_rank\": float(r[\"avg_rank\"]) if pd.notna(r[\"avg_rank\"]) else None,\n",
    "                \"avg_est_score\": float(r[\"avg_est_score\"]) if pd.notna(r[\"avg_est_score\"]) else None,\n",
    "                \"rank1_count\": int(r[\"rank1_count\"]),\n",
    "                \"original_title\": r.get(\"original_title\", pd.NA),\n",
    "                \"genres_all\": r.get(\"genres_all\", pd.NA),\n",
    "            })\n",
    "\n",
    "    # NMF INJECTIONS\n",
    "    for K in K_LIST:\n",
    "        for N in N_LIST:\n",
    "            fp = find_injection(GEN_DISP, N, K)\n",
    "            if not fp:\n",
    "                print(f\"[warn][{GEN_DISP}] Missing NMF injection file for N={N}, K={K}\")\n",
    "                continue\n",
    "            df = load_rec_csv(fp)\n",
    "            uniq_all, avg_user, uniq_tg, freq, users_with_tg, is_tg = metrics_for_file(df, GEN_DISP)\n",
    "            print(f\"[{GEN_DISP}] [{K}] {fp.name} -> {uniq_all} books -> {GEN_DISP}: avg/user={avg_user:.2f}, unique={uniq_tg}\")\n",
    "            injection_uniques[(N, K)] = uniq_tg\n",
    "            data_by_k[K][str(N)] = avg_user\n",
    "\n",
    "            ranked = per_book_ranking(df.loc[is_tg].copy())\n",
    "            for _, r in ranked.iterrows():\n",
    "                per_book_rows.append({\n",
    "                    \"genre\": GEN_DISP,\n",
    "                    \"dataset\": f\"{N}u_{K}\",\n",
    "                    \"book_id\": int(r[\"book_id\"]),\n",
    "                    \"rank\": int(r[\"rank\"]),\n",
    "                    \"freq\": int(r[\"freq\"]),\n",
    "                    \"users_n\": int(r[\"users_n\"]),\n",
    "                    \"avg_rank\": float(r[\"avg_rank\"]) if pd.notna(r[\"avg_rank\"]) else None,\n",
    "                    \"avg_est_score\": float(r[\"avg_est_score\"]) if pd.notna(r[\"avg_est_score\"]) else None,\n",
    "                    \"rank1_count\": int(r[\"rank1_count\"]),\n",
    "                    \"original_title\": r.get(\"original_title\", pd.NA),\n",
    "                    \"genres_all\": r.get(\"genres_all\", pd.NA),\n",
    "                })\n",
    "\n",
    "    # Write per-genre text\n",
    "    text_path = OUT_DIR / \"explanation.txt\"\n",
    "    with open(text_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{GEN_DISP.lower()}:\\n\")\n",
    "        for K in K_LIST:\n",
    "            if K in original_uniques:\n",
    "                f.write(f\"original {K}: number_of_unique_books: {original_uniques[K]}\\n\")\n",
    "        for K in K_LIST:\n",
    "            for N in N_LIST:\n",
    "                val = injection_uniques.get((N, K))\n",
    "                if val is not None:\n",
    "                    f.write(f\"{N}u, {K}, number_of_unique_books: {val}\\n\")\n",
    "\n",
    "    # Write per-genre ranking table\n",
    "    table_df = pd.DataFrame(per_book_rows)\n",
    "    table_path = OUT_DIR / \"per_book_ranking.csv\"\n",
    "    table_df.to_csv(table_path, index=False)\n",
    "\n",
    "    # Make and save per-genre figure into the same folder\n",
    "    fig_path = OUT_DIR / f\"{slugify_token(GEN_DISP)}__pos5.png\"\n",
    "    plot_genre_pos_three_bins(GEN_DISP, data_by_k, fig_path)\n",
    "\n",
    "    print(f\"[OK][{GEN_DISP}] Saved text:   {text_path}\")\n",
    "    print(f\"[OK][{GEN_DISP}] Saved table:  {table_path}\")\n",
    "    print(f\"[OK][{GEN_DISP}] Saved figure: {fig_path}\")\n",
    "\n",
    "    return {\n",
    "        \"disp\": GEN_DISP,\n",
    "        \"original_uniques\": original_uniques,\n",
    "        \"injection_uniques\": injection_uniques,\n",
    "        \"out_dir\": OUT_DIR,\n",
    "        \"per_book_rows\": per_book_rows,\n",
    "    }\n",
    "\n",
    "# ========= MAIN (all genres) =================================================\n",
    "def main():\n",
    "    OUT_ALL = OUT_BASE / \"_all_genres\"\n",
    "    OUT_ALL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    all_rows: List[Dict] = []\n",
    "    master_lines: List[str] = []\n",
    "\n",
    "    for g in CANONICAL_GENRES:\n",
    "        res = process_one_genre(g)\n",
    "        # Append master block\n",
    "        master_lines.append(f\"{res['disp'].lower()}:\")\n",
    "        for K in K_LIST:\n",
    "            if K in res[\"original_uniques\"]:\n",
    "                master_lines.append(f\"original {K}: number_of_unique_books: {res['original_uniques'][K]}\")\n",
    "        for K in K_LIST:\n",
    "            for N in N_LIST:\n",
    "                val = res[\"injection_uniques\"].get((N, K))\n",
    "                if val is not None:\n",
    "                    master_lines.append(f\"{N}u, {K}, number_of_unique_books: {val}\")\n",
    "        master_lines.append(\"\")  # blank line\n",
    "        all_rows.extend(res[\"per_book_rows\"])\n",
    "\n",
    "    # Save global rollups\n",
    "    master_txt = OUT_ALL / \"summary_master.txt\"\n",
    "    with open(master_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(master_lines))\n",
    "    print(f\"[OK] Wrote master summary: {master_txt}\")\n",
    "\n",
    "    if all_rows:\n",
    "        df_all = pd.DataFrame(all_rows)\n",
    "        df_all.to_csv(OUT_ALL / \"per_book_ranking_all.csv\", index=False)\n",
    "        print(f\"[OK] Wrote global per-book ranking CSV: {OUT_ALL / 'per_book_ranking_all.csv'}\")\n",
    "    else:\n",
    "        print(\"[warn] No per-book rows produced. Check inputs / paths.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
