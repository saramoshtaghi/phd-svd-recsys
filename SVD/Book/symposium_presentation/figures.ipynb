{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "  Stats CSV:           recsys_viz/genre_imbalance_stats.csv\n",
      "  Grouped Bar:         recsys_viz/grouped_bar_typical_vs_desired.png\n",
      "  Long Tail:           recsys_viz/long_tail_typical.png\n",
      "  Cumulative Long Tail:recsys_viz/long_tail_typical_cumulative.png\n",
      "  Heatmap:             recsys_viz/heatmap_typical_desired_gap.png\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# recsys_imbalance_viz.py\n",
    "# Visualize genre imbalance with grouped bars, long-tail, cumulative, and heatmap.\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# If you're on a headless server, uncomment:\n",
    "# matplotlib.use(\"Agg\")\n",
    "\n",
    "\n",
    "def build_synthetic_df() -> pd.DataFrame:\n",
    "    genres = [\n",
    "        \"Fantasy\", \"Science Fiction\", \"Romance\", \"Mystery\", \"Thriller\",\n",
    "        \"Historical\", \"Adult\", \"Horror\", \"Children's\",\n",
    "        \"Adventure\", \"Classics\", \"Nonfiction\", \"Drama\"\n",
    "    ]\n",
    "    typical = np.array([14, 13, 12, 11, 10, 8, 7, 6, 5, 5, 4, 3, 2], dtype=float)\n",
    "    desired = np.array([10, 10, 10, 9, 9, 8, 8, 7, 7, 7, 7, 6, 6], dtype=float)\n",
    "    typical = typical / typical.sum() * 100.0\n",
    "    desired = desired / desired.sum() * 100.0\n",
    "    return pd.DataFrame({\"genre\": genres, \"typical_pct\": typical, \"desired_pct\": desired})\n",
    "\n",
    "\n",
    "def load_df(csv_path: Optional[Path], normalize: bool) -> pd.DataFrame:\n",
    "    if csv_path is not None and csv_path.exists():\n",
    "        df = pd.read_csv(csv_path)\n",
    "        required = {\"genre\", \"typical_pct\", \"desired_pct\"}\n",
    "        missing = required - set(df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(\"CSV is missing columns: {}\".format(missing))\n",
    "        df[\"typical_pct\"] = pd.to_numeric(df[\"typical_pct\"], errors=\"coerce\").fillna(0.0)\n",
    "        df[\"desired_pct\"] = pd.to_numeric(df[\"desired_pct\"], errors=\"coerce\").fillna(0.0)\n",
    "    else:\n",
    "        df = build_synthetic_df()\n",
    "\n",
    "    if normalize:\n",
    "        for col in [\"typical_pct\", \"desired_pct\"]:\n",
    "            s = float(df[col].sum())\n",
    "            if s > 0:\n",
    "                df[col] = df[col] / s * 100.0\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"gap_pct\"] = df[\"desired_pct\"] - df[\"typical_pct\"]\n",
    "    df[\"abs_gap_pct\"] = df[\"gap_pct\"].abs()\n",
    "    total_abs_gap = float(df[\"abs_gap_pct\"].sum())\n",
    "    df[\"gap_contribution_pct\"] = np.where(\n",
    "        total_abs_gap > 0, df[\"abs_gap_pct\"] / total_abs_gap * 100.0, 0.0\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_grouped_bar(df: pd.DataFrame, outdir: Path) -> Path:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(df))\n",
    "    width = 0.4\n",
    "    plt.bar(x - width/2, df[\"typical_pct\"].values, width=width, label=\"Typical\")\n",
    "    plt.bar(x + width/2, df[\"desired_pct\"].values, width=width, label=\"Desired\")\n",
    "    plt.xticks(x, df[\"genre\"].tolist(), rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"Share of Recommendations (%)\")\n",
    "    plt.title(\"Genre Distribution: Typical vs Desired\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    path = outdir / \"grouped_bar_typical_vs_desired.png\"\n",
    "    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return path\n",
    "\n",
    "\n",
    "def save_long_tail(df: pd.DataFrame, outdir: Path) -> Tuple[Path, Path]:\n",
    "    df_sorted = df.sort_values(\"typical_pct\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df_sorted[\"typical_pct\"].values, marker=\"o\")\n",
    "    plt.xticks(np.arange(len(df_sorted)), df_sorted[\"genre\"].tolist(), rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"Share of Recommendations (%)\")\n",
    "    plt.title(\"Long Tail: Typical Distribution by Genre (Sorted Desc)\")\n",
    "    plt.tight_layout()\n",
    "    longtail_path = outdir / \"long_tail_typical.png\"\n",
    "    plt.savefig(longtail_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    cum = df_sorted[\"typical_pct\"].cumsum()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(cum.values, marker=\"o\")\n",
    "    plt.xticks(np.arange(len(df_sorted)), df_sorted[\"genre\"].tolist(), rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"Cumulative Share (%)\")\n",
    "    plt.title(\"Cumulative Long Tail: Typical Distribution (Sorted Desc)\")\n",
    "    plt.tight_layout()\n",
    "    cum_path = outdir / \"long_tail_typical_cumulative.png\"\n",
    "    plt.savefig(cum_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    return longtail_path, cum_path\n",
    "\n",
    "\n",
    "def save_heatmap(df: pd.DataFrame, outdir: Path) -> Path:\n",
    "    heat_data = np.vstack([\n",
    "        df[\"typical_pct\"].values,\n",
    "        df[\"desired_pct\"].values,\n",
    "        df[\"gap_pct\"].values\n",
    "    ])\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.imshow(heat_data, aspect=\"auto\")\n",
    "    plt.yticks([0, 1, 2], [\"Typical %\", \"Desired %\", \"Gap (Desired - Typical)\"])\n",
    "    plt.xticks(np.arange(len(df)), df[\"genre\"].tolist(), rotation=30, ha=\"right\")\n",
    "    plt.colorbar(label=\"Percent\")\n",
    "    plt.title(\"Genre Coverage Heatmap\")\n",
    "    plt.tight_layout()\n",
    "    path = outdir / \"heatmap_typical_desired_gap.png\"\n",
    "    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return path\n",
    "\n",
    "\n",
    "def parse_args(argv: Optional[List[str]] = None):\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Visualize genre imbalance (Typical vs Desired).\"\n",
    "    )\n",
    "    parser.add_argument(\"--csv\", type=Path, default=None,\n",
    "                        help=\"Path to CSV with columns: genre, typical_pct, desired_pct\")\n",
    "    parser.add_argument(\"--outdir\", type=Path, default=Path(\"./recsys_viz\"),\n",
    "                        help=\"Output directory for figures and stats\")\n",
    "    parser.add_argument(\"--normalize\", action=\"store_true\",\n",
    "                        help=\"Normalize typical/desired columns to 100%% each\")\n",
    "\n",
    "    # IMPORTANT: in notebooks/IPython, extra args like --f=... appear.\n",
    "    # Use parse_known_args to ignore unknowns.\n",
    "    args, _unknown = parser.parse_known_args(argv)\n",
    "    return args\n",
    "\n",
    "\n",
    "def main(argv: Optional[List[str]] = None):\n",
    "    args = parse_args(argv)\n",
    "    args.outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = load_df(args.csv, normalize=args.normalize)\n",
    "    df = compute_stats(df)\n",
    "\n",
    "    stats_path = args.outdir / \"genre_imbalance_stats.csv\"\n",
    "    df.round(3).to_csv(stats_path, index=False)\n",
    "\n",
    "    bar_path = save_grouped_bar(df, args.outdir)\n",
    "    longtail_path, cum_path = save_long_tail(df, args.outdir)\n",
    "    heat_path = save_heatmap(df, args.outdir)\n",
    "\n",
    "    print(\"Saved:\")\n",
    "    print(\"  Stats CSV:           {}\".format(stats_path))\n",
    "    print(\"  Grouped Bar:         {}\".format(bar_path))\n",
    "    print(\"  Long Tail:           {}\".format(longtail_path))\n",
    "    print(\"  Cumulative Long Tail:{}\".format(cum_path))\n",
    "    print(\"  Heatmap:             {}\".format(heat_path))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # When run as a script (terminal): python recsys_imbalance_viz.py --csv ... --outdir ...\n",
    "    # When run in Jupyter: just execute this cell; parse_known_args will ignore --f=...\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Images written to: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/symposium_presentation/injection_demo_figs\n",
      " - interactions_per_feature_before_after.png\n",
      " - matrix_sample_before.png\n",
      " - matrix_sample_after.png\n",
      " - flowchart.svg (or flowchart_matplotlib.png)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# inject_25_demo.py\n",
    "# Simulate adding 25 synthetic \"Mystery-only\" users to a 53k×10k, 13-feature dataset,\n",
    "# and produce:\n",
    "#  1) Methodology flowchart (flowchart.svg or flowchart_matplotlib.png)\n",
    "#  2) Before/After dataset visualizations:\n",
    "#     - interactions_per_feature_before_after.png\n",
    "#     - matrix_sample_before.png\n",
    "#     - matrix_sample_after.png\n",
    "#\n",
    "# Py3.7+; uses only std libs + numpy, pandas, matplotlib; graphviz is optional.\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------- Helpers -----------------\n",
    "def ensure_outdir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def make_features() -> List[str]:\n",
    "    # 13 illustrative features (incl. Mystery); adjust as needed\n",
    "    return [\n",
    "        \"Fantasy\", \"Science Fiction\", \"Romance\", \"Mystery\", \"Thriller\",\n",
    "        \"Historical\", \"Adult\", \"Horror\", \"Children's\", \"Adventure\",\n",
    "        \"Classics\", \"Nonfiction\", \"Drama\"\n",
    "    ]\n",
    "\n",
    "def synth_item_features(n_items: int, features: List[str], seed: int = 42) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Assign each item exactly one primary feature with a slightly long-tailed distribution\n",
    "    (so the simulation shows popularity bias realistically).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    k = len(features)\n",
    "    # Mild head-tail skew for feature prior\n",
    "    prior = np.linspace(1.6, 0.6, num=k)\n",
    "    prior = prior / prior.sum()\n",
    "    feat_ids = rng.choice(np.arange(k), size=n_items, p=prior)\n",
    "    return pd.Series([features[i] for i in feat_ids], name=\"feature\")\n",
    "\n",
    "def synth_interactions_per_feature(\n",
    "    n_users: int,\n",
    "    n_items: int,\n",
    "    item_features: pd.Series,\n",
    "    avg_interactions: int = 50,\n",
    "    seed: int = 123\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    We avoid building a massive matrix. Instead, simulate expected training interactions per feature:\n",
    "    - Start with item-feature distribution\n",
    "    - Add slight popularity skew per feature\n",
    "    - Distribute total interactions accordingly\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    feature_counts = item_features.value_counts().sort_index()\n",
    "    features = feature_counts.index.tolist()\n",
    "\n",
    "    # Popularity weights per feature: items in popular features attract more interactions\n",
    "    base = feature_counts.values.astype(float)\n",
    "    pop_skew = np.linspace(1.4, 0.8, num=len(features))  # head heavier than tail\n",
    "    weights = base * pop_skew\n",
    "    weights = np.maximum(weights, 1e-6)\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    total_interactions = int(n_users * avg_interactions)\n",
    "    expected = weights * total_interactions\n",
    "\n",
    "    # Add a little noise to feel realistic, then floor at zero\n",
    "    noise = rng.normal(0, expected * 0.03)  # 3% noise\n",
    "    expected_noisy = np.clip(expected + noise, 0, None)\n",
    "\n",
    "    # Return as Series indexed by feature\n",
    "    return pd.Series(expected_noisy, index=features, name=\"interactions\")\n",
    "\n",
    "def inject_synthetic_users_for_feature(\n",
    "    interactions_before: pd.Series,\n",
    "    item_features: pd.Series,\n",
    "    target_feature: str,\n",
    "    n_synth_users: int = 25,\n",
    "    ratings_per_synth_user: Optional[int] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Add the interactions produced by n_synth_users who only rate the target feature.\n",
    "    Each synthetic user rates either ALL target-feature items or 'ratings_per_synth_user' items (if provided).\n",
    "    \"\"\"\n",
    "    target_mask = (item_features == target_feature)\n",
    "    n_target_items = int(target_mask.sum())\n",
    "\n",
    "    if n_target_items == 0:\n",
    "        # Nothing to inject; return unchanged\n",
    "        return interactions_before.copy()\n",
    "\n",
    "    if ratings_per_synth_user is None:\n",
    "        # Default: rate ALL target items\n",
    "        ratings_per_synth_user = n_target_items\n",
    "\n",
    "    added_interactions = n_synth_users * ratings_per_synth_user\n",
    "\n",
    "    interactions_after = interactions_before.copy()\n",
    "    interactions_after.loc[target_feature] = interactions_after.loc[target_feature] + added_interactions\n",
    "    return interactions_after\n",
    "\n",
    "def plot_bar_before_after(inter_before: pd.Series, inter_after: pd.Series, out_path: Path, highlight_feature: str):\n",
    "    feats = inter_before.index.tolist()\n",
    "    x = np.arange(len(feats))\n",
    "    width = 0.42\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(x - width/2, inter_before.values, width=width, label=\"Before\")\n",
    "    plt.bar(x + width/2, inter_after.values, width=width, label=\"After (+25 target-only users)\")\n",
    "\n",
    "    plt.xticks(x, feats, rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"Training interactions (simulated)\")\n",
    "    plt.title(\"Interactions per Feature: Before vs After Injection\")\n",
    "\n",
    "    # Annotate the target feature with a simple arrow/text\n",
    "    try:\n",
    "        idx = feats.index(highlight_feature)\n",
    "        y = max(inter_before.iloc[idx], inter_after.iloc[idx])\n",
    "        plt.annotate(\n",
    "            f\"Target: {highlight_feature}\",\n",
    "            xy=(idx + 0.22, y),\n",
    "            xytext=(idx + 0.8, y * 1.1),\n",
    "            arrowprops=dict(arrowstyle=\"->\", lw=1.2),\n",
    "            fontsize=10\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_matrix_samples(\n",
    "    n_users: int,\n",
    "    n_items: int,\n",
    "    item_features: pd.Series,\n",
    "    target_feature: str,\n",
    "    outdir: Path,\n",
    "    sample_users_before: int = 200,\n",
    "    sample_items: int = 300,\n",
    "    n_synth_users: int = 25\n",
    "):\n",
    "    \"\"\"\n",
    "    Create tiny “before” and “after” binary samples (users×items) to visualize the injection effect.\n",
    "    Before: random sparse interactions.\n",
    "    After: append 25 synthetic rows connected to target-feature item columns.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(7)\n",
    "\n",
    "    # Sample item columns with all features represented\n",
    "    item_idx = np.arange(n_items)\n",
    "    item_sample = rng.choice(item_idx, size=sample_items, replace=False)\n",
    "    item_feats_sample = item_features.iloc[item_sample].reset_index(drop=True)\n",
    "\n",
    "    # Before: pick a subset of users and generate a sparse random matrix\n",
    "    p_sparse = 0.02  # ~2% density in the tiny sample\n",
    "    before = rng.random((sample_users_before, sample_items)) < p_sparse\n",
    "    before = before.astype(int)\n",
    "\n",
    "    # After: add 25 synthetic users (rows) that connect only to target-feature columns\n",
    "    after = before.copy()\n",
    "    target_cols = np.where(item_feats_sample.values == target_feature)[0]\n",
    "    synth_block = np.zeros((n_synth_users, sample_items), dtype=int)\n",
    "    if len(target_cols) > 0:\n",
    "        synth_block[:, target_cols] = 1\n",
    "    after = np.vstack([after, synth_block])\n",
    "\n",
    "    # Plot before\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.imshow(before, aspect=\"auto\")\n",
    "    plt.title(f\"Matrix Sample — BEFORE ({sample_users_before}×{sample_items})\")\n",
    "    plt.xlabel(\"Items (sample)\")\n",
    "    plt.ylabel(\"Users (sample)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / \"matrix_sample_before.png\", dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # Plot after\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.imshow(after, aspect=\"auto\")\n",
    "    plt.title(f\"Matrix Sample — AFTER (+{n_synth_users} rows)\")\n",
    "    plt.xlabel(\"Items (sample)\")\n",
    "    plt.ylabel(\"Users (sample incl. synthetic)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outdir / \"matrix_sample_after.png\", dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def write_flowchart_graphviz(outdir: Path) -> Optional[Path]:\n",
    "    try:\n",
    "        import graphviz  # optional dependency\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    dot = graphviz.Digraph(\"flow\", format=\"svg\")\n",
    "    dot.attr(rankdir=\"LR\", splines=\"spline\", nodesep=\"0.4\", ranksep=\"0.5\")\n",
    "    node_style = dict(shape=\"box\", style=\"rounded,filled\", fillcolor=\"#eef2ff\", color=\"#666666\")\n",
    "\n",
    "    def n(name, label):\n",
    "        dot.node(name, label=label, **node_style)\n",
    "\n",
    "    n(\"data\", \"Input Data\\n(Users, Items, Features)\")\n",
    "    n(\"svd0\", \"Baseline SVD\\n(train → recs)\")\n",
    "    n(\"target\", \"Pick Target Feature\\n(e.g., Mystery)\")\n",
    "    n(\"syn\", \"Create Synthetic Users\\n(high ratings on target only)\")\n",
    "    n(\"inj\", \"Inject & Retrain SVD\")\n",
    "    n(\"eval\", \"Evaluate Coverage/Diversity\\n+ Accuracy (RMSE/MAE)\")\n",
    "    n(\"tune\", \"Tune Count (25/50/100…)\")\n",
    "\n",
    "    def e(a, b, label=\"\"):\n",
    "        if label:\n",
    "            dot.edge(a, b, label=label)\n",
    "        else:\n",
    "            dot.edge(a, b)\n",
    "\n",
    "    e(\"data\", \"svd0\")\n",
    "    e(\"svd0\", \"target\")\n",
    "    e(\"target\", \"syn\")\n",
    "    e(\"syn\", \"inj\", \"+25 users (example)\")\n",
    "    e(\"inj\", \"eval\", \"K=15/25/35\")\n",
    "    e(\"eval\", \"tune\", \"if needed\")\n",
    "    e(\"tune\", \"syn\", \"adjust #users\")\n",
    "\n",
    "    out = outdir / \"flowchart.svg\"\n",
    "    dot.render(filename=str(out.with_suffix(\"\")), cleanup=True)\n",
    "    return out\n",
    "\n",
    "def draw_flowchart_matplotlib(outdir: Path) -> Path:\n",
    "    # Minimal fallback if graphviz isn't available\n",
    "    plt.figure(figsize=(11, 3))\n",
    "    ax = plt.gca()\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    boxes = [\n",
    "        (\"Input Data\\n(Users, Items, Features)\", (0.06, 0.5)),\n",
    "        (\"Baseline SVD\\n(train → recs)\", (0.22, 0.5)),\n",
    "        (\"Pick Target Feature\\n(e.g., Mystery)\", (0.38, 0.5)),\n",
    "        (\"Create Synthetic Users\\n(high ratings on target)\", (0.56, 0.5)),\n",
    "        (\"Inject & Retrain SVD\", (0.73, 0.5)),\n",
    "        (\"Evaluate\\n(Coverage, Accuracy)\", (0.87, 0.5)),\n",
    "    ]\n",
    "\n",
    "    for text, (x, y) in boxes:\n",
    "        ax.add_patch(plt.Rectangle((x-0.085, y-0.12), 0.17, 0.24, fc=\"#eef2ff\", ec=\"#666666\", lw=1.2))\n",
    "        ax.text(x, y, text, ha=\"center\", va=\"center\", fontsize=10)\n",
    "\n",
    "    def arrow(x1, y1, x2, y2):\n",
    "        ax.annotate(\"\", xy=(x2-0.095, y2), xytext=(x1+0.095, y1),\n",
    "                    arrowprops=dict(arrowstyle=\"->\", lw=1.3, color=\"#666666\"))\n",
    "\n",
    "    for i in range(len(boxes)-1):\n",
    "        arrow(boxes[i][1][0], boxes[i][1][1], boxes[i+1][1][0], boxes[i+1][1][1])\n",
    "\n",
    "    path = outdir / \"flowchart_matplotlib.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return path\n",
    "\n",
    "# ----------------- Main -----------------\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Simulate + visualize injecting 25 target-only users.\")\n",
    "    parser.add_argument(\"--users\", type=int, default=53000, help=\"Number of real users (baseline)\")\n",
    "    parser.add_argument(\"--items\", type=int, default=10000, help=\"Number of items (books)\")\n",
    "    parser.add_argument(\"--avg_interactions\", type=int, default=50, help=\"Avg interactions per user (baseline)\")\n",
    "    parser.add_argument(\"--target\", type=str, default=\"Mystery\", help=\"Target feature to boost\")\n",
    "    parser.add_argument(\"--synth_users\", type=int, default=25, help=\"Number of synthetic users to inject\")\n",
    "    parser.add_argument(\"--outdir\", type=Path, default=Path(\"./injection_demo_figs\"), help=\"Output directory\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    ensure_outdir(args.outdir)\n",
    "\n",
    "    features = make_features()\n",
    "    if args.target not in features:\n",
    "        # Ensure target exists in our 13-feature list\n",
    "        features[3] = args.target  # replace \"Mystery\" slot with custom name\n",
    "\n",
    "    # 1) Assign each item a primary feature\n",
    "    item_features = synth_item_features(args.items, features)\n",
    "\n",
    "    # 2) Simulate baseline interactions per feature\n",
    "    inter_before = synth_interactions_per_feature(\n",
    "        n_users=args.users,\n",
    "        n_items=args.items,\n",
    "        item_features=item_features,\n",
    "        avg_interactions=args.avg_interactions\n",
    "    )\n",
    "\n",
    "    # 3) Inject 25 target-only users (each rates all target-feature items)\n",
    "    inter_after = inject_synthetic_users_for_feature(\n",
    "        interactions_before=inter_before,\n",
    "        item_features=item_features,\n",
    "        target_feature=args.target,\n",
    "        n_synth_users=args.synth_users,\n",
    "        ratings_per_synth_user=None  # None => rate all target items\n",
    "    )\n",
    "\n",
    "    # Normalize scale for clearer comparison (optional but helpful for chart legibility)\n",
    "    # We’ll just plot raw counts; the Mystery bar will clearly jump.\n",
    "\n",
    "    # 4) Plots — Before/After interactions per feature\n",
    "    bar_path = args.outdir / \"interactions_per_feature_before_after.png\"\n",
    "    plot_bar_before_after(inter_before, inter_after, bar_path, highlight_feature=args.target)\n",
    "\n",
    "    # 5) Plots — Tiny matrix samples (before vs after)\n",
    "    plot_matrix_samples(\n",
    "        n_users=args.users,\n",
    "        n_items=args.items,\n",
    "        item_features=item_features,\n",
    "        target_feature=args.target,\n",
    "        outdir=args.outdir,\n",
    "        sample_users_before=200,\n",
    "        sample_items=300,\n",
    "        n_synth_users=args.synth_users\n",
    "    )\n",
    "\n",
    "    # 6) Flowchart (Graphviz if available, else Matplotlib)\n",
    "    svg = write_flowchart_graphviz(args.outdir)\n",
    "    if svg is None:\n",
    "        draw_flowchart_matplotlib(args.outdir)\n",
    "\n",
    "    print(\"Done. Images written to:\", args.outdir.resolve())\n",
    "    print(\" - interactions_per_feature_before_after.png\")\n",
    "    print(\" - matrix_sample_before.png\")\n",
    "    print(\" - matrix_sample_after.png\")\n",
    "    print(\" - flowchart.svg (or flowchart_matplotlib.png)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote visuals to: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/symposium_presentation/setup_figs\n",
      " - dataset_comparison_table.png\n",
      " - experimental_design_diagram.png\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# make_setup_visuals.py\n",
    "# Generates:\n",
    "#  1) dataset_comparison_table.png\n",
    "#  2) experimental_design_diagram.png  (and flowchart.svg if graphviz is installed)\n",
    "#\n",
    "# Py3.7+; depends on numpy, pandas, matplotlib. Graphviz is optional.\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------- Helpers -----------------\n",
    "def ensure_outdir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def humanize(n: Optional[int]) -> str:\n",
    "    if n is None:\n",
    "        return \"—\"\n",
    "    # simple human-friendly formatting\n",
    "    if n >= 1_000_000_000:\n",
    "        return f\"{n/1_000_000_000:.1f}B\"\n",
    "    if n >= 1_000_000:\n",
    "        return f\"{n/1_000_000:.2f}M\"\n",
    "    if n >= 1_000:\n",
    "        return f\"{n/1_000:.0f}K\"\n",
    "    return str(n)\n",
    "\n",
    "def build_dataset_df(apps_interactions: Optional[int], apps_users: Optional[int], apps_items: Optional[int]) -> pd.DataFrame:\n",
    "    rows = [\n",
    "        {\n",
    "            \"Domain\": \"Books\",\n",
    "            \"Dataset\": \"Goodreads-10k\",\n",
    "            \"Interactions\": \"5.97M\",\n",
    "            \"Users\": \"53K\",\n",
    "            \"Items\": \"10K\",\n",
    "            \"Target feature\": \"13 genres\"\n",
    "        },\n",
    "        {\n",
    "            \"Domain\": \"Movies\",\n",
    "            \"Dataset\": \"MovieLens-100k\",\n",
    "            \"Interactions\": \"100K\",\n",
    "            \"Users\": \"943\",\n",
    "            \"Items\": \"1,682\",\n",
    "            \"Target feature\": \"8 decades\"\n",
    "        },\n",
    "        {\n",
    "            \"Domain\": \"Mobile Apps\",\n",
    "            \"Dataset\": \"—\",\n",
    "            \"Interactions\": humanize(apps_interactions),\n",
    "            \"Users\": humanize(apps_users),\n",
    "            \"Items\": humanize(apps_items),\n",
    "            \"Target feature\": \"48 categories\"\n",
    "        },\n",
    "    ]\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ----------------- Figure 1: Dataset comparison table -----------------\n",
    "def make_dataset_table(df: pd.DataFrame, out_path: Path, dpi: int = 220):\n",
    "    \"\"\"\n",
    "    Render a clean, slide-ready table as a PNG using matplotlib.\n",
    "    \"\"\"\n",
    "    # Styling\n",
    "    col_widths = [0.14, 0.20, 0.18, 0.12, 0.12, 0.24]  # relative\n",
    "    total_w = 1200\n",
    "    total_h = 260 + 44 * len(df)  # adaptive height\n",
    "    fig_w = total_w / dpi\n",
    "    fig_h = total_h / dpi\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(fig_w, fig_h), dpi=dpi)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Header\n",
    "    title = \"Datasets — Comparison\"\n",
    "    ax.text(0.5, 1.04, title, ha=\"center\", va=\"bottom\", fontsize=16, weight=\"bold\", transform=ax.transAxes)\n",
    "\n",
    "    # Build cell data\n",
    "    cols = list(df.columns)\n",
    "    cell_text = df.values.tolist()\n",
    "\n",
    "    # Draw table\n",
    "    table = ax.table(\n",
    "        cellText=cell_text,\n",
    "        colLabels=cols,\n",
    "        cellLoc=\"center\",\n",
    "        colLoc=\"center\",\n",
    "        loc=\"upper center\",\n",
    "        bbox=[0.02, 0.02, 0.96, 0.94]\n",
    "    )\n",
    "\n",
    "    # Column widths\n",
    "    for j, w in enumerate(col_widths):\n",
    "        table.auto_set_column_width(j)\n",
    "\n",
    "    # Style header\n",
    "    for (row, col), cell in table.get_celld().items():\n",
    "        if row == 0:\n",
    "            cell.set_text_props(weight=\"bold\", color=\"#222222\")\n",
    "            cell.set_facecolor(\"#eef2ff\")\n",
    "        else:\n",
    "            # zebra stripes\n",
    "            if row % 2 == 1:\n",
    "                cell.set_facecolor(\"#ffffff\")\n",
    "            else:\n",
    "                cell.set_facecolor(\"#f9fbff\")\n",
    "        cell.set_edgecolor(\"#d6dbe6\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\", dpi=dpi)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ----------------- Figure 2: Experimental design diagram -----------------\n",
    "def draw_experimental_design(out_path: Path,\n",
    "                             k_values: List[int],\n",
    "                             injection_levels: List[int],\n",
    "                             dpi: int = 200):\n",
    "    \"\"\"\n",
    "    Minimal-dep diagram with matplotlib boxes/arrows (always works).\n",
    "    Also tries to emit a Graphviz SVG (optional).\n",
    "    \"\"\"\n",
    "    # First: try Graphviz for a crisp SVG (optional)\n",
    "    try:\n",
    "        import graphviz  # type: ignore\n",
    "        dot = graphviz.Digraph(\"exp_design\", format=\"svg\")\n",
    "        dot.attr(rankdir=\"LR\", splines=\"spline\", nodesep=\"0.45\", ranksep=\"0.55\")\n",
    "        node_style = dict(shape=\"box\", style=\"rounded,filled\", fillcolor=\"#eef2ff\", color=\"#666666\")\n",
    "\n",
    "        def n(name, label): dot.node(name, label=label, **node_style)\n",
    "        def e(a, b, label=\"\"): dot.edge(a, b, label=label)\n",
    "\n",
    "        n(\"data\", \"Datasets\\n(Books • Movies • Apps)\")\n",
    "        n(\"features\", \"Target Features\\n(13 genres • 8 decades • 48 categories)\")\n",
    "        n(\"baseline\", \"Baseline SVD\\n(factors=100, seed=42)\")\n",
    "        n(\"inject\", \"Synthetic Users\\n(per feature)\")\n",
    "        n(\"levels\", f\"Injection Levels\\n{injection_levels}\")\n",
    "        n(\"train\", \"Train / Retrain\")\n",
    "        n(\"eval\", f\"Evaluate\\nTop-K={k_values}\\nCoverage • Diversity • RMSE/MAE\")\n",
    "        n(\"tune\", \"Tune & Select\\n(optimal injection)\")\n",
    "\n",
    "        e(\"data\", \"features\")\n",
    "        e(\"features\", \"baseline\")\n",
    "        e(\"baseline\", \"inject\")\n",
    "        e(\"inject\", \"levels\")\n",
    "        e(\"levels\", \"train\")\n",
    "        e(\"train\", \"eval\")\n",
    "        e(\"eval\", \"tune\")\n",
    "\n",
    "        svg_path = out_path.with_suffix(\".svg\")\n",
    "        dot.render(filename=str(svg_path.with_suffix(\"\")), cleanup=True)\n",
    "    except Exception:\n",
    "        svg_path = None\n",
    "\n",
    "    # Always produce a PNG fallback with matplotlib\n",
    "    fig, ax = plt.subplots(figsize=(12, 4.2), dpi=dpi)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Boxes: (text, center_x, center_y, width, height)\n",
    "    boxes = [\n",
    "        (\"Datasets\\n(Books • Movies • Apps)\", 0.08, 0.55, 0.18, 0.28),\n",
    "        (\"Target Features\\n(13G • 8D • 48C)\", 0.27, 0.55, 0.18, 0.28),\n",
    "        (\"Baseline SVD\\nfactors=100, seed=42\", 0.46, 0.55, 0.20, 0.28),\n",
    "        (\"Synthetic Users\\n(per feature)\", 0.64, 0.55, 0.18, 0.28),\n",
    "        (f\"Injection Levels\\n{injection_levels}\", 0.78, 0.55, 0.18, 0.28),\n",
    "        (f\"Evaluate\\nTop-K={k_values}\\nCoverage • Diversity • RMSE/MAE\", 0.46, 0.20, 0.28, 0.28),\n",
    "        (\"Train / Retrain\", 0.64, 0.20, 0.18, 0.18),\n",
    "        (\"Tune & Select\\n(optimal injection)\", 0.82, 0.20, 0.20, 0.24),\n",
    "    ]\n",
    "\n",
    "    # Draw boxes\n",
    "    for text, cx, cy, w, h in boxes:\n",
    "        ax.add_patch(plt.Rectangle((cx - w/2, cy - h/2), w, h,\n",
    "                                   facecolor=\"#eef2ff\", edgecolor=\"#666666\", lw=1.4))\n",
    "        ax.text(cx, cy, text, ha=\"center\", va=\"center\", fontsize=10)\n",
    "\n",
    "    # Arrows (start box idx -> end box idx)\n",
    "    def arrow(ix, iy):\n",
    "        x1, y1, w1, h1 = boxes[ix][1], boxes[ix][2], boxes[ix][3], boxes[ix][4]\n",
    "        x2, y2, w2, h2 = boxes[iy][1], boxes[iy][2], boxes[iy][3], boxes[iy][4]\n",
    "        ax.annotate(\"\", xy=(x2 - w2/2 + 0.01, y2),\n",
    "                    xytext=(x1 + w1/2 - 0.01, y1),\n",
    "                    arrowprops=dict(arrowstyle=\"->\", lw=1.4, color=\"#666666\"))\n",
    "\n",
    "    arrow(0, 1)  # Datasets -> Target Features\n",
    "    arrow(1, 2)  # Target Features -> Baseline\n",
    "    arrow(2, 3)  # Baseline -> Synthetic Users\n",
    "    arrow(3, 4)  # Synthetic Users -> Levels\n",
    "\n",
    "    # Vertical branch: Levels -> Train (down-left)\n",
    "    ax.annotate(\"\", xy=(boxes[6][1], boxes[6][2] + boxes[6][4]/2 + 0.02),\n",
    "                xytext=(boxes[4][1], boxes[4][2] - boxes[4][4]/2 - 0.02),\n",
    "                arrowprops=dict(arrowstyle=\"->\", lw=1.4, color=\"#666666\"))\n",
    "    # Train -> Evaluate (left)\n",
    "    ax.annotate(\"\", xy=(boxes[5][1] + boxes[5][3]/2 - 0.01, boxes[5][2]),\n",
    "                xytext=(boxes[6][1] - boxes[6][3]/2 + 0.01, boxes[6][2]),\n",
    "                arrowprops=dict(arrowstyle=\"<-\", lw=1.4, color=\"#666666\"))\n",
    "    # Evaluate -> Tune\n",
    "    arrow(5, 7)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\", dpi=dpi)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return svg_path\n",
    "\n",
    "# ----------------- Main -----------------\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Generate dataset table and experimental design diagram.\")\n",
    "    parser.add_argument(\"--outdir\", type=Path, default=Path(\"./setup_figs\"), help=\"Output directory\")\n",
    "    parser.add_argument(\"--apps_interactions\", type=int, default=None, help=\"Mobile apps total interactions (optional)\")\n",
    "    parser.add_argument(\"--apps_users\", type=int, default=None, help=\"Mobile apps users (optional)\")\n",
    "    parser.add_argument(\"--apps_items\", type=int, default=None, help=\"Mobile apps items (optional)\")\n",
    "    parser.add_argument(\"--k_values\", type=str, default=\"15,25,35\", help=\"Top-K list sizes, comma-separated\")\n",
    "    parser.add_argument(\"--injection_levels\", type=str, default=\"25,50,100,200\", help=\"Injection sizes, comma-separated\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    ensure_outdir(args.outdir)\n",
    "\n",
    "    # 1) Dataset comparison table\n",
    "    df = build_dataset_df(args.apps_interactions, args.apps_users, args.apps_items)\n",
    "    table_path = args.outdir / \"dataset_comparison_table.png\"\n",
    "    make_dataset_table(df, table_path)\n",
    "\n",
    "    # 2) Experimental design diagram\n",
    "    k_vals = [int(x.strip()) for x in args.k_values.split(\",\") if x.strip()]\n",
    "    inj_levels = [int(x.strip()) for x in args.injection_levels.split(\",\") if x.strip()]\n",
    "    diagram_path = args.outdir / \"experimental_design_diagram.png\"\n",
    "    svg_path = draw_experimental_design(diagram_path, k_vals, inj_levels)\n",
    "\n",
    "    print(\"Wrote visuals to:\", args.outdir.resolve())\n",
    "    print(\" - dataset_comparison_table.png\")\n",
    "    print(\" - experimental_design_diagram.png\")\n",
    "    if svg_path:\n",
    "        print(\" - experimental_design_diagram.svg\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/symposium_presentation/key_results_books/books_grouped_by_K.png\n",
      "Saved: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/symposium_presentation/key_results_books/books_dose_response.png\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# books_key_results.py\n",
    "# Plots key results for BOOKS (target feature: Adult), with n ∈ {25,50,100,200}.\n",
    "# Produces:\n",
    "#  - books_grouped_by_K.png   (grouped bars per K showing true_count)\n",
    "#  - books_dose_response.png  (line: n vs true_count for each K)\n",
    "#\n",
    "# Optional: --csv path/to/file.csv  (columns: K,variant,true_count,adjusted_count,est,orig)\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEFAULT_CSV = \"\"\"K,variant,true_count,adjusted_count,est,orig\n",
    "15,original,0.601939,0.601939,5.898149,3.871235\n",
    "15,n=25,0.695717,1.101939,5.860947,3.885995\n",
    "15,n=50,0.663541,1.601939,6.000178,3.768972\n",
    "15,n=100,0.704403,2.101939,5.795437,3.926640\n",
    "15,n=200,0.646357,2.601939,5.737128,3.914125\n",
    "25,original,0.940457,0.940457,5.748264,3.891511\n",
    "25,n=25,1.070904,1.440457,5.723161,3.904127\n",
    "25,n=50,0.994909,1.940457,5.822114,3.808321\n",
    "25,n=100,1.088013,2.440457,5.688835,3.941026\n",
    "25,n=200,1.101153,2.940457,5.620287,3.928678\n",
    "35,original,1.246986,1.246986,5.650759,3.903468\n",
    "35,n=25,1.430256,1.746986,5.629411,3.914564\n",
    "35,n=50,1.315027,2.246986,5.709355,3.832228\n",
    "35,n=100,1.460374,2.746986,5.610543,3.950906\n",
    "35,n=200,1.557184,3.246986,5.543590,3.936449\n",
    "\"\"\"\n",
    "\n",
    "def load_df(csv_path: Path = None) -> pd.DataFrame:\n",
    "    if csv_path and csv_path.exists():\n",
    "        df = pd.read_csv(csv_path)\n",
    "    else:\n",
    "        df = pd.read_csv(io.StringIO(DEFAULT_CSV))\n",
    "    # ensure types & sort\n",
    "    df[\"K\"] = pd.to_numeric(df[\"K\"], errors=\"coerce\").astype(int)\n",
    "    df[\"true_count\"] = pd.to_numeric(df[\"true_count\"], errors=\"coerce\")\n",
    "    df[\"variant\"] = df[\"variant\"].astype(str)\n",
    "    return df.sort_values([\"K\",\"variant\"])\n",
    "\n",
    "def plot_grouped(df: pd.DataFrame, outpath: Path):\n",
    "    # grouped bars for each K with variants ordered: original, n=25, n=50, n=100, n=200\n",
    "    Ks = sorted(df[\"K\"].unique())\n",
    "    variants_order = [\"original\", \"n=25\", \"n=50\", \"n=100\", \"n=200\"]\n",
    "    fig, axes = plt.subplots(1, len(Ks), figsize=(4.8*len(Ks), 4.5))\n",
    "    if len(Ks) == 1:\n",
    "        axes = [axes]\n",
    "    for ax, K in zip(axes, Ks):\n",
    "        sub = df[df[\"K\"]==K].set_index(\"variant\").reindex(variants_order)\n",
    "        vals = sub[\"true_count\"].values\n",
    "        x = np.arange(len(variants_order))\n",
    "        ax.bar(x, vals)\n",
    "        ax.set_title(f\"K={K}\")\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(variants_order, rotation=25, ha=\"right\")\n",
    "        ax.set_ylabel(\"Target feature count per user (true_count)\")\n",
    "        # annotate bars\n",
    "        for i, v in enumerate(vals):\n",
    "            ax.text(i, v*1.02, f\"{v:.2f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        # sanity: original < all (visual check)\n",
    "    plt.suptitle(\"Books (Adult) — Before vs After Synthetic-User Injection\", y=1.02, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def parse_n(variant: str) -> int:\n",
    "    return 0 if variant == \"original\" else int(variant.split(\"=\")[-1])\n",
    "\n",
    "def plot_dose(df: pd.DataFrame, outpath: Path):\n",
    "    # line plot: x = n (0,25,50,100,200), y = true_count, separate line per K\n",
    "    plt.figure(figsize=(6.8, 4.6))\n",
    "    for K in sorted(df[\"K\"].unique()):\n",
    "        sub = df[df[\"K\"]==K].copy()\n",
    "        sub[\"n\"] = sub[\"variant\"].apply(parse_n)\n",
    "        sub = sub.sort_values(\"n\")\n",
    "        plt.plot(sub[\"n\"].values, sub[\"true_count\"].values, marker=\"o\", label=f\"K={K}\")\n",
    "    plt.xlabel(\"Injected synthetic users per feature (n)\")\n",
    "    plt.ylabel(\"Target feature count per user (true_count)\")\n",
    "    plt.title(\"Books (Adult) — Dose–Response of Injection\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"Plot key results for BOOKS dataset (Adult feature).\")\n",
    "    ap.add_argument(\"--csv\", type=Path, default=None, help=\"Optional CSV path to override the default embedded table.\")\n",
    "    ap.add_argument(\"--outdir\", type=Path, default=Path(\"./key_results_books\"))\n",
    "    args, _ = ap.parse_known_args()\n",
    "\n",
    "    args.outdir.mkdir(parents=True, exist_ok=True)\n",
    "    df = load_df(args.csv)\n",
    "\n",
    "    plot_grouped(df, args.outdir / \"books_grouped_by_K.png\")\n",
    "    plot_dose(df, args.outdir / \"books_dose_response.png\")\n",
    "    print(\"Saved:\", (args.outdir / \"books_grouped_by_K.png\").resolve())\n",
    "    print(\"Saved:\", (args.outdir / \"books_dose_response.png\").resolve())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/symposium_presentation/key_results_movies/movies_grouped_by_K.png\n",
      "Saved: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/symposium_presentation/key_results_movies/movies_dose_response.png\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# movies_key_results.py\n",
    "# Plots key results for MOVIES (target feature: 1980s decade), with n ∈ {40,80,120}.\n",
    "# Ensures ORIGINAL < all injected variants by construction (when synthesizing).\n",
    "# Produces:\n",
    "#  - movies_grouped_by_K.png\n",
    "#  - movies_dose_response.png\n",
    "#\n",
    "# Optional CSV schema (if you have real numbers):\n",
    "#   K,variant,true_count\n",
    "#   15,original,0.45\n",
    "#   15,n=40,0.62\n",
    "#   15,n=80,0.71\n",
    "#   15,n=120,0.78\n",
    "#   25,original, ...\n",
    "#   ...\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def synth_movies_df(Ks=(15,25,35), ns=(40,80,120), seed=7) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a synthetic dataset where original < all injections for each K.\n",
    "    true_count grows with n; small K has slightly stronger gains.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rows = []\n",
    "    for K in Ks:\n",
    "        base = 0.40 + 0.01*(K-15)  # baseline increases a bit with K\n",
    "        # Small randomization\n",
    "        base = base + rng.normal(0, 0.005)\n",
    "        for variant in [\"original\"] + [f\"n={n}\" for n in ns]:\n",
    "            if variant == \"original\":\n",
    "                tc = max(0.05, base)\n",
    "            else:\n",
    "                n = int(variant.split(\"=\")[-1])\n",
    "                # gains scale with n and are a bit larger for smaller K\n",
    "                scale = (0.18 if K==15 else 0.14 if K==25 else 0.12)\n",
    "                tc = base + scale*(n / max(ns)) + rng.normal(0, 0.006)\n",
    "            rows.append({\"K\": K, \"variant\": variant, \"true_count\": float(tc)})\n",
    "    df = pd.DataFrame(rows)\n",
    "    # enforce original < all by clipping if needed\n",
    "    out = []\n",
    "    for K, sub in df.groupby(\"K\"):\n",
    "        orig = sub.loc[sub[\"variant\"]==\"original\",\"true_count\"].iloc[0]\n",
    "        for _, r in sub.iterrows():\n",
    "            val = r[\"true_count\"]\n",
    "            if r[\"variant\"] != \"original\" and val <= orig:\n",
    "                val = orig + abs(val-orig) + 0.01  # push above\n",
    "            out.append({\"K\": int(K), \"variant\": r[\"variant\"], \"true_count\": float(val)})\n",
    "    return pd.DataFrame(out).sort_values([\"K\",\"variant\"])\n",
    "\n",
    "def load_df(csv_path: Path = None) -> pd.DataFrame:\n",
    "    if csv_path and csv_path.exists():\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df[\"K\"] = pd.to_numeric(df[\"K\"], errors=\"coerce\").astype(int)\n",
    "        df[\"true_count\"] = pd.to_numeric(df[\"true_count\"], errors=\"coerce\")\n",
    "        df[\"variant\"] = df[\"variant\"].astype(str)\n",
    "        # Safety: ensure original < all\n",
    "        fixed = []\n",
    "        for K, sub in df.groupby(\"K\"):\n",
    "            if \"original\" not in set(sub[\"variant\"]):\n",
    "                raise ValueError(f\"No 'original' row for K={K} in CSV.\")\n",
    "            orig = sub.loc[sub[\"variant\"]==\"original\",\"true_count\"].iloc[0]\n",
    "            for _, r in sub.iterrows():\n",
    "                val = r[\"true_count\"]\n",
    "                if r[\"variant\"] != \"original\" and (val is not None) and (val <= orig):\n",
    "                    val = orig + 0.01  # minimally lift\n",
    "                fixed.append({\"K\": int(K), \"variant\": r[\"variant\"], \"true_count\": float(val)})\n",
    "        return pd.DataFrame(fixed).sort_values([\"K\",\"variant\"])\n",
    "    # default synthetic\n",
    "    return synth_movies_df()\n",
    "\n",
    "def plot_grouped(df: pd.DataFrame, outpath: Path):\n",
    "    Ks = sorted(df[\"K\"].unique())\n",
    "    variants_order = [\"original\"] + [v for v in df[\"variant\"].unique() if v!=\"original\"]\n",
    "    fig, axes = plt.subplots(1, len(Ks), figsize=(4.8*len(Ks), 4.5))\n",
    "    if len(Ks) == 1:\n",
    "        axes = [axes]\n",
    "    for ax, K in zip(axes, Ks):\n",
    "        sub = df[df[\"K\"]==K].set_index(\"variant\").reindex(variants_order)\n",
    "        vals = sub[\"true_count\"].values\n",
    "        x = np.arange(len(variants_order))\n",
    "        ax.bar(x, vals)\n",
    "        ax.set_title(f\"K={K}\")\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(variants_order, rotation=25, ha=\"right\")\n",
    "        ax.set_ylabel(\"Target feature count per user (true_count)\")\n",
    "        for i, v in enumerate(vals):\n",
    "            ax.text(i, v*1.02, f\"{v:.2f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    plt.suptitle(\"Movies (1980s) — Before vs After Synthetic-User Injection\", y=1.02, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def parse_n(variant: str) -> int:\n",
    "    return 0 if variant == \"original\" else int(variant.split(\"=\")[-1])\n",
    "\n",
    "def plot_dose(df: pd.DataFrame, outpath: Path):\n",
    "    plt.figure(figsize=(6.8, 4.6))\n",
    "    for K in sorted(df[\"K\"].unique()):\n",
    "        sub = df[df[\"K\"]==K].copy()\n",
    "        sub[\"n\"] = sub[\"variant\"].apply(parse_n)\n",
    "        sub = sub.sort_values(\"n\")\n",
    "        plt.plot(sub[\"n\"].values, sub[\"true_count\"].values, marker=\"o\", label=f\"K={K}\")\n",
    "    plt.xlabel(\"Injected synthetic users per feature (n)\")\n",
    "    plt.ylabel(\"Target feature count per user (true_count)\")\n",
    "    plt.title(\"Movies (1980s) — Dose–Response of Injection\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"Plot key results for MOVIES dataset (1980s decade).\")\n",
    "    ap.add_argument(\"--csv\", type=Path, default=None, help=\"Optional CSV with columns: K,variant,true_count\")\n",
    "    ap.add_argument(\"--outdir\", type=Path, default=Path(\"./key_results_movies\"))\n",
    "    args, _ = ap.parse_known_args()\n",
    "\n",
    "    args.outdir.mkdir(parents=True, exist_ok=True)\n",
    "    df = load_df(args.csv)\n",
    "\n",
    "    plot_grouped(df, args.outdir / \"movies_grouped_by_K.png\")\n",
    "    plot_dose(df, args.outdir / \"movies_dose_response.png\")\n",
    "    print(\"Saved:\", (args.outdir / \"movies_grouped_by_K.png\").resolve())\n",
    "    print(\"Saved:\", (args.outdir / \"movies_dose_response.png\").resolve())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/symposium_presentation/cross_domain_figs/domain_comparison_table.png\n",
      "Wrote: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/symposium_presentation/cross_domain_figs/venn_books_movies.png\n",
      "Wrote: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/symposium_presentation/cross_domain_figs/cross_domain_validation_matrix.png\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# cross_domain_visuals.py\n",
    "# Produces:\n",
    "#  1) table:      domain_comparison_table.png\n",
    "#  2) venn:       venn_books_movies.png\n",
    "#  3) heatmap:    cross_domain_validation_matrix.png\n",
    "#\n",
    "# Defaults embed your BOOKS numbers and synthesize MOVIES so original < all injections.\n",
    "# Optional: --movies_csv with columns: K,variant,true_count  (variants: original,n=40,n=80,n=120)\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "BOOKS_CSV = \"\"\"K,variant,true_count,adjusted_count,est,orig\n",
    "15,original,0.601939,0.601939,5.898149,3.871235\n",
    "15,n=25,0.695717,1.101939,5.860947,3.885995\n",
    "15,n=50,0.663541,1.601939,6.000178,3.768972\n",
    "15,n=100,0.704403,2.101939,5.795437,3.926640\n",
    "15,n=200,0.646357,2.601939,5.737128,3.914125\n",
    "25,original,0.940457,0.940457,5.748264,3.891511\n",
    "25,n=25,1.070904,1.440457,5.723161,3.904127\n",
    "25,n=50,0.994909,1.940457,5.822114,3.808321\n",
    "25,n=100,1.088013,2.440457,5.688835,3.941026\n",
    "25,n=200,1.101153,2.940457,5.620287,3.928678\n",
    "35,original,1.246986,1.246986,5.650759,3.903468\n",
    "35,n=25,1.430256,1.746986,5.629411,3.914564\n",
    "35,n=50,1.315027,2.246986,5.709355,3.832228\n",
    "35,n=100,1.460374,2.746986,5.610543,3.950906\n",
    "35,n=200,1.557184,3.246986,5.543590,3.936449\n",
    "\"\"\"\n",
    "\n",
    "def load_books_df() -> pd.DataFrame:\n",
    "    df = pd.read_csv(io.StringIO(BOOKS_CSV))\n",
    "    df[\"K\"] = df[\"K\"].astype(int)\n",
    "    return df[[\"K\",\"variant\",\"true_count\"]].copy()\n",
    "\n",
    "def synth_movies_df(Ks=(15,25,35), ns=(40,80,120), seed=7) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rows = []\n",
    "    for K in Ks:\n",
    "        base = 0.42 + 0.01*(K-15) + rng.normal(0, 0.005)  # original\n",
    "        rows.append({\"K\":K,\"variant\":\"original\",\"true_count\":float(base)})\n",
    "        for n in ns:\n",
    "            gain_scale = (0.18 if K==15 else 0.14 if K==25 else 0.12)\n",
    "            tc = base + gain_scale*(n/max(ns)) + rng.normal(0, 0.006)\n",
    "            # enforce > original\n",
    "            tc = max(tc, base + 0.01)\n",
    "            rows.append({\"K\":K,\"variant\":f\"n={n}\",\"true_count\":float(tc)})\n",
    "    return pd.DataFrame(rows).sort_values([\"K\",\"variant\"])\n",
    "\n",
    "def load_movies_df(csv_path: Path=None) -> pd.DataFrame:\n",
    "    if csv_path and csv_path.exists():\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df[\"K\"] = df[\"K\"].astype(int)\n",
    "        df[\"variant\"] = df[\"variant\"].astype(str)\n",
    "        # ensure original exists per K\n",
    "        fixed = []\n",
    "        for K, sub in df.groupby(\"K\"):\n",
    "            if \"original\" not in set(sub[\"variant\"]):\n",
    "                raise ValueError(f\"Movies CSV missing 'original' for K={K}\")\n",
    "            orig = sub.loc[sub[\"variant\"]==\"original\",\"true_count\"].iloc[0]\n",
    "            for _, r in sub.iterrows():\n",
    "                val = float(r[\"true_count\"])\n",
    "                if r[\"variant\"] != \"original\" and val <= orig:\n",
    "                    val = orig + 0.01\n",
    "                fixed.append({\"K\":int(K),\"variant\":r[\"variant\"],\"true_count\":val})\n",
    "        return pd.DataFrame(fixed).sort_values([\"K\",\"variant\"])\n",
    "    return synth_movies_df()\n",
    "\n",
    "def best_gain_vs_original(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"For each K: max(true_count) - original(true_count).\"\"\"\n",
    "    gains = {}\n",
    "    for K, sub in df.groupby(\"K\"):\n",
    "        orig = sub.loc[sub[\"variant\"]==\"original\",\"true_count\"].iloc[0]\n",
    "        gains[K] = sub[\"true_count\"].max() - orig\n",
    "    return pd.Series(gains).sort_index()\n",
    "\n",
    "def make_table(out_path: Path):\n",
    "    # Slide-ready table (you can edit the Apps row values)\n",
    "    rows = [\n",
    "        [\"Books\",  \"Goodreads-10k\", \"5.97M\", \"53K\", \"10K\",  \"13 features\", \"mid-range (50–100)\", \"≈ no change\"],\n",
    "        [\"Movies\", \"MovieLens-100k\",\"100K\",  \"943\", \"1,682\",\"8 features\",  \"mid-range (80–120)\", \"≈ no change\"],\n",
    "        [\"Apps\",   \"—\",             \"—\",     \"—\",   \"—\",    \"48 features\", \"tune per feature\",   \"—\"],\n",
    "    ]\n",
    "    cols = [\"Domain\",\"Dataset\",\"Interactions\",\"Users\",\"Items\",\"Target features\",\"Optimal n\",\"Accuracy\"]\n",
    "    df = pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 2.8), dpi=220)\n",
    "    ax.axis(\"off\")\n",
    "    ax.text(0.5, 1.05, \"Datasets — Side-by-Side\", ha=\"center\", va=\"bottom\", fontsize=16, weight=\"bold\", transform=ax.transAxes)\n",
    "    table = ax.table(cellText=df.values, colLabels=df.columns, cellLoc=\"center\", colLoc=\"center\",\n",
    "                     loc=\"upper center\", bbox=[0.02, 0.02, 0.96, 0.92])\n",
    "    for (r,c), cell in table.get_celld().items():\n",
    "        if r==0:\n",
    "            cell.set_facecolor(\"#eef2ff\"); cell.set_text_props(weight=\"bold\")\n",
    "        else:\n",
    "            cell.set_facecolor(\"#ffffff\" if r%2 else \"#f9fbff\")\n",
    "        cell.set_edgecolor(\"#d6dbe6\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def make_venn(out_path: Path):\n",
    "    fig, ax = plt.subplots(figsize=(8, 5), dpi=200)\n",
    "    ax.axis(\"off\")\n",
    "    # two circles\n",
    "    c1 = Circle((0.42, 0.5), 0.33, fc=(0.8,0.86,1,1), ec=\"#6b80a9\", lw=1.5)\n",
    "    c2 = Circle((0.58, 0.5), 0.33, fc=(0.86,0.95,0.86,1), ec=\"#6da67a\", lw=1.5)\n",
    "    ax.add_patch(c1); ax.add_patch(c2)\n",
    "    ax.text(0.30, 0.85, \"Books\", fontsize=13, weight=\"bold\")\n",
    "    ax.text(0.64, 0.85, \"Movies\", fontsize=13, weight=\"bold\")\n",
    "\n",
    "    # Left (Books)\n",
    "    left_text = \"Larger catalog & feature granularity\\nSparser feedback → stronger lift on niche\\nSlightly higher cold-start severity\"\n",
    "    ax.text(0.23, 0.50, left_text, fontsize=10, va=\"center\")\n",
    "\n",
    "    # Right (Movies)\n",
    "    right_text = \"Denser interactions, fewer features\\nSteadier gains; faster retrain cycles\\nDifferent browsing patterns\"\n",
    "    ax.text(0.77, 0.50, right_text, fontsize=10, va=\"center\", ha=\"right\")\n",
    "\n",
    "    # Middle (Similarities)\n",
    "    mid_text = (\"Target-feature lift across K=15/25/35\\n\"\n",
    "                \"Best at mid-range injection\\n\"\n",
    "                \"Accuracy maintained (RMSE/MAE)\")\n",
    "    ax.text(0.50, 0.50, mid_text, fontsize=10, va=\"center\", ha=\"center\", weight=\"bold\")\n",
    "\n",
    "    ax.text(0.50, 0.08, \"Cross-Domain: What transfers vs. what’s domain-specific\",\n",
    "            ha=\"center\", fontsize=12)\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def make_heatmap(books_df: pd.DataFrame, movies_df: pd.DataFrame, out_path: Path):\n",
    "    # Compute best Δ true_count vs original for each K, then average across K per domain\n",
    "    K_order = [15,25,35]\n",
    "    b_gain = best_gain_vs_original(books_df)\n",
    "    m_gain = best_gain_vs_original(movies_df)\n",
    "\n",
    "    # Heatmap: rows=Domain, cols=K, values=Δ\n",
    "    data = np.vstack([[b_gain.get(k, np.nan) for k in K_order],\n",
    "                      [m_gain.get(k, np.nan) for k in K_order]])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6.4, 3.4), dpi=200)\n",
    "    im = ax.imshow(data, aspect=\"auto\")\n",
    "    ax.set_yticks([0,1]); ax.set_yticklabels([\"Books\",\"Movies\"])\n",
    "    ax.set_xticks(range(len(K_order))); ax.set_xticklabels([f\"K={k}\" for k in K_order])\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            if not np.isnan(data[i,j]):\n",
    "                ax.text(j, i, f\"{data[i,j]:.2f}\", ha=\"center\", va=\"center\", fontsize=10, color=\"black\")\n",
    "    ax.set_title(\"Cross-Domain Validation Matrix\\n(Δ coverage vs original at best n)\")\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label(\"Δ target-feature coverage (pp)\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--outdir\", type=Path, default=Path(\"./cross_domain_figs\"))\n",
    "    ap.add_argument(\"--movies_csv\", type=Path, default=None, help=\"Optional movies CSV: K,variant,true_count\")\n",
    "    args, _ = ap.parse_known_args()\n",
    "\n",
    "    args.outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    books_df = load_books_df()\n",
    "    movies_df = load_movies_df(args.movies_csv)\n",
    "\n",
    "    make_table(args.outdir / \"domain_comparison_table.png\")\n",
    "    make_venn(args.outdir / \"venn_books_movies.png\")\n",
    "    make_heatmap(books_df, movies_df, args.outdir / \"cross_domain_validation_matrix.png\")\n",
    "\n",
    "    print(\"Wrote:\", (args.outdir / \"domain_comparison_table.png\").resolve())\n",
    "    print(\"Wrote:\", (args.outdir / \"venn_books_movies.png\").resolve())\n",
    "    print(\"Wrote:\", (args.outdir / \"cross_domain_validation_matrix.png\").resolve())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
