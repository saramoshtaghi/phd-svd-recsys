{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2273674/2272693250.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2273674/2272693250.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGENRES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mdf_uni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_unique_df_for_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# save per-genre outputs under figure/<GENRE>/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2273674/2272693250.py\u001b[0m in \u001b[0;36mbuild_unique_df_for_folder\u001b[0;34m(genre)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0morig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBASE_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"ORIGINAL_{K}recommendation.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mtot_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_unique_books_for_genre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[WARN] {genre} | K={K}: ORIGINAL missing/invalid -> {e}; skipping this K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2273674/2272693250.py\u001b[0m in \u001b[0;36mcount_unique_books_for_genre\u001b[0;34m(csv_path, target_genre_token)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{csv_path} missing columns: {missing}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_genre_for_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_genre_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGENRE_COL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_split_genres_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBOOK_COL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4431\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4432\u001b[0m         \"\"\"\n\u001b[0;32m-> 4433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4435\u001b[0m     def _reduce(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1144\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2273674/2272693250.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(cell)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{csv_path} missing columns: {missing}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_genre_for_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_genre_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGENRE_COL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_split_genres_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBOOK_COL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# UNIQUE BOOKS ONLY â€” single folder layout (no primary/enhanced)\n",
    "# Files like:\n",
    "#   ORIGINAL_<K>recommendation.csv\n",
    "#   enhanced_<Genre>_<RUN>_<K>recommendation.csv\n",
    "# Output per genre under: <BASE_DIR>/figure/<GENRE>/\n",
    "#   - <GENRE>_unique_totals.txt\n",
    "#   - <GENRE>_unique_totals.png\n",
    "# Plus a master file with all genres:\n",
    "#   - <BASE_DIR>/figure/ALL_unique_totals.txt\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================== CONFIG ======================\n",
    "BASE_DIR = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/postlift\")\n",
    "\n",
    "GENRE_COL = \"genres_all\"\n",
    "BOOK_COL  = \"book_id\"\n",
    "\n",
    "K_LIST = [15, 25, 35]\n",
    "RUNS   = [25, 400, 1000, 5000, 10000]   # match what's actually present in your folder listing\n",
    "# Genres as they appear in filenames (underscores ok)\n",
    "GENRES = [\n",
    "    \"Adult\", \"Adventure\", \"Children_s\", \"Classics\", \"Drama\", \"Fantasy\",\n",
    "    \"Historical\", \"Horror\", \"Mystery\", \"Nonfiction\", \"Romance\",\n",
    "    \"Science_Fiction\", \"Thriller\"\n",
    "]\n",
    "# ====================================================\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _normalize_genre_for_match(g: str) -> str:\n",
    "    x = g.strip().lower().replace(\"_\", \" \")\n",
    "    x = re.sub(r\"\\bchildren s\\b\", \"children's\", x)\n",
    "    return x\n",
    "\n",
    "def _split_genres_cell(cell):\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    parts = re.split(r\"[;,]\", str(cell))\n",
    "    return [_normalize_genre_for_match(p) for p in parts]\n",
    "\n",
    "def count_unique_books_for_genre(csv_path: Path, target_genre_token: str) -> int:\n",
    "    \"\"\"Count UNIQUE book_id values in this file whose genres include the target genre.\"\"\"\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(csv_path)\n",
    "    df = pd.read_csv(csv_path, usecols=lambda c: c in {BOOK_COL, GENRE_COL})\n",
    "    missing = {BOOK_COL, GENRE_COL} - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"{csv_path} missing columns: {missing}\")\n",
    "    tgt = _normalize_genre_for_match(target_genre_token)\n",
    "    mask = df[GENRE_COL].apply(lambda cell: tgt in _split_genres_cell(cell))\n",
    "    return df.loc[mask, BOOK_COL].nunique()\n",
    "\n",
    "def build_unique_df_for_folder(genre: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns tidy DF for this folder:\n",
    "      columns = ['genre','K','label','unique_books']\n",
    "      label âˆˆ {'ORIGINAL', f'n{run}' for run in RUNS}\n",
    "    If ORIGINAL_<K> is missing, that K is skipped entirely.\n",
    "    Missing variants are included with 0 to keep bar alignment.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for K in K_LIST:\n",
    "        # ORIGINAL\n",
    "        orig_path = BASE_DIR / f\"ORIGINAL_{K}recommendation.csv\"\n",
    "        try:\n",
    "            tot_orig = int(count_unique_books_for_genre(orig_path, genre))\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] {genre} | K={K}: ORIGINAL missing/invalid -> {e}; skipping this K\")\n",
    "            continue\n",
    "        rows.append({\"genre\": genre, \"K\": K, \"label\": \"ORIGINAL\", \"unique_books\": tot_orig})\n",
    "\n",
    "        # Variants enhanced_<Genre>_<RUN>_<K>\n",
    "        for n in RUNS:\n",
    "            var_path = BASE_DIR / f\"enhanced_{genre}_{n}_{K}recommendation.csv\"\n",
    "            try:\n",
    "                tot_var = int(count_unique_books_for_genre(var_path, genre))\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] {genre} | K={K} | n={n}: variant missing/invalid -> {e}; using 0\")\n",
    "                tot_var = 0\n",
    "            rows.append({\"genre\": genre, \"K\": K, \"label\": f\"n{n}\", \"unique_books\": tot_var})\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"genre\",\"K\",\"label\",\"unique_books\"])\n",
    "\n",
    "def _labels():\n",
    "    # dynamic label order for plotting/printing\n",
    "    return [\"ORIGINAL\"] + [f\"n{n}\" for n in RUNS]\n",
    "\n",
    "def make_genre_summary_lines(genre: str, df_uni: pd.DataFrame, include_header: bool) -> list[str]:\n",
    "    \"\"\"Build the lines that describe this genre's unique-book totals.\"\"\"\n",
    "    labels = _labels()\n",
    "    lines = []\n",
    "    if include_header:\n",
    "        lines.append(f\"[{genre}]\")\n",
    "    for K in sorted(df_uni[\"K\"].unique()):\n",
    "        sub = df_uni[df_uni[\"K\"] == K]\n",
    "        for lab in labels:\n",
    "            v = sub[sub[\"label\"] == lab][\"unique_books\"]\n",
    "            if v.empty:\n",
    "                continue\n",
    "            lines.append(f\"K={K} | {lab} unique_books: {int(v.iloc[0])}\")\n",
    "        lines.append(\"\")\n",
    "    return lines\n",
    "\n",
    "def write_txt_unique_per_genre(df_uni: pd.DataFrame, out_txt: Path, genre: str):\n",
    "    \"\"\"Write the per-genre TXT (no header to match your original style).\"\"\"\n",
    "    lines = make_genre_summary_lines(genre, df_uni, include_header=False)\n",
    "    ensure_dir(out_txt.parent)\n",
    "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "def plot_grouped_unique(df_uni: pd.DataFrame, title: str, out_png: Path):\n",
    "    \"\"\"Grouped bar chart: x=K, bars=ORIGINAL + dynamic RUN labels; y=unique book count.\"\"\"\n",
    "    if df_uni.empty:\n",
    "        print(f\"[INFO] Nothing to plot for {title}\")\n",
    "        return\n",
    "    labels = _labels()\n",
    "    K_vals = sorted(df_uni[\"K\"].unique().tolist())\n",
    "    series = {lab: [] for lab in labels}\n",
    "    for K in K_vals:\n",
    "        sub = df_uni[df_uni[\"K\"] == K]\n",
    "        for lab in labels:\n",
    "            row = sub[sub[\"label\"] == lab]\n",
    "            series[lab].append(int(row[\"unique_books\"].iloc[0]) if not row.empty else 0)\n",
    "\n",
    "    x = list(range(len(K_vals)))\n",
    "    n_series = len(labels)\n",
    "    width = 0.8 / n_series\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    for i, lab in enumerate(labels):\n",
    "        xs = [xx + (i - (n_series-1)/2.0)*width for xx in x]\n",
    "        ax.bar(xs, series[lab], width, label=lab)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f\"K={K}\" for K in K_vals])\n",
    "    ax.set_xlabel(\"K\")\n",
    "    ax.set_ylabel(\"Unique books with target genre\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"y\", alpha=0.2)\n",
    "\n",
    "    ensure_dir(out_png.parent)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "def main():\n",
    "    all_lines = []  # accumulate for master file\n",
    "    master_txt = BASE_DIR / \"figure\" / \"ALL_unique_totals.txt\"\n",
    "    ensure_dir(master_txt.parent)\n",
    "\n",
    "    for g in GENRES:\n",
    "        df_uni = build_unique_df_for_folder(g)\n",
    "\n",
    "        # save per-genre outputs under figure/<GENRE>/\n",
    "        out_dir = BASE_DIR / \"figure\" / g\n",
    "        txt_path = out_dir / f\"{g}_unique_totals.txt\"\n",
    "        png_path = out_dir / f\"{g}_unique_totals.png\"\n",
    "\n",
    "        # Write individual TXT (no header) and PNG\n",
    "        write_txt_unique_per_genre(df_uni, txt_path, g)\n",
    "        plot_grouped_unique(df_uni, title=f\"{g} â€“ UNIQUE books (no clustering)\", out_png=png_path)\n",
    "        print(f\"[OK] Wrote {txt_path} and {png_path}\")\n",
    "\n",
    "        # Append this genre's block (with header) to the master list\n",
    "        all_lines.extend(make_genre_summary_lines(g, df_uni, include_header=True))\n",
    "\n",
    "    # Write the combined master TXT once at the end\n",
    "    with open(master_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(all_lines))\n",
    "    print(f\"[OK] Wrote master summary â†’ {master_txt}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Adult/Adult_unique_totals.txt and /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Adult/Adult_unique_totals.png\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Adventure/Adventure_unique_totals.txt and /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Adventure/Adventure_unique_totals.png\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Children_s/Children_s_unique_totals.txt and /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Children_s/Children_s_unique_totals.png\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Classics/Classics_unique_totals.txt and /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Classics/Classics_unique_totals.png\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Drama/Drama_unique_totals.txt and /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Drama/Drama_unique_totals.png\n",
      "[WARN] Fantasy | K=15 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Fantasy_25_15recommendation.csv; using 0\n",
      "[WARN] Fantasy | K=15 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Fantasy_400_15recommendation.csv; using 0\n",
      "[WARN] Fantasy | K=15 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Fantasy_5000_15recommendation.csv; using 0\n",
      "[WARN] Fantasy | K=15 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Fantasy_10000_15recommendation.csv; using 0\n",
      "[WARN] Fantasy | K=25 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Fantasy_25_25recommendation.csv; using 0\n",
      "[WARN] Fantasy | K=25 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Fantasy_400_25recommendation.csv; using 0\n",
      "[WARN] Fantasy | K=25 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Fantasy_5000_25recommendation.csv; using 0\n",
      "[WARN] Fantasy | K=25 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Fantasy_10000_25recommendation.csv; using 0\n",
      "[WARN] Fantasy | K=35 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Fantasy_25_35recommendation.csv; using 0\n",
      "[WARN] Fantasy | K=35 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Fantasy_400_35recommendation.csv; using 0\n",
      "[WARN] Fantasy | K=35 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Fantasy_5000_35recommendation.csv; using 0\n",
      "[WARN] Fantasy | K=35 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Fantasy_10000_35recommendation.csv; using 0\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Fantasy/Fantasy_unique_totals.txt and /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Fantasy/Fantasy_unique_totals.png\n",
      "[WARN] Historical | K=15 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Historical_1000_15recommendation.csv; using 0\n",
      "[WARN] Historical | K=25 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Historical_1000_25recommendation.csv; using 0\n",
      "[WARN] Historical | K=35 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Historical_1000_35recommendation.csv; using 0\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Historical/Historical_unique_totals.txt and /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Historical/Historical_unique_totals.png\n",
      "[WARN] Horror | K=15 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Horror_1000_15recommendation.csv; using 0\n",
      "[WARN] Horror | K=25 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Horror_1000_25recommendation.csv; using 0\n",
      "[WARN] Horror | K=35 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Horror_1000_35recommendation.csv; using 0\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Horror/Horror_unique_totals.txt and /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Horror/Horror_unique_totals.png\n",
      "[WARN] Mystery | K=15 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Mystery_25_15recommendation.csv; using 0\n",
      "[WARN] Mystery | K=15 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Mystery_400_15recommendation.csv; using 0\n",
      "[WARN] Mystery | K=15 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Mystery_5000_15recommendation.csv; using 0\n",
      "[WARN] Mystery | K=15 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Mystery_10000_15recommendation.csv; using 0\n",
      "[WARN] Mystery | K=25 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Mystery_25_25recommendation.csv; using 0\n",
      "[WARN] Mystery | K=25 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Mystery_400_25recommendation.csv; using 0\n",
      "[WARN] Mystery | K=25 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Mystery_5000_25recommendation.csv; using 0\n",
      "[WARN] Mystery | K=25 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Mystery_10000_25recommendation.csv; using 0\n",
      "[WARN] Mystery | K=35 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Mystery_25_35recommendation.csv; using 0\n",
      "[WARN] Mystery | K=35 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Mystery_400_35recommendation.csv; using 0\n",
      "[WARN] Mystery | K=35 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Mystery_5000_35recommendation.csv; using 0\n",
      "[WARN] Mystery | K=35 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Mystery_10000_35recommendation.csv; using 0\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Mystery/Mystery_unique_totals.txt and /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Mystery/Mystery_unique_totals.png\n",
      "[WARN] Nonfiction | K=15 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_25_15recommendation.csv; using 0\n",
      "[WARN] Nonfiction | K=15 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_400_15recommendation.csv; using 0\n",
      "[WARN] Nonfiction | K=15 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_1000_15recommendation.csv; using 0\n",
      "[WARN] Nonfiction | K=15 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_5000_15recommendation.csv; using 0\n",
      "[WARN] Nonfiction | K=15 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_10000_15recommendation.csv; using 0\n",
      "[WARN] Nonfiction | K=25 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_25_25recommendation.csv; using 0\n",
      "[WARN] Nonfiction | K=25 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_400_25recommendation.csv; using 0\n",
      "[WARN] Nonfiction | K=25 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_1000_25recommendation.csv; using 0\n",
      "[WARN] Nonfiction | K=25 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_5000_25recommendation.csv; using 0\n",
      "[WARN] Nonfiction | K=25 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_10000_25recommendation.csv; using 0\n",
      "[WARN] Nonfiction | K=35 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_25_35recommendation.csv; using 0\n",
      "[WARN] Nonfiction | K=35 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_400_35recommendation.csv; using 0\n",
      "[WARN] Nonfiction | K=35 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_1000_35recommendation.csv; using 0\n",
      "[WARN] Nonfiction | K=35 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_5000_35recommendation.csv; using 0\n",
      "[WARN] Nonfiction | K=35 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Nonfiction_10000_35recommendation.csv; using 0\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Nonfiction/Nonfiction_unique_totals.txt and /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Nonfiction/Nonfiction_unique_totals.png\n",
      "[WARN] Romance | K=15 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_25_15recommendation.csv; using 0\n",
      "[WARN] Romance | K=15 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_400_15recommendation.csv; using 0\n",
      "[WARN] Romance | K=15 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_1000_15recommendation.csv; using 0\n",
      "[WARN] Romance | K=15 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_5000_15recommendation.csv; using 0\n",
      "[WARN] Romance | K=15 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_10000_15recommendation.csv; using 0\n",
      "[WARN] Romance | K=25 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_25_25recommendation.csv; using 0\n",
      "[WARN] Romance | K=25 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_400_25recommendation.csv; using 0\n",
      "[WARN] Romance | K=25 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_1000_25recommendation.csv; using 0\n",
      "[WARN] Romance | K=25 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_5000_25recommendation.csv; using 0\n",
      "[WARN] Romance | K=25 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_10000_25recommendation.csv; using 0\n",
      "[WARN] Romance | K=35 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_25_35recommendation.csv; using 0\n",
      "[WARN] Romance | K=35 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_400_35recommendation.csv; using 0\n",
      "[WARN] Romance | K=35 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_1000_35recommendation.csv; using 0\n",
      "[WARN] Romance | K=35 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_5000_35recommendation.csv; using 0\n",
      "[WARN] Romance | K=35 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Romance_10000_35recommendation.csv; using 0\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Romance/Romance_unique_totals.txt and /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Romance/Romance_unique_totals.png\n",
      "[WARN] Science_Fiction | K=15 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_25_15recommendation.csv; using 0\n",
      "[WARN] Science_Fiction | K=15 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_400_15recommendation.csv; using 0\n",
      "[WARN] Science_Fiction | K=15 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_1000_15recommendation.csv; using 0\n",
      "[WARN] Science_Fiction | K=15 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_5000_15recommendation.csv; using 0\n",
      "[WARN] Science_Fiction | K=15 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_10000_15recommendation.csv; using 0\n",
      "[WARN] Science_Fiction | K=25 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_25_25recommendation.csv; using 0\n",
      "[WARN] Science_Fiction | K=25 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_400_25recommendation.csv; using 0\n",
      "[WARN] Science_Fiction | K=25 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_1000_25recommendation.csv; using 0\n",
      "[WARN] Science_Fiction | K=25 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_5000_25recommendation.csv; using 0\n",
      "[WARN] Science_Fiction | K=25 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_10000_25recommendation.csv; using 0\n",
      "[WARN] Science_Fiction | K=35 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_25_35recommendation.csv; using 0\n",
      "[WARN] Science_Fiction | K=35 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_400_35recommendation.csv; using 0\n",
      "[WARN] Science_Fiction | K=35 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_1000_35recommendation.csv; using 0\n",
      "[WARN] Science_Fiction | K=35 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_5000_35recommendation.csv; using 0\n",
      "[WARN] Science_Fiction | K=35 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Science_Fiction_10000_35recommendation.csv; using 0\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Science_Fiction/Science_Fiction_unique_totals.txt and /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Science_Fiction/Science_Fiction_unique_totals.png\n",
      "[WARN] Thriller | K=15 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_25_15recommendation.csv; using 0\n",
      "[WARN] Thriller | K=15 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_400_15recommendation.csv; using 0\n",
      "[WARN] Thriller | K=15 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_1000_15recommendation.csv; using 0\n",
      "[WARN] Thriller | K=15 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_5000_15recommendation.csv; using 0\n",
      "[WARN] Thriller | K=15 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_10000_15recommendation.csv; using 0\n",
      "[WARN] Thriller | K=25 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_25_25recommendation.csv; using 0\n",
      "[WARN] Thriller | K=25 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_400_25recommendation.csv; using 0\n",
      "[WARN] Thriller | K=25 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_1000_25recommendation.csv; using 0\n",
      "[WARN] Thriller | K=25 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_5000_25recommendation.csv; using 0\n",
      "[WARN] Thriller | K=25 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_10000_25recommendation.csv; using 0\n",
      "[WARN] Thriller | K=35 | n=25: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_25_35recommendation.csv; using 0\n",
      "[WARN] Thriller | K=35 | n=400: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_400_35recommendation.csv; using 0\n",
      "[WARN] Thriller | K=35 | n=1000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_1000_35recommendation.csv; using 0\n",
      "[WARN] Thriller | K=35 | n=5000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_5000_35recommendation.csv; using 0\n",
      "[WARN] Thriller | K=35 | n=10000: variant missing/invalid -> /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/enhanced_Thriller_10000_35recommendation.csv; using 0\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Thriller/Thriller_unique_totals.txt and /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/Thriller/Thriller_unique_totals.png\n",
      "[OK] Wrote master summary â†’ /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack/figure/ALL_unique_totals.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# UNIQUE BOOKS ONLY â€” single folder layout (no primary/enhanced)\n",
    "# Files like:\n",
    "#   ORIGINAL_<K>recommendation.csv\n",
    "#   enhanced_<Genre>_<RUN>_<K>recommendation.csv\n",
    "# Output per genre under: <BASE_DIR>/figure/<GENRE>/\n",
    "#   - <GENRE>_unique_totals.txt\n",
    "#   - <GENRE>_unique_totals.png\n",
    "# Plus a master file with all genres:\n",
    "#   - <BASE_DIR>/figure/ALL_unique_totals.txt\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================== CONFIG ======================\n",
    "BASE_DIR = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0928/SVD/attack\")\n",
    "\n",
    "GENRE_COL = \"genres_all\"\n",
    "BOOK_COL  = \"book_id\"\n",
    "\n",
    "K_LIST = [15, 25, 35]\n",
    "RUNS   = [25, 400, 1000, 5000, 10000]   # match what's actually present in your folder listing\n",
    "# Genres as they appear in filenames (underscores ok)\n",
    "GENRES = [\n",
    "    \"Adult\", \"Adventure\", \"Children_s\", \"Classics\", \"Drama\", \"Fantasy\",\n",
    "    \"Historical\", \"Horror\", \"Mystery\", \"Nonfiction\", \"Romance\",\n",
    "    \"Science_Fiction\", \"Thriller\"\n",
    "]\n",
    "# ====================================================\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _normalize_genre_for_match(g: str) -> str:\n",
    "    x = g.strip().lower().replace(\"_\", \" \")\n",
    "    x = re.sub(r\"\\bchildren s\\b\", \"children's\", x)\n",
    "    return x\n",
    "\n",
    "def _split_genres_cell(cell):\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    parts = re.split(r\"[;,]\", str(cell))\n",
    "    return [_normalize_genre_for_match(p) for p in parts]\n",
    "\n",
    "def count_unique_books_for_genre(csv_path: Path, target_genre_token: str) -> int:\n",
    "    \"\"\"Count UNIQUE book_id values in this file whose genres include the target genre.\"\"\"\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(csv_path)\n",
    "    df = pd.read_csv(csv_path, usecols=lambda c: c in {BOOK_COL, GENRE_COL})\n",
    "    missing = {BOOK_COL, GENRE_COL} - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"{csv_path} missing columns: {missing}\")\n",
    "    tgt = _normalize_genre_for_match(target_genre_token)\n",
    "    mask = df[GENRE_COL].apply(lambda cell: tgt in _split_genres_cell(cell))\n",
    "    return df.loc[mask, BOOK_COL].nunique()\n",
    "\n",
    "def build_unique_df_for_folder(genre: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns tidy DF for this folder:\n",
    "      columns = ['genre','K','label','unique_books']\n",
    "      label âˆˆ {'ORIGINAL', f'n{run}' for run in RUNS}\n",
    "    If ORIGINAL_<K> is missing, that K is skipped entirely.\n",
    "    Missing variants are included with 0 to keep bar alignment.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for K in K_LIST:\n",
    "        # ORIGINAL\n",
    "        orig_path = BASE_DIR / f\"ORIGINAL_{K}recommendation.csv\"\n",
    "        try:\n",
    "            tot_orig = int(count_unique_books_for_genre(orig_path, genre))\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] {genre} | K={K}: ORIGINAL missing/invalid -> {e}; skipping this K\")\n",
    "            continue\n",
    "        rows.append({\"genre\": genre, \"K\": K, \"label\": \"ORIGINAL\", \"unique_books\": tot_orig})\n",
    "\n",
    "        # Variants enhanced_<Genre>_<RUN>_<K>\n",
    "        for n in RUNS:\n",
    "            var_path = BASE_DIR / f\"enhanced_{genre}_{n}_{K}recommendation.csv\"\n",
    "            try:\n",
    "                tot_var = int(count_unique_books_for_genre(var_path, genre))\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] {genre} | K={K} | n={n}: variant missing/invalid -> {e}; using 0\")\n",
    "                tot_var = 0\n",
    "            rows.append({\"genre\": genre, \"K\": K, \"label\": f\"n{n}\", \"unique_books\": tot_var})\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"genre\",\"K\",\"label\",\"unique_books\"])\n",
    "\n",
    "def _labels():\n",
    "    # dynamic label order for plotting/printing\n",
    "    return [\"ORIGINAL\"] + [f\"n{n}\" for n in RUNS]\n",
    "\n",
    "def make_genre_summary_lines(genre: str, df_uni: pd.DataFrame, include_header: bool) -> list[str]:\n",
    "    \"\"\"Build the lines that describe this genre's unique-book totals.\"\"\"\n",
    "    labels = _labels()\n",
    "    lines = []\n",
    "    if include_header:\n",
    "        lines.append(f\"[{genre}]\")\n",
    "    for K in sorted(df_uni[\"K\"].unique()):\n",
    "        sub = df_uni[df_uni[\"K\"] == K]\n",
    "        for lab in labels:\n",
    "            v = sub[sub[\"label\"] == lab][\"unique_books\"]\n",
    "            if v.empty:\n",
    "                continue\n",
    "            lines.append(f\"K={K} | {lab} unique_books: {int(v.iloc[0])}\")\n",
    "        lines.append(\"\")\n",
    "    return lines\n",
    "\n",
    "def write_txt_unique_per_genre(df_uni: pd.DataFrame, out_txt: Path, genre: str):\n",
    "    \"\"\"Write the per-genre TXT (no header to match your original style).\"\"\"\n",
    "    lines = make_genre_summary_lines(genre, df_uni, include_header=False)\n",
    "    ensure_dir(out_txt.parent)\n",
    "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "def plot_grouped_unique(df_uni: pd.DataFrame, title: str, out_png: Path):\n",
    "    \"\"\"Grouped bar chart: x=K, bars=ORIGINAL + dynamic RUN labels; y=unique book count.\"\"\"\n",
    "    if df_uni.empty:\n",
    "        print(f\"[INFO] Nothing to plot for {title}\")\n",
    "        return\n",
    "    labels = _labels()\n",
    "    K_vals = sorted(df_uni[\"K\"].unique().tolist())\n",
    "    series = {lab: [] for lab in labels}\n",
    "    for K in K_vals:\n",
    "        sub = df_uni[df_uni[\"K\"] == K]\n",
    "        for lab in labels:\n",
    "            row = sub[sub[\"label\"] == lab]\n",
    "            series[lab].append(int(row[\"unique_books\"].iloc[0]) if not row.empty else 0)\n",
    "\n",
    "    x = list(range(len(K_vals)))\n",
    "    n_series = len(labels)\n",
    "    width = 0.8 / n_series\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    for i, lab in enumerate(labels):\n",
    "        xs = [xx + (i - (n_series-1)/2.0)*width for xx in x]\n",
    "        ax.bar(xs, series[lab], width, label=lab)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f\"K={K}\" for K in K_vals])\n",
    "    ax.set_xlabel(\"K\")\n",
    "    ax.set_ylabel(\"Unique books with target genre\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"y\", alpha=0.2)\n",
    "\n",
    "    ensure_dir(out_png.parent)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "def main():\n",
    "    all_lines = []  # accumulate for master file\n",
    "    master_txt = BASE_DIR / \"figure\" / \"ALL_unique_totals.txt\"\n",
    "    ensure_dir(master_txt.parent)\n",
    "\n",
    "    for g in GENRES:\n",
    "        df_uni = build_unique_df_for_folder(g)\n",
    "\n",
    "        # save per-genre outputs under figure/<GENRE>/\n",
    "        out_dir = BASE_DIR / \"figure\" / g\n",
    "        txt_path = out_dir / f\"{g}_unique_totals.txt\"\n",
    "        png_path = out_dir / f\"{g}_unique_totals.png\"\n",
    "\n",
    "        # Write individual TXT (no header) and PNG\n",
    "        write_txt_unique_per_genre(df_uni, txt_path, g)\n",
    "        plot_grouped_unique(df_uni, title=f\"{g} â€“ UNIQUE books (no clustering)\", out_png=png_path)\n",
    "        print(f\"[OK] Wrote {txt_path} and {png_path}\")\n",
    "\n",
    "        # Append this genre's block (with header) to the master list\n",
    "        all_lines.extend(make_genre_summary_lines(g, df_uni, include_header=True))\n",
    "\n",
    "    # Write the combined master TXT once at the end\n",
    "    with open(master_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(all_lines))\n",
    "    print(f\"[OK] Wrote master summary â†’ {master_txt}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
