{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adult_25_15recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adult_25_15recommendation.csv\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adult_50_15recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adult_50_15recommendation.csv\n",
      "[OK] Saved: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/figure/Adult_K15_primary.png\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adult_25_25recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adult_25_25recommendation.csv\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adult_50_25recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adult_50_25recommendation.csv\n",
      "[OK] Saved: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/figure/Adult_K25_primary.png\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adult_25_35recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adult_25_35recommendation.csv\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adult_50_35recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adult_50_35recommendation.csv\n",
      "[OK] Saved: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/figure/Adult_K35_primary.png\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_25_15recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_25_15recommendation.csv\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_50_15recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_50_15recommendation.csv\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_100_15recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_100_15recommendation.csv\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_200_15recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_200_15recommendation.csv\n",
      "[OK] Saved: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/figure/Adventure_K15_primary.png\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_25_25recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_25_25recommendation.csv\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_50_25recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_50_25recommendation.csv\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_100_25recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_100_25recommendation.csv\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_200_25recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_200_25recommendation.csv\n",
      "[OK] Saved: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/figure/Adventure_K25_primary.png\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_25_35recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_25_35recommendation.csv\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_50_35recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_50_35recommendation.csv\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_100_35recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_100_35recommendation.csv\n",
      "[WARN] Missing/invalid: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_200_35recommendation.csv -> Missing file: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/p_Adventure_200_35recommendation.csv\n",
      "[OK] Saved: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0926/SVD/figure/Adventure_K35_primary.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_451798/3571312762.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_451798/3571312762.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0mbuild_primary_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# logs + figures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0mcollect_summary_primary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# tidy CSV with averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_451798/3571312762.py\u001b[0m in \u001b[0;36mbuild_primary_outputs\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0moriginal_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPRIMARY_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"ORIGINAL_{K}recommendation.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 \u001b[0ms_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_genre_per_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[WARN] Skip {g} K={K}: cannot load ORIGINAL -> {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_451798/3571312762.py\u001b[0m in \u001b[0;36mcount_genre_per_user\u001b[0;34m(csv_path, target_genre_token)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{csv_path} must contain '{USER_COL}' and '{GENRE_COL}'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_genre_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_hit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGENRE_COL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_genres_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUSER_COL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_hit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4431\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4432\u001b[0m         \"\"\"\n\u001b[0;32m-> 4433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4435\u001b[0m     def _reduce(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1144\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_451798/3571312762.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(cell)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{csv_path} must contain '{USER_COL}' and '{GENRE_COL}'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_genre_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_hit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGENRE_COL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_genres_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUSER_COL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_hit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_451798/3571312762.py\u001b[0m in \u001b[0;36msplit_genres_cell\u001b[0;34m(cell)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"[;,]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnormalize_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcount_genre_per_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_genre_token\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_451798/3571312762.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"[;,]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnormalize_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcount_genre_per_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_genre_token\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_451798/3571312762.py\u001b[0m in \u001b[0;36mnormalize_token\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;34m\"\"\"Normalize a genre token for matching inside CSV cells.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\bchildren s\\b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"children's\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Merge of: (1) avg summary builder + (2) per-genre logging + bin plots\n",
    "# Single dataset: PRIMARY only\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================== CONFIG ======================\n",
    "BASE_DIR   = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0927/SVD\")\n",
    "PRIMARY_DIR = BASE_DIR  # files live directly here\n",
    "\n",
    "USER_COL  = \"user_id\"\n",
    "GENRE_COL = \"genres_all\"\n",
    "\n",
    "K_LIST   = [15, 25, 35]\n",
    "RUNS     = [25, 50, 100, 200]\n",
    "NUM_BINS = 10\n",
    "\n",
    "GENRES = [\n",
    "    \"Adult\", \"Adventure\", \"Children_s\", \"Classics\", \"Drama\", \"Fantasy\",\n",
    "    \"Historical\", \"Horror\", \"Mystery\", \"Nonfiction\", \"Romance\",\n",
    "    \"Science_Fiction\", \"Thriller\"\n",
    "]\n",
    "# ====================================================\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def normalize_token(s: str) -> str:\n",
    "    \"\"\"Normalize a genre token for matching inside CSV cells.\"\"\"\n",
    "    x = s.strip().lower().replace(\"_\", \" \")\n",
    "    x = re.sub(r\"\\bchildren s\\b\", \"children's\", x)\n",
    "    return x\n",
    "\n",
    "def split_genres_cell(cell) -> list:\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    parts = re.split(r\"[;,]\", str(cell))\n",
    "    return [normalize_token(p) for p in parts]\n",
    "\n",
    "def count_genre_per_user(csv_path: Path, target_genre_token: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns a Series indexed by user_id with the COUNT of rows whose 'genres_all'\n",
    "    include the target genre.\n",
    "    \"\"\"\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing file: {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if USER_COL not in df.columns or GENRE_COL not in df.columns:\n",
    "        raise ValueError(f\"{csv_path} must contain '{USER_COL}' and '{GENRE_COL}'.\")\n",
    "    tgt = normalize_token(target_genre_token)\n",
    "    df[\"_hit\"] = df[GENRE_COL].apply(lambda cell: int(tgt in split_genres_cell(cell)))\n",
    "    return df.groupby(USER_COL)[\"_hit\"].sum()\n",
    "\n",
    "def summarize_one(file_path: Path, genre: str):\n",
    "    \"\"\"\n",
    "    Returns (users, total_hits, mean_per_user) for one CSV/genre.\n",
    "    If file missing, returns None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s = count_genre_per_user(file_path, genre)\n",
    "    except (FileNotFoundError, ValueError):\n",
    "        return None\n",
    "    users = int(s.shape[0])\n",
    "    total = int(s.sum())\n",
    "    mean = (total / users) if users else 0.0\n",
    "    return users, total, float(mean)\n",
    "\n",
    "def intersect_users(series_list):\n",
    "    \"\"\"Intersection of indices across non-empty series.\"\"\"\n",
    "    series_list = [s for s in series_list if s is not None and len(s) > 0]\n",
    "    if not series_list:\n",
    "        return pd.Index([])\n",
    "    inter = series_list[0].index\n",
    "    for s in series_list[1:]:\n",
    "        inter = inter.intersection(s.index)\n",
    "    return inter\n",
    "\n",
    "def compute_bin_means(original_s: pd.Series, variant_series: dict, num_bins=10) -> dict:\n",
    "    \"\"\"Sort users by ORIGINAL desc, split into bins, average per bin.\"\"\"\n",
    "    sorted_users = original_s.sort_values(ascending=False).index.tolist()\n",
    "    n = len(sorted_users)\n",
    "    if n == 0:\n",
    "        return {lab: [0.0]*num_bins for lab in [\"ORIGINAL\", *variant_series.keys()]}\n",
    "    bins = []\n",
    "    base = n // num_bins\n",
    "    rem = n % num_bins\n",
    "    start = 0\n",
    "    for i in range(num_bins):\n",
    "        size = base + (1 if i < rem else 0)\n",
    "        end = start + size\n",
    "        bins.append(sorted_users[start:end])\n",
    "        start = end\n",
    "    out = {}\n",
    "    out[\"ORIGINAL\"] = [float(original_s.loc[b].mean()) if b else 0.0 for b in bins]\n",
    "    for lab, s in variant_series.items():\n",
    "        out[lab] = [float(s.loc[b].mean()) if b else 0.0 for b in bins]\n",
    "    return out\n",
    "\n",
    "def plot_grouped_bars(bin_stats: dict, title: str, out_path: Path):\n",
    "    labels = list(bin_stats.keys())  # [\"ORIGINAL\", \"25\", \"50\", \"100\", \"200\"]\n",
    "    x = np.arange(NUM_BINS)\n",
    "    n_series = len(labels)\n",
    "    width = 0.8 / n_series\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    for i, lab in enumerate(labels):\n",
    "        offsets = (i - (n_series-1)/2.0) * width\n",
    "        ax.bar(x + offsets, bin_stats[lab], width, label=lab)\n",
    "    ax.set_xlabel(\"User bins (sorted by ORIGINAL genre count, high → low)\")\n",
    "    ax.set_ylabel(\"Avg count of target-genre items per user\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f\"Bin {i+1}\" for i in range(NUM_BINS)], rotation=0)\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"y\", alpha=0.2)\n",
    "    ensure_dir(out_path.parent)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "def log_genre_counts(folder_dir: Path, genre: str, K: int,\n",
    "                     total_original: int, totals_variants: dict,\n",
    "                     n_users_original: int, n_users_variants: dict):\n",
    "    \"\"\"\n",
    "    Append per-genre totals (and means) to one summary text file in PRIMARY_DIR.\n",
    "    \"\"\"\n",
    "    log_path = folder_dir / \"genre_counts_summary.txt\"\n",
    "    pretty_g = genre.replace(\"_\", \" \").replace(\"Children s\", \"Children's\")\n",
    "    lines = []\n",
    "    mean_o = total_original / n_users_original if n_users_original else 0.0\n",
    "    lines.append(\n",
    "        f\"primary_ {pretty_g} | K={K} | ORIGINAL: total={int(total_original)}, users={n_users_original}, mean_per_user={mean_o:.4f}\"\n",
    "    )\n",
    "    for lab in [\"25\", \"50\", \"100\", \"200\"]:\n",
    "        tot = int(totals_variants.get(lab, 0))\n",
    "        n_u = int(n_users_variants.get(lab, 0))\n",
    "        mean_v = (tot / n_u) if n_u else 0.0\n",
    "        lines.append(\n",
    "            f\"primary_ {pretty_g} | K={K} | {lab}: total={tot}, users={n_u}, mean_per_user={mean_v:.4f}\"\n",
    "        )\n",
    "    lines.append(\"\")  # spacer\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "def build_primary_outputs():\n",
    "    \"\"\"\n",
    "    For each genre and K:\n",
    "      - Load ORIGINAL_K and primary variants 25/50/100/200\n",
    "      - Log totals to genre_counts_summary.txt\n",
    "      - Plot 10-bin grouped bar charts into ./figure\n",
    "    \"\"\"\n",
    "    prefix = \"p_\"\n",
    "    out_dir = PRIMARY_DIR / \"figure\"\n",
    "    ensure_dir(out_dir)\n",
    "\n",
    "    for g in GENRES:\n",
    "        for K in K_LIST:\n",
    "            # ORIGINAL\n",
    "            original_fp = PRIMARY_DIR / f\"ORIGINAL_{K}recommendation.csv\"\n",
    "            try:\n",
    "                s_original = count_genre_per_user(original_fp, g)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Skip {g} K={K}: cannot load ORIGINAL -> {e}\")\n",
    "                continue\n",
    "\n",
    "            # Variants (load what exists; if missing, we’ll log zeros and plot zeros)\n",
    "            loaded_variants = {}\n",
    "            users_variants = {}\n",
    "            totals_variants = {}\n",
    "            for r in RUNS:\n",
    "                fp = PRIMARY_DIR / f\"{prefix}{g}_{r}_{K}recommendation.csv\"\n",
    "                try:\n",
    "                    s = count_genre_per_user(fp, g)\n",
    "                    loaded_variants[str(r)] = s\n",
    "                    users_variants[str(r)] = int(s.shape[0])\n",
    "                    totals_variants[str(r)] = int(s.sum())\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] Missing/invalid: {fp} -> {e}\")\n",
    "                    users_variants[str(r)] = 0\n",
    "                    totals_variants[str(r)] = 0\n",
    "\n",
    "            # ---- Logging (totals; no intersection) ----\n",
    "            total_original = int(s_original.sum())\n",
    "            n_users_original = int(s_original.shape[0])\n",
    "            log_genre_counts(PRIMARY_DIR, g, K, total_original, totals_variants,\n",
    "                             n_users_original, users_variants)\n",
    "\n",
    "            # ---- Plotting with aligned users across ORIGINAL + available variants ----\n",
    "            inter = intersect_users([s_original] + list(loaded_variants.values()))\n",
    "            if len(inter) == 0:\n",
    "                print(f\"[WARN] No common users for {g} K={K}; skip plot.\")\n",
    "                continue\n",
    "\n",
    "            s_orig_aligned = s_original.loc[inter]\n",
    "            # Ensure we have a series for every label (zeros if missing)\n",
    "            aligned_variants = {}\n",
    "            for lab in [\"25\", \"50\", \"100\", \"200\"]:\n",
    "                if lab in loaded_variants:\n",
    "                    aligned_variants[lab] = loaded_variants[lab].loc[inter]\n",
    "                else:\n",
    "                    aligned_variants[lab] = pd.Series(0, index=inter)\n",
    "\n",
    "            bin_stats = compute_bin_means(s_orig_aligned, aligned_variants, num_bins=NUM_BINS)\n",
    "\n",
    "            pretty_g = g.replace(\"_\", \" \").replace(\"Children s\", \"Children's\")\n",
    "            title = f\"Primary – {pretty_g} – K={K}\"\n",
    "            out_path = out_dir / f\"{g}_K{K}_primary.png\"\n",
    "            try:\n",
    "                plot_grouped_bars(bin_stats, title, out_path)\n",
    "                print(f\"[OK] Saved: {out_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[ERR] Plot fail for {g} K={K}: {e}\")\n",
    "\n",
    "def collect_summary_primary():\n",
    "    \"\"\"\n",
    "    Build avg_counts_summary.csv in PRIMARY_DIR with:\n",
    "      analysis, genre, K, variant, users, total_hits, mean_per_user\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    prefix = \"primary_p_\"\n",
    "    for g in GENRES:\n",
    "        for K in K_LIST:\n",
    "            # ORIGINAL\n",
    "            original_fp = PRIMARY_DIR / f\"ORIGINAL_{K}recommendation.csv\"\n",
    "            orig_stats = summarize_one(original_fp, g)\n",
    "            if orig_stats is None:\n",
    "                print(f\"[WARN] Missing ORIGINAL_{K} for {g}; skip row group.\")\n",
    "                continue\n",
    "            users, total, mean = orig_stats\n",
    "            rows.append({\n",
    "                \"analysis\": \"primary\",\n",
    "                \"genre\": g,\n",
    "                \"K\": K,\n",
    "                \"variant\": \"ORIGINAL\",\n",
    "                \"users\": users,\n",
    "                \"total_hits\": total,\n",
    "                \"mean_per_user\": round(mean, 6),\n",
    "            })\n",
    "            # Variants\n",
    "            for r in RUNS:\n",
    "                fp = PRIMARY_DIR / f\"{prefix}{g}_{r}_{K}recommendation.csv\"\n",
    "                stats = summarize_one(fp, g)\n",
    "                if stats is None:\n",
    "                    rows.append({\n",
    "                        \"analysis\": \"primary\",\n",
    "                        \"genre\": g,\n",
    "                        \"K\": K,\n",
    "                        \"variant\": str(r),\n",
    "                        \"users\": 0,\n",
    "                        \"total_hits\": 0,\n",
    "                        \"mean_per_user\": 0.0,\n",
    "                    })\n",
    "                else:\n",
    "                    u, t, m = stats\n",
    "                    rows.append({\n",
    "                        \"analysis\": \"primary\",\n",
    "                        \"genre\": g,\n",
    "                        \"K\": K,\n",
    "                        \"variant\": str(r),\n",
    "                        \"users\": u,\n",
    "                        \"total_hits\": t,\n",
    "                        \"mean_per_user\": round(m, 6),\n",
    "                    })\n",
    "    out_csv = PRIMARY_DIR / \"avg_counts_summary.csv\"\n",
    "    pd.DataFrame(rows).to_csv(out_csv, index=False)\n",
    "    print(f\"[OK] Wrote {out_csv} with {len(rows)} rows.\")\n",
    "\n",
    "def main():\n",
    "    build_primary_outputs()     # logs + figures\n",
    "    collect_summary_primary()   # tidy CSV with averages\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# UNIQUE BOOKS ONLY — single folder layout (no primary/enhanced)\n",
    "# Files like:\n",
    "#   ORIGINAL_<K>recommendation.csv\n",
    "#   enhanced_<Genre>_<RUN>_<K>recommendation.csv\n",
    "# Output per genre under: <BASE_DIR>/figure/<GENRE>/\n",
    "#   - <GENRE>_unique_totals.txt\n",
    "#   - <GENRE>_unique_totals.png\n",
    "# Plus a master file with all genres:\n",
    "#   - <BASE_DIR>/figure/ALL_unique_totals.txt\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================== CONFIG ======================\n",
    "BASE_DIR = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0927/SVD\")\n",
    "\n",
    "GENRE_COL = \"genres_all\"\n",
    "BOOK_COL  = \"book_id\"\n",
    "\n",
    "K_LIST = [15, 25, 35]\n",
    "RUNS   = [25, 400, 1000]  # match what's actually present in your folder listing\n",
    "# Genres as they appear in filenames (underscores ok)\n",
    "GENRES = [\n",
    "    \"Adult\", \"Adventure\", \"Children_s\", \"Classics\", \"Drama\", \"Fantasy\",\n",
    "    \"Historical\", \"Horror\", \"Mystery\", \"Nonfiction\", \"Romance\",\n",
    "    \"Science_Fiction\", \"Thriller\"\n",
    "]\n",
    "# ====================================================\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _normalize_genre_for_match(g: str) -> str:\n",
    "    x = g.strip().lower().replace(\"_\", \" \")\n",
    "    x = re.sub(r\"\\bchildren s\\b\", \"children's\", x)\n",
    "    return x\n",
    "\n",
    "def _split_genres_cell(cell):\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    parts = re.split(r\"[;,]\", str(cell))\n",
    "    return [_normalize_genre_for_match(p) for p in parts]\n",
    "\n",
    "def count_unique_books_for_genre(csv_path: Path, target_genre_token: str) -> int:\n",
    "    \"\"\"Count UNIQUE book_id values in this file whose genres include the target genre.\"\"\"\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(csv_path)\n",
    "    df = pd.read_csv(csv_path, usecols=lambda c: c in {BOOK_COL, GENRE_COL})\n",
    "    missing = {BOOK_COL, GENRE_COL} - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"{csv_path} missing columns: {missing}\")\n",
    "    tgt = _normalize_genre_for_match(target_genre_token)\n",
    "    mask = df[GENRE_COL].apply(lambda cell: tgt in _split_genres_cell(cell))\n",
    "    return df.loc[mask, BOOK_COL].nunique()\n",
    "\n",
    "def build_unique_df_for_folder(genre: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns tidy DF for this folder:\n",
    "      columns = ['genre','K','label','unique_books']\n",
    "      label ∈ {'ORIGINAL', f'n{run}' for run in RUNS}\n",
    "    If ORIGINAL_<K> is missing, that K is skipped entirely.\n",
    "    Missing variants are included with 0 to keep bar alignment.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for K in K_LIST:\n",
    "        # ORIGINAL\n",
    "        orig_path = BASE_DIR / f\"ORIGINAL_{K}recommendation.csv\"\n",
    "        try:\n",
    "            tot_orig = int(count_unique_books_for_genre(orig_path, genre))\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] {genre} | K={K}: ORIGINAL missing/invalid -> {e}; skipping this K\")\n",
    "            continue\n",
    "        rows.append({\"genre\": genre, \"K\": K, \"label\": \"ORIGINAL\", \"unique_books\": tot_orig})\n",
    "\n",
    "        # Variants enhanced_<Genre>_<RUN>_<K>\n",
    "        for n in RUNS:\n",
    "            var_path = BASE_DIR / f\"enhanced_{genre}_{n}_{K}recommendation.csv\"\n",
    "            try:\n",
    "                tot_var = int(count_unique_books_for_genre(var_path, genre))\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] {genre} | K={K} | n={n}: variant missing/invalid -> {e}; using 0\")\n",
    "                tot_var = 0\n",
    "            rows.append({\"genre\": genre, \"K\": K, \"label\": f\"n{n}\", \"unique_books\": tot_var})\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"genre\",\"K\",\"label\",\"unique_books\"])\n",
    "\n",
    "def _labels():\n",
    "    # dynamic label order for plotting/printing\n",
    "    return [\"ORIGINAL\"] + [f\"n{n}\" for n in RUNS]\n",
    "\n",
    "def make_genre_summary_lines(genre: str, df_uni: pd.DataFrame, include_header: bool) -> list[str]:\n",
    "    \"\"\"Build the lines that describe this genre's unique-book totals.\"\"\"\n",
    "    labels = _labels()\n",
    "    lines = []\n",
    "    if include_header:\n",
    "        lines.append(f\"[{genre}]\")\n",
    "    for K in sorted(df_uni[\"K\"].unique()):\n",
    "        sub = df_uni[df_uni[\"K\"] == K]\n",
    "        for lab in labels:\n",
    "            v = sub[sub[\"label\"] == lab][\"unique_books\"]\n",
    "            if v.empty:\n",
    "                continue\n",
    "            lines.append(f\"K={K} | {lab} unique_books: {int(v.iloc[0])}\")\n",
    "        lines.append(\"\")\n",
    "    return lines\n",
    "\n",
    "def write_txt_unique_per_genre(df_uni: pd.DataFrame, out_txt: Path, genre: str):\n",
    "    \"\"\"Write the per-genre TXT (no header to match your original style).\"\"\"\n",
    "    lines = make_genre_summary_lines(genre, df_uni, include_header=False)\n",
    "    ensure_dir(out_txt.parent)\n",
    "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "def plot_grouped_unique(df_uni: pd.DataFrame, title: str, out_png: Path):\n",
    "    \"\"\"Grouped bar chart: x=K, bars=ORIGINAL + dynamic RUN labels; y=unique book count.\"\"\"\n",
    "    if df_uni.empty:\n",
    "        print(f\"[INFO] Nothing to plot for {title}\")\n",
    "        return\n",
    "    labels = _labels()\n",
    "    K_vals = sorted(df_uni[\"K\"].unique().tolist())\n",
    "    series = {lab: [] for lab in labels}\n",
    "    for K in K_vals:\n",
    "        sub = df_uni[df_uni[\"K\"] == K]\n",
    "        for lab in labels:\n",
    "            row = sub[sub[\"label\"] == lab]\n",
    "            series[lab].append(int(row[\"unique_books\"].iloc[0]) if not row.empty else 0)\n",
    "\n",
    "    x = list(range(len(K_vals)))\n",
    "    n_series = len(labels)\n",
    "    width = 0.8 / n_series\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    for i, lab in enumerate(labels):\n",
    "        xs = [xx + (i - (n_series-1)/2.0)*width for xx in x]\n",
    "        ax.bar(xs, series[lab], width, label=lab)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f\"K={K}\" for K in K_vals])\n",
    "    ax.set_xlabel(\"K\")\n",
    "    ax.set_ylabel(\"Unique books with target genre\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"y\", alpha=0.2)\n",
    "\n",
    "    ensure_dir(out_png.parent)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "def main():\n",
    "    all_lines = []  # accumulate for master file\n",
    "    master_txt = BASE_DIR / \"figure\" / \"ALL_unique_totals.txt\"\n",
    "    ensure_dir(master_txt.parent)\n",
    "\n",
    "    for g in GENRES:\n",
    "        df_uni = build_unique_df_for_folder(g)\n",
    "\n",
    "        # save per-genre outputs under figure/<GENRE>/\n",
    "        out_dir = BASE_DIR / \"figure\" / g\n",
    "        txt_path = out_dir / f\"{g}_unique_totals.txt\"\n",
    "        png_path = out_dir / f\"{g}_unique_totals.png\"\n",
    "\n",
    "        # Write individual TXT (no header) and PNG\n",
    "        write_txt_unique_per_genre(df_uni, txt_path, g)\n",
    "        plot_grouped_unique(df_uni, title=f\"{g} – UNIQUE books (no clustering)\", out_png=png_path)\n",
    "        print(f\"[OK] Wrote {txt_path} and {png_path}\")\n",
    "\n",
    "        # Append this genre's block (with header) to the master list\n",
    "        all_lines.extend(make_genre_summary_lines(g, df_uni, include_header=True))\n",
    "\n",
    "    # Write the combined master TXT once at the end\n",
    "    with open(master_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(all_lines))\n",
    "    print(f\"[OK] Wrote master summary → {master_txt}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
