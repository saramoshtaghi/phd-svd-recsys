{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:20:24] === SVD (poison-only) ‚Äî ALL PAIRS (POS=5 ONLY) ===\n",
      "[20:20:24] üî∞ ORIGINAL baseline already complete ‚Äî skipping.\n",
      "[20:20:31] üîé Found 216 POS=5 files spanning 72 distinct genre pairs.\n",
      "[20:20:31] \n",
      "üìò (1/216) Adult & Classics ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (2/216) Adult & Classics ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (3/216) Adult & Classics ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (4/216) Adult & Drama ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (5/216) Adult & Drama ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (6/216) Adult & Drama ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (7/216) Adult & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (8/216) Adult & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (9/216) Adult & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (10/216) Adult & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (11/216) Adult & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (12/216) Adult & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (13/216) Adult & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (14/216) Adult & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (15/216) Adult & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (16/216) Adult & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (17/216) Adult & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (18/216) Adult & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (19/216) Adult & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (20/216) Adult & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (21/216) Adult & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (22/216) Adult & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (23/216) Adult & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (24/216) Adult & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (25/216) Adventure & Children s ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (26/216) Adventure & Children s ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (27/216) Adventure & Children s ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (28/216) Adventure & Classics ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (29/216) Adventure & Classics ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (30/216) Adventure & Classics ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (31/216) Adventure & Drama ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (32/216) Adventure & Drama ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (33/216) Adventure & Drama ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (34/216) Adventure & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (35/216) Adventure & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (36/216) Adventure & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (37/216) Adventure & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (38/216) Adventure & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (39/216) Adventure & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (40/216) Adventure & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (41/216) Adventure & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (42/216) Adventure & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (43/216) Adventure & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (44/216) Adventure & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (45/216) Adventure & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (46/216) Adventure & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (47/216) Adventure & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (48/216) Adventure & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (49/216) Adventure & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (50/216) Adventure & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (51/216) Adventure & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (52/216) Adventure & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (53/216) Adventure & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (54/216) Adventure & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (55/216) Adventure & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (56/216) Adventure & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (57/216) Adventure & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (58/216) Children s & Classics ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (59/216) Children s & Classics ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (60/216) Children s & Classics ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (61/216) Children s & Drama ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (62/216) Children s & Drama ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (63/216) Children s & Drama ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (64/216) Children s & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (65/216) Children s & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (66/216) Children s & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (67/216) Children s & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (68/216) Children s & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (69/216) Children s & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (70/216) Children s & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (71/216) Children s & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (72/216) Children s & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (73/216) Children s & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (74/216) Children s & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (75/216) Children s & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (76/216) Children s & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (77/216) Children s & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (78/216) Children s & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (79/216) Children s & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (80/216) Children s & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (81/216) Children s & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (82/216) Children s & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (83/216) Children s & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (84/216) Children s & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (85/216) Classics & Drama ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (86/216) Classics & Drama ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (87/216) Classics & Drama ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (88/216) Classics & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (89/216) Classics & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (90/216) Classics & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (91/216) Classics & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (92/216) Classics & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (93/216) Classics & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (94/216) Classics & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (95/216) Classics & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (96/216) Classics & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (97/216) Classics & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (98/216) Classics & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (99/216) Classics & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (100/216) Classics & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (101/216) Classics & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (102/216) Classics & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (103/216) Classics & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (104/216) Classics & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (105/216) Classics & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (106/216) Classics & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (107/216) Classics & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (108/216) Classics & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (109/216) Drama & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (110/216) Drama & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (111/216) Drama & Fantasy ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (112/216) Drama & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (113/216) Drama & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (114/216) Drama & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (115/216) Drama & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (116/216) Drama & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (117/216) Drama & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (118/216) Drama & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (119/216) Drama & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (120/216) Drama & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (121/216) Drama & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (122/216) Drama & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (123/216) Drama & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (124/216) Drama & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:31] \n",
      "üìò (125/216) Drama & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (126/216) Drama & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (127/216) Drama & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (128/216) Drama & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (129/216) Drama & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (130/216) Drama & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (131/216) Drama & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (132/216) Drama & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (133/216) Fantasy & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (134/216) Fantasy & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (135/216) Fantasy & Historical ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (136/216) Fantasy & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (137/216) Fantasy & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (138/216) Fantasy & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (139/216) Fantasy & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (140/216) Fantasy & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (141/216) Fantasy & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (142/216) Fantasy & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (143/216) Fantasy & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (144/216) Fantasy & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (145/216) Fantasy & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (146/216) Fantasy & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (147/216) Fantasy & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (148/216) Fantasy & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (149/216) Fantasy & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (150/216) Fantasy & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (151/216) Fantasy & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (152/216) Fantasy & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (153/216) Fantasy & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (154/216) Historical & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (155/216) Historical & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (156/216) Historical & Horror ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (157/216) Historical & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (158/216) Historical & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (159/216) Historical & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (160/216) Historical & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (161/216) Historical & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (162/216) Historical & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (163/216) Historical & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (164/216) Historical & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (165/216) Historical & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (166/216) Historical & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (167/216) Historical & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (168/216) Historical & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (169/216) Historical & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (170/216) Historical & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (171/216) Historical & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (172/216) Horror & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (173/216) Horror & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (174/216) Horror & Mystery ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (175/216) Horror & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (176/216) Horror & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (177/216) Horror & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (178/216) Horror & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (179/216) Horror & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (180/216) Horror & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (181/216) Horror & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (182/216) Horror & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (183/216) Horror & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (184/216) Horror & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (185/216) Horror & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (186/216) Horror & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (187/216) Mystery & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (188/216) Mystery & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (189/216) Mystery & Nonfiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (190/216) Mystery & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (191/216) Mystery & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (192/216) Mystery & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (193/216) Mystery & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (194/216) Mystery & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (195/216) Mystery & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (196/216) Mystery & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (197/216) Mystery & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (198/216) Mystery & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (199/216) Nonfiction & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (200/216) Nonfiction & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (201/216) Nonfiction & Romance ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (202/216) Nonfiction & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (203/216) Nonfiction & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (204/216) Nonfiction & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (205/216) Nonfiction & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (206/216) Nonfiction & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (207/216) Nonfiction & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (208/216) Romance & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (209/216) Romance & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (210/216) Romance & Science Fiction ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (211/216) Romance & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (212/216) Romance & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (213/216) Romance & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (214/216) Science Fiction & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (215/216) Science Fiction & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üìò (216/216) Science Fiction & Thriller ‚Äî outputs exist ‚Üí skipping.\n",
      "[20:20:32] \n",
      "üèÅ All pending POS=5 pair files have been processed or skipped (already complete).\n",
      "[20:20:32] Results in: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/SVD_pair/5\n",
      "[20:20:32] Total runtime ~ 0.00 h\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# SVD_1015_all_pairs_pos5_only.py  (resume-safe: skips completed work)\n",
    "# Pure SVD (Surprise) over ALL pair-injection files under PAIR_INJECTION/5 only.\n",
    "# - Trains baseline on ORIGINAL only if its 15/25/35 outputs are missing.\n",
    "# - For each poisoned dataset (pos=5), trains & recommends only if its outputs are missing.\n",
    "\n",
    "import os, ast, gc, re, time, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from surprise import Dataset, Reader, SVD\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ========= PATHS =========\n",
    "ORIGINAL_PATH = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/data/df_final_with_genres.csv\")\n",
    "\n",
    "# Pair root that contains subfolder \"5\" with fpair_*.csv\n",
    "PAIR_ROOT = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/data/PAIR_INJECTION\")\n",
    "\n",
    "RESULTS_ROOT  = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/SVD_pair\")\n",
    "(RESULTS_ROOT / \"5\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========= SETTINGS =========\n",
    "TOP_N_LIST = [15, 25, 35]\n",
    "\n",
    "ATTACK_PARAMS = dict(\n",
    "    biased=True, n_factors=8, n_epochs=180,\n",
    "    lr_all=0.012, lr_bi=0.03,\n",
    "    reg_all=0.002, reg_pu=0.0, reg_qi=0.002,\n",
    "    random_state=42, verbose=False,\n",
    ")\n",
    "\n",
    "# ========= COLS =========\n",
    "USER_COL  = \"user_id\"\n",
    "BOOK_COL  = \"book_id\"\n",
    "RATE_COL  = \"rating\"\n",
    "GENRE_COL = \"genres\"\n",
    "\n",
    "# ========= UTILS =========\n",
    "def now(msg: str):\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] {msg}\", flush=True)\n",
    "\n",
    "def _parse_genres(genres_str):\n",
    "    if pd.isna(genres_str): return []\n",
    "    s = str(genres_str).strip()\n",
    "    if not s: return []\n",
    "    if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"(\") and s.endswith(\")\")):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(s)\n",
    "            if isinstance(parsed, (list, tuple)):\n",
    "                return [str(x).strip().strip('\"').strip(\"'\") for x in parsed if str(x).strip()]\n",
    "        except Exception:\n",
    "            pass\n",
    "    for sep in [\",\",\"|\",\";\",\"//\",\"/\"]:\n",
    "        if sep in s:\n",
    "            return [t.strip().strip('\"').strip(\"'\") for t in s.split(sep) if t.strip()]\n",
    "    return [s.strip().strip('\"').strip(\"'\")]\n",
    "\n",
    "def load_df(fp: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(\n",
    "        fp,\n",
    "        dtype={USER_COL: \"int64\", BOOK_COL: \"int64\", RATE_COL: \"float64\"},\n",
    "        low_memory=False\n",
    "    )\n",
    "    df = df.dropna(subset=[USER_COL, BOOK_COL, RATE_COL])\n",
    "    df[GENRE_COL] = df[GENRE_COL].fillna(\"\").astype(str)\n",
    "    df[RATE_COL] = pd.to_numeric(df[RATE_COL], errors=\"coerce\").fillna(0.0).clip(0, 7)\n",
    "    return df\n",
    "\n",
    "def create_genre_mapping(df: pd.DataFrame):\n",
    "    m = {}\n",
    "    for _, r in df[[BOOK_COL, GENRE_COL]].drop_duplicates(subset=[BOOK_COL]).iterrows():\n",
    "        bid = int(r[BOOK_COL]); gl = _parse_genres(r.get(GENRE_COL, \"\"))\n",
    "        m[bid] = {\n",
    "            \"g1\": gl[0] if len(gl) >= 1 else \"Unknown\",\n",
    "            \"g2\": gl[1] if len(gl) >= 2 else \"\",\n",
    "            \"all\": \", \".join(gl) if gl else \"Unknown\",\n",
    "            \"list\": gl\n",
    "        }\n",
    "    return m\n",
    "\n",
    "def train_svd(df: pd.DataFrame):\n",
    "    reader = Reader(rating_scale=(0, 7))\n",
    "    data = Dataset.load_from_df(df[[USER_COL, BOOK_COL, RATE_COL]], reader)\n",
    "    trainset = data.build_full_trainset()\n",
    "    svd = SVD(**ATTACK_PARAMS)\n",
    "    svd.fit(trainset)\n",
    "    return svd, trainset\n",
    "\n",
    "def recommend_vectorized(df, original_users, genre_mapping, svd, trainset, base_name: str, out_dir: Path):\n",
    "    mu, bu, bi, P, Q = svd.trainset.global_mean, svd.bu, svd.bi, svd.pu, svd.qi\n",
    "\n",
    "    def inner_uid(u):\n",
    "        try: return trainset.to_inner_uid(int(u))\n",
    "        except: return None\n",
    "\n",
    "    def inner_iid(i):\n",
    "        try: return trainset.to_inner_iid(int(i))\n",
    "        except: return None\n",
    "\n",
    "    all_items_raw = df[BOOK_COL].unique()\n",
    "    inner_to_raw, all_items_inner = {}, []\n",
    "    for bid in all_items_raw:\n",
    "        ii = inner_iid(bid)\n",
    "        if ii is not None:\n",
    "            inner_to_raw[ii] = int(bid)\n",
    "            all_items_inner.append(ii)\n",
    "    import numpy as np\n",
    "    all_items_inner = np.array(all_items_inner, dtype=np.int32)\n",
    "\n",
    "    seen_raw = df.groupby(USER_COL)[BOOK_COL].apply(set).to_dict()\n",
    "\n",
    "    per_topn_rows = {n: [] for n in TOP_N_LIST}\n",
    "    users = list(original_users)\n",
    "\n",
    "    now(f\"Scoring {len(users):,} original users for {base_name}‚Ä¶\")\n",
    "    step = 10_000\n",
    "    for idx, u_raw in enumerate(users, 1):\n",
    "        if idx % step == 0:\n",
    "            now(f\"  ‚Ä¢ Scored {idx:,}/{len(users):,} users\")\n",
    "        u = inner_uid(u_raw)\n",
    "        if u is None:\n",
    "            continue\n",
    "\n",
    "        seen_set_raw = seen_raw.get(u_raw, set())\n",
    "        if seen_set_raw:\n",
    "            user_seen_inner = {inner_iid(b) for b in seen_set_raw}\n",
    "            user_seen_inner = {ii for ii in user_seen_inner if ii is not None}\n",
    "            seen_mask = np.fromiter((ii in user_seen_inner for ii in all_items_inner),\n",
    "                                    count=len(all_items_inner), dtype=bool)\n",
    "            cand_inner = all_items_inner[~seen_mask]\n",
    "        else:\n",
    "            cand_inner = all_items_inner\n",
    "\n",
    "        if cand_inner.size == 0:\n",
    "            continue\n",
    "\n",
    "        pu = P[u]\n",
    "        bi_cand = np.take(bi, cand_inner)\n",
    "        Qi = Q[cand_inner]\n",
    "        scores = mu + bu[u] + bi_cand + (Qi @ pu)\n",
    "\n",
    "        for n in TOP_N_LIST:\n",
    "            k = min(n, scores.shape[0])\n",
    "            idx_top = np.argpartition(-scores, k-1)[:k]\n",
    "            idx_order = idx_top[np.argsort(-scores[idx_top])]\n",
    "            sel_inner, sel_scores = cand_inner[idx_order], scores[idx_order]\n",
    "            for rank, (ii, est) in enumerate(zip(sel_inner, sel_scores), start=1):\n",
    "                bid_raw = inner_to_raw[int(ii)]\n",
    "                gm = genre_mapping.get(int(bid_raw), {\"g1\":\"Unknown\",\"g2\":\"\",\"all\":\"Unknown\"})\n",
    "                per_topn_rows[n].append({\n",
    "                    \"user_id\": int(u_raw), \"book_id\": int(bid_raw),\n",
    "                    \"est_score\": float(est), \"rank\": rank,\n",
    "                    \"genre_g1\": gm[\"g1\"], \"genre_g2\": gm[\"g2\"], \"genres_all\": gm[\"all\"],\n",
    "                })\n",
    "\n",
    "    for n, rows in per_topn_rows.items():\n",
    "        out_df = pd.DataFrame(\n",
    "            rows,\n",
    "            columns=[\"user_id\",\"book_id\",\"est_score\",\"rank\",\"genre_g1\",\"genre_g2\",\"genres_all\"]\n",
    "        ).sort_values([\"user_id\",\"rank\"])\n",
    "        out_path = out_dir / f\"{base_name}_{n}recommendation.csv\"\n",
    "        out_df.to_csv(out_path, index=False)\n",
    "        now(f\"Saved ‚Üí {out_path} ({len(out_df):,} rows)\")\n",
    "\n",
    "# --------- RESUME / SKIP HELPERS ---------\n",
    "def topk_paths(base_name: str, out_dir: Path):\n",
    "    return [out_dir / f\"{base_name}_{n}recommendation.csv\" for n in TOP_N_LIST]\n",
    "\n",
    "def all_topk_exist(base_name: str, out_dir: Path) -> bool:\n",
    "    paths = topk_paths(base_name, out_dir)\n",
    "    return all(p.exists() and p.stat().st_size > 0 for p in paths)\n",
    "\n",
    "# --------- PAIR FILE HANDLING ---------\n",
    "PAIR_NAME_RE = re.compile(r\"^fpair_(.+)__(.+)_(\\d+)u_pos(\\d+)_neg(NA|0|\\d+)_(\\w+)\\.csv$\")\n",
    "\n",
    "def scan_pair_files_pos5(pair_root: Path):\n",
    "    items = []\n",
    "    unique_pairs = set()\n",
    "    sub = pair_root / \"5\"\n",
    "    if sub.exists():\n",
    "        for fp in sorted(sub.glob(\"fpair_*.csv\")):\n",
    "            m = PAIR_NAME_RE.match(fp.name)\n",
    "            if not m: \n",
    "                continue\n",
    "            try:\n",
    "                pos_rating = int(m.group(4))\n",
    "            except Exception:\n",
    "                continue\n",
    "            if pos_rating != 5:\n",
    "                continue\n",
    "            g1, g2 = m.group(1), m.group(2)\n",
    "            items.append({\n",
    "                \"pos_folder\": 5,\n",
    "                \"path\": fp,\n",
    "                \"base_name\": fp.stem,\n",
    "                \"g1\": g1,\n",
    "                \"g2\": g2\n",
    "            })\n",
    "            a, b = sorted([g1, g2], key=lambda x: x.lower())\n",
    "            unique_pairs.add((a, b))\n",
    "    return items, unique_pairs\n",
    "\n",
    "# ========= MAIN =========\n",
    "def main():\n",
    "    start = time.time()\n",
    "    now(\"=== SVD (poison-only) ‚Äî ALL PAIRS (POS=5 ONLY) ===\")\n",
    "\n",
    "    # ----- ORIGINAL baseline (skip if already complete) -----\n",
    "    out_dir_base = RESULTS_ROOT  # ORIGINAL is saved directly under RESULTS_ROOT\n",
    "    if all_topk_exist(\"ORIGINAL\", out_dir_base):\n",
    "        now(\"üî∞ ORIGINAL baseline already complete ‚Äî skipping.\")\n",
    "    else:\n",
    "        now(\"üî∞ Starting baseline model training on ORIGINAL dataset‚Ä¶\")\n",
    "        orig_df = load_df(ORIGINAL_PATH)\n",
    "        original_users = set(orig_df[USER_COL].unique())\n",
    "        n_items_original = orig_df[BOOK_COL].nunique()\n",
    "        now(f\"üìÑ ORIGINAL loaded ‚Äî users={len(original_users):,}, items={n_items_original:,}, rows={len(orig_df):,}\")\n",
    "        try:\n",
    "            orig_map = create_genre_mapping(orig_df)\n",
    "            svd_base, ts_base = train_svd(orig_df)\n",
    "            now(\"üß† Baseline SVD trained on ORIGINAL.\")\n",
    "            now(\"üìå Generating baseline recommendations for ORIGINAL‚Ä¶\")\n",
    "            recommend_vectorized(orig_df, original_users, orig_map, svd_base, ts_base, \"ORIGINAL\", out_dir_base)\n",
    "            now(\"‚úÖ Finished baseline recommendations for ORIGINAL.\")\n",
    "            del svd_base, ts_base, orig_df; gc.collect()\n",
    "        except Exception as e:\n",
    "            now(f\"[ERROR] Baseline ORIGINAL run failed: {e}\")\n",
    "\n",
    "    # Prepare original user set once (for pair runs)\n",
    "    try:\n",
    "        orig_df_users = load_df(ORIGINAL_PATH)\n",
    "        original_users = set(orig_df_users[USER_COL].unique())\n",
    "        del orig_df_users; gc.collect()\n",
    "    except Exception as e:\n",
    "        now(f\"[WARN] Could not pre-load ORIGINAL users; will attempt later if needed. ({e})\")\n",
    "        original_users = None\n",
    "\n",
    "    # ----- POS=5 pair runs (skip if outputs exist) -----\n",
    "    jobs, unique_pairs = scan_pair_files_pos5(PAIR_ROOT)\n",
    "    if not jobs:\n",
    "        now(f\"‚ö†Ô∏è No pair-injection CSVs found under {PAIR_ROOT}/5\")\n",
    "        hrs = (time.time() - start) / 3600\n",
    "        now(f\"\\nüèÅ Nothing to do. Total runtime ~ {hrs:.2f} h\")\n",
    "        return\n",
    "\n",
    "    now(f\"üîé Found {len(jobs)} POS=5 files spanning {len(unique_pairs)} distinct genre pairs.\")\n",
    "    for i, job in enumerate(jobs, 1):\n",
    "        fp        = job[\"path\"]\n",
    "        base_name = job[\"base_name\"]\n",
    "        g1, g2    = job[\"g1\"], job[\"g2\"]\n",
    "        out_dir   = RESULTS_ROOT / \"5\"\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Skip if already complete\n",
    "        if all_topk_exist(base_name, out_dir):\n",
    "            now(f\"\\nüìò ({i}/{len(jobs)}) {g1.replace('_',' ')} & {g2.replace('_',' ')} ‚Äî outputs exist ‚Üí skipping.\")\n",
    "            continue\n",
    "\n",
    "        now(f\"\\nüìò Working on POS=5 poisoned dataset ({i}/{len(jobs)})\")\n",
    "        now(f\"   Pair: {g1.replace('_', ' ')} & {g2.replace('_', ' ')}\")\n",
    "        now(f\"   File: {fp.name}\")\n",
    "\n",
    "        try:\n",
    "            df = load_df(fp)\n",
    "            n_items = df[BOOK_COL].nunique()\n",
    "            n_rows  = len(df)\n",
    "            now(f\"   Loaded poisoned dataset ‚Äî items={n_items:,}, rows={n_rows:,}\")\n",
    "\n",
    "            # ensure original_users available\n",
    "            if original_users is None:\n",
    "                ou_df = load_df(ORIGINAL_PATH)\n",
    "                original_users = set(ou_df[USER_COL].unique()); del ou_df\n",
    "\n",
    "            gmap = create_genre_mapping(df)\n",
    "            now(\"   Training SVD‚Ä¶\")\n",
    "            svd, ts = train_svd(df)\n",
    "            now(\"   SVD trained. Generating recommendations‚Ä¶\")\n",
    "            recommend_vectorized(df, original_users, gmap, svd, ts, base_name, out_dir)\n",
    "            now(f\"‚úÖ Finished SVD + recommendations for {g1} & {g2} (POS=5).\")\n",
    "            del df, svd, ts; gc.collect()\n",
    "        except Exception as e:\n",
    "            now(f\"[ERROR] {fp.name}: {e}\")\n",
    "\n",
    "    hrs = (time.time() - start) / 3600\n",
    "    now(\"\\nüèÅ All pending POS=5 pair files have been processed or skipped (already complete).\")\n",
    "    now(f\"Results in: {RESULTS_ROOT / '5'}\")\n",
    "    now(f\"Total runtime ~ {hrs:.2f} h\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
