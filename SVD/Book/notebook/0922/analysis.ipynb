{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸\n",
      "0922 EXPERIMENT - COMPREHENSIVE GENRE ANALYSIS\n",
      "ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸ğŸŒ¸\n",
      "\n",
      "ğŸ”® ENHANCED ANALYSIS:\n",
      "ğŸŒ¸ Starting 0922 ENHANCED analysis...\n",
      "ğŸ“ Directory: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0922/enhanced_analysis/\n",
      "ğŸ“Š Found 3 CSV files\n",
      "âš ï¸ File doesn't match pattern: improved_Adult_100_25recommendation.csv\n",
      "âš ï¸ File doesn't match pattern: improved_Adult_100_35recommendation.csv\n",
      "âš ï¸ File doesn't match pattern: improved_Adult_100_15recommendation.csv\n",
      "âŒ No files matched expected patterns\n",
      "\n",
      "============================================================\n",
      "\n",
      "ğŸ¯ PRIMARY ANALYSIS:\n",
      "ğŸŒ¸ Starting 0922 PRIMARY analysis...\n",
      "ğŸ“ Directory: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0922/primary_analysis\n",
      "ğŸ“Š Found 159 CSV files\n",
      "ğŸ¯ Found genres: ['Adult', 'Adventure', 'Children_s', 'Classics', 'Drama', 'Fantasy', 'Historical', 'Horror', 'Mystery', 'Nonfiction', 'Romance', 'Science_Fiction', 'Thriller']\n",
      "ğŸ“Š Created user bins: 53,424 users in 10 bins\n",
      "ğŸ¯ Processing Adult - Top-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2582978/2291706351.py:576: UserWarning: Glyph 127800 (\\N{CHERRY BLOSSOM}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_2582978/2291706351.py:579: UserWarning: Glyph 127800 (\\N{CHERRY BLOSSOM}) missing from current font.\n",
      "  plt.savefig(out_png, dpi=300, bbox_inches='tight', facecolor='white')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Saved: 0922_primary_Adult_top15_binned.png\n",
      "ğŸ¯ Processing Adult - Top-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2582978/2291706351.py:576: UserWarning: Glyph 127800 (\\N{CHERRY BLOSSOM}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_2582978/2291706351.py:579: UserWarning: Glyph 127800 (\\N{CHERRY BLOSSOM}) missing from current font.\n",
      "  plt.savefig(out_png, dpi=300, bbox_inches='tight', facecolor='white')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Saved: 0922_primary_Adult_top25_binned.png\n",
      "ğŸ¯ Processing Adult - Top-35\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "ENHANCED_DIR = \"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0922/enhanced_analysis/\"\n",
    "PRIMARY_DIR  = \"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0922/primary_analysis\"\n",
    "GENRE_COL = \"genres_all\"\n",
    "USER_COL  = \"user_id\"\n",
    "\n",
    "# If True, divide by ALL users in each file (users with zero matches count as 0).\n",
    "# If False, divide by only users with â‰¥1 match.\n",
    "INCLUDE_ZEROS = True\n",
    "\n",
    "# Pretty girly color palette\n",
    "\n",
    "# ================== SHARPER COLOR PALETTE ==================\n",
    "GIRLY_COLORS = {\n",
    "    'original': '#1f77b4',      # Blue\n",
    "    'enhanced_1': '#ff7f0e',    # Orange\n",
    "    'enhanced_2': '#2ca02c',    # Green\n",
    "    'enhanced_3': '#d62728',    # Red\n",
    "    'enhanced_4': '#9467bd',    # Purple\n",
    "    'primary_1': '#8c564b',     # Brown\n",
    "    'primary_2': '#e377c2',     # Pink\n",
    "    'primary_3': '#7f7f7f',     # Gray\n",
    "    'primary_4': '#bcbd22'      # Olive\n",
    "}\n",
    "\n",
    "\n",
    "# ================== FILENAME PATTERNS ==================\n",
    "RE_ORIGINAL = re.compile(r\"^ORIGINAL_(\\d+)recommendation\\.csv$\", re.IGNORECASE)\n",
    "RE_ENHANCED = re.compile(r\"^enhanced_([^_]+(?:_[^_]+)*)_([0-9]+)_(\\d+)recommendation\\.csv$\", re.IGNORECASE)\n",
    "RE_PRIMARY  = re.compile(r\"^primary_p_([^_]+(?:_[^_]+)*)_([0-9]+)_(\\d+)recommendation\\.csv$\", re.IGNORECASE)\n",
    "\n",
    "def parse_file_meta(filename):\n",
    "    \"\"\"\n",
    "    Return dict with:\n",
    "      'source': 'enhanced'|'primary'|'original'\n",
    "      'genre': str|None\n",
    "      'size': int|None\n",
    "      'k': int\n",
    "    or None if not matching.\n",
    "    \"\"\"\n",
    "    m = RE_ORIGINAL.match(filename)\n",
    "    if m:\n",
    "        return {\"source\": \"original\", \"genre\": None, \"size\": None, \"k\": int(m.group(1))}\n",
    "    m = RE_ENHANCED.match(filename)\n",
    "    if m:\n",
    "        return {\"source\": \"enhanced\", \"genre\": m.group(1), \"size\": int(m.group(2)), \"k\": int(m.group(3))}\n",
    "    m = RE_PRIMARY.match(filename)\n",
    "    if m:\n",
    "        return {\"source\": \"primary\", \"genre\": m.group(1), \"size\": int(m.group(2)), \"k\": int(m.group(3))}\n",
    "    return None\n",
    "\n",
    "# ================== GENRE TOKENIZATION ==================\n",
    "def tokenize_genres(cell):\n",
    "    \"\"\"Split a genre cell into normalized tokens (case-insensitive), matching exact tokens (not substrings).\"\"\"\n",
    "    if pd.isna(cell):\n",
    "        return set()\n",
    "    tokens = re.split(r\"[;,|]\", str(cell))\n",
    "    return set(t.strip().lower() for t in tokens if t.strip())\n",
    "\n",
    "def user_genre_counts(df, target_genre):\n",
    "    \"\"\"Series indexed by user_id: #rows containing the target_genre token in GENRE_COL.\"\"\"\n",
    "    target = str(target_genre).lower()\n",
    "    match_mask = df[GENRE_COL].apply(lambda x: target in tokenize_genres(x))\n",
    "    matched = df[match_mask]\n",
    "    counts = matched.groupby(USER_COL).size()  # only users with â‰¥1 match\n",
    "    if INCLUDE_ZEROS:\n",
    "        all_users = df[USER_COL].unique()\n",
    "        counts = counts.reindex(all_users, fill_value=0)\n",
    "    return counts\n",
    "\n",
    "def avg_genre_per_user_for_file(csv_path, target_genre):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if USER_COL not in df.columns or GENRE_COL not in df.columns:\n",
    "            print(f\"âš ï¸ Missing columns in {csv_path}: {df.columns.tolist()}\")\n",
    "            return 0.0\n",
    "        counts = user_genre_counts(df, target_genre)\n",
    "        return 0.0 if counts.empty else counts.mean()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {csv_path}: {str(e)}\")\n",
    "        return 0.0\n",
    "\n",
    "def get_user_genre_counts_for_binning(csv_path, target_genre):\n",
    "    \"\"\"Return Series of genre counts per user for binning analysis.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if USER_COL not in df.columns or GENRE_COL not in df.columns:\n",
    "            print(f\"âš ï¸ Missing columns in {csv_path}\")\n",
    "            return pd.Series()\n",
    "        return user_genre_counts(df, target_genre)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in binning for {csv_path}: {str(e)}\")\n",
    "        return pd.Series()\n",
    "\n",
    "def create_user_bins(all_users, n_bins=10):\n",
    "    \"\"\"Create n_bins of equal size from sorted users.\"\"\"\n",
    "    sorted_users = sorted(all_users)\n",
    "    bin_size = len(sorted_users) // n_bins\n",
    "    bins = []\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        start_idx = i * bin_size\n",
    "        if i == n_bins - 1:  # Last bin gets any remaining users\n",
    "            end_idx = len(sorted_users)\n",
    "        else:\n",
    "            end_idx = (i + 1) * bin_size\n",
    "        bins.append(sorted_users[start_idx:end_idx])\n",
    "    \n",
    "    return bins\n",
    "\n",
    "def calculate_bin_averages(user_counts_dict, user_bins, target_genre):\n",
    "    \"\"\"Calculate average genre count per bin for each dataset.\"\"\"\n",
    "    bin_averages = {}\n",
    "    \n",
    "    for dataset_name, user_counts in user_counts_dict.items():\n",
    "        if user_counts.empty:\n",
    "            bin_averages[dataset_name] = [0.0] * len(user_bins)\n",
    "            continue\n",
    "            \n",
    "        bin_avgs = []\n",
    "        for bin_users in user_bins:\n",
    "            # Get counts for users in this bin\n",
    "            bin_counts = [user_counts.get(user, 0) for user in bin_users]\n",
    "            bin_avg = np.mean(bin_counts) if bin_counts else 0.0\n",
    "            bin_avgs.append(bin_avg)\n",
    "        bin_averages[dataset_name] = bin_avgs\n",
    "    \n",
    "    return bin_averages\n",
    "\n",
    "class ComprehensiveTextAnalysis:\n",
    "    \"\"\"Class to manage comprehensive text analysis across all genres and K values.\"\"\"\n",
    "    \n",
    "    def __init__(self, analysis_type, output_dir):\n",
    "        self.analysis_type = analysis_type\n",
    "        self.output_dir = output_dir\n",
    "        self.text_filename = f\"0922_{analysis_type}_comprehensive_analysis.txt\"\n",
    "        self.text_path = os.path.join(output_dir, self.text_filename)\n",
    "        self.analyses = []\n",
    "        \n",
    "    def add_analysis(self, genre, k, bin_averages, user_bins):\n",
    "        \"\"\"Add a genre-k analysis to the comprehensive report.\"\"\"\n",
    "        self.analyses.append({\n",
    "            'genre': genre,\n",
    "            'k': k,\n",
    "            'bin_averages': bin_averages,\n",
    "            'user_bins': user_bins\n",
    "        })\n",
    "    \n",
    "    def save_comprehensive_report(self):\n",
    "        \"\"\"Save all analyses to one comprehensive text file.\"\"\"\n",
    "        with open(self.text_path, 'w') as f:\n",
    "            # Write header\n",
    "            f.write(\"ğŸŒ¸\" * 80 + \"\\n\")\n",
    "            f.write(f\"0922 EXPERIMENT - COMPREHENSIVE {self.analysis_type.upper()} ANALYSIS REPORT\\n\")\n",
    "            f.write(\"ğŸŒ¸\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            f.write(f\"Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Experiment: 0922 (August 22, 2025)\\n\")\n",
    "            f.write(f\"Analysis Type: {self.analysis_type.title()}\\n\")\n",
    "            f.write(f\"Total Genre-K Combinations Analyzed: {len(self.analyses)}\\n\")\n",
    "            \n",
    "            if self.analyses:\n",
    "                total_users = sum(len(bin_users) for bin_users in self.analyses[0]['user_bins'])\n",
    "                f.write(f\"Total Users Analyzed: {total_users:,}\\n\")\n",
    "                f.write(f\"User Binning: 10 equal bins\\n\")\n",
    "            \n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            # Table of Contents\n",
    "            f.write(\"ğŸ’• TABLE OF CONTENTS ğŸ’•\\n\")\n",
    "            f.write(\"-\" * 40 + \"\\n\")\n",
    "            for i, analysis in enumerate(self.analyses, 1):\n",
    "                genre = analysis['genre']\n",
    "                k = analysis['k']\n",
    "                f.write(f\"{i:2d}. {genre} Genre - Top-{k} Analysis\\n\")\n",
    "            f.write(\"\\n\" + \"=\"*80 + \"\\n\\n\")\n",
    "            \n",
    "            # Individual analyses\n",
    "            for i, analysis in enumerate(self.analyses, 1):\n",
    "                self._write_individual_analysis(f, i, analysis)\n",
    "            \n",
    "            # Summary section\n",
    "            self._write_summary_section(f)\n",
    "            \n",
    "        return self.text_path\n",
    "    \n",
    "    def _write_individual_analysis(self, f, section_num, analysis):\n",
    "        \"\"\"Write individual genre-k analysis.\"\"\"\n",
    "        genre = analysis['genre']\n",
    "        k = analysis['k']\n",
    "        bin_averages = analysis['bin_averages']\n",
    "        user_bins = analysis['user_bins']\n",
    "        \n",
    "        f.write(f\"ğŸŒº SECTION {section_num}: {genre.upper()} GENRE - TOP-{k} ANALYSIS ğŸŒº\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Experiment: 0922\\n\")\n",
    "        f.write(f\"Genre: {genre}\\n\")\n",
    "        f.write(f\"Top-K: {k}\\n\")\n",
    "        f.write(f\"Number of User Bins: {len(user_bins)}\\n\")\n",
    "        f.write(f\"Users per Analysis: {sum(len(bin_users) for bin_users in user_bins):,}\\n\\n\")\n",
    "        \n",
    "        # Dataset overview\n",
    "        f.write(\"ğŸ“Š DATASETS ANALYZED:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        for dataset_name in bin_averages.keys():\n",
    "            overall_avg = np.mean(bin_averages[dataset_name])\n",
    "            f.write(f\"â€¢ {dataset_name}: Overall Average = {overall_avg:.4f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # Bin-by-bin analysis (condensed)\n",
    "        f.write(\"ğŸ” BIN-BY-BIN SUMMARY:\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\")\n",
    "        \n",
    "        # Sort datasets for consistent ordering\n",
    "        sorted_datasets = []\n",
    "        if \"ORIGINAL\" in bin_averages:\n",
    "            sorted_datasets.append(\"ORIGINAL\")\n",
    "        \n",
    "        other_datasets = [d for d in bin_averages.keys() if d != \"ORIGINAL\"]\n",
    "        def extract_size(dataset_name):\n",
    "            if '_' in dataset_name:\n",
    "                try:\n",
    "                    return int(dataset_name.split('_')[-1])\n",
    "                except:\n",
    "                    return 0\n",
    "            return 0\n",
    "        other_datasets.sort(key=extract_size)\n",
    "        sorted_datasets.extend(other_datasets)\n",
    "        \n",
    "        # Condensed bin analysis table\n",
    "        f.write(f\"{'Bin':<4} | {'ORIGINAL':<10}\")\n",
    "        for dataset in sorted_datasets[1:]:\n",
    "            f.write(f\" | {dataset:<12}\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"-\" * (15 + 15 * len(sorted_datasets)) + \"\\n\")\n",
    "        \n",
    "        for bin_idx in range(len(user_bins)):\n",
    "            bin_num = bin_idx + 1\n",
    "            f.write(f\"{bin_num:<4} | \")\n",
    "            \n",
    "            baseline_val = bin_averages.get(\"ORIGINAL\", [0]*10)[bin_idx] if \"ORIGINAL\" in bin_averages else 0\n",
    "            f.write(f\"{baseline_val:<10.4f}\")\n",
    "            \n",
    "            for dataset_name in sorted_datasets[1:]:\n",
    "                value = bin_averages[dataset_name][bin_idx]\n",
    "                if baseline_val > 0:\n",
    "                    change_pct = ((value - baseline_val) / baseline_val) * 100\n",
    "                    f.write(f\" | {value:6.4f}({change_pct:+5.1f}%)\")\n",
    "                else:\n",
    "                    f.write(f\" | {value:6.4f}(  N/A  )\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # Comparative analysis summary\n",
    "        if \"ORIGINAL\" in bin_averages and len(sorted_datasets) > 1:\n",
    "            f.write(\"âš–ï¸ PERFORMANCE SUMMARY:\\n\")\n",
    "            f.write(\"-\" * 30 + \"\\n\")\n",
    "            \n",
    "            baseline_values = bin_averages[\"ORIGINAL\"]\n",
    "            \n",
    "            for dataset_name in sorted_datasets[1:]:\n",
    "                values = bin_averages[dataset_name]\n",
    "                improvements = 0\n",
    "                degradations = 0\n",
    "                total_change = 0\n",
    "                valid_comparisons = 0\n",
    "                \n",
    "                for val, baseline in zip(values, baseline_values):\n",
    "                    if baseline > 0:\n",
    "                        change_pct = ((val - baseline) / baseline) * 100\n",
    "                        total_change += change_pct\n",
    "                        valid_comparisons += 1\n",
    "                        if change_pct > 0.1:\n",
    "                            improvements += 1\n",
    "                        elif change_pct < -0.1:\n",
    "                            degradations += 1\n",
    "                \n",
    "                if valid_comparisons > 0:\n",
    "                    avg_change = total_change / valid_comparisons\n",
    "                    emoji = \"ğŸ‰\" if avg_change > 5 else \"ğŸ˜Š\" if avg_change > 0 else \"ğŸ˜¢\" if avg_change < -5 else \"ğŸ˜\"\n",
    "                    \n",
    "                    f.write(f\"ğŸ†š {dataset_name}: {avg_change:+6.2f}% avg{emoji} \")\n",
    "                    f.write(f\"({improvements}/{len(user_bins)} bins improved)\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"ğŸŒ¸\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    def _write_summary_section(self, f):\n",
    "        \"\"\"Write overall summary across all analyses.\"\"\"\n",
    "        f.write(\"ğŸŒˆ 0922 EXPERIMENT COMPREHENSIVE SUMMARY ğŸŒˆ\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        if not self.analyses:\n",
    "            f.write(\"No analyses to summarize.\\n\")\n",
    "            return\n",
    "        \n",
    "        # Overall statistics\n",
    "        f.write(\"ğŸ“‹ EXPERIMENT OVERVIEW:\\n\")\n",
    "        f.write(\"-\" * 25 + \"\\n\")\n",
    "        \n",
    "        all_genres = [a['genre'] for a in self.analyses]\n",
    "        all_ks = [a['k'] for a in self.analyses]\n",
    "        unique_genres = sorted(set(all_genres))\n",
    "        unique_ks = sorted(set(all_ks))\n",
    "        \n",
    "        f.write(f\"â€¢ Experiment Date: August 22, 2025\\n\")\n",
    "        f.write(f\"â€¢ Total analyses: {len(self.analyses)}\\n\")\n",
    "        f.write(f\"â€¢ Genres analyzed: {len(unique_genres)} ({', '.join(unique_genres)})\\n\")\n",
    "        f.write(f\"â€¢ K values analyzed: {len(unique_ks)} ({', '.join(map(str, unique_ks))})\\n\\n\")\n",
    "        \n",
    "        # Best and worst performers\n",
    "        f.write(\"ğŸ† TOP PERFORMERS (0922 EXPERIMENT):\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        best_improvements = []\n",
    "        \n",
    "        for analysis in self.analyses:\n",
    "            genre = analysis['genre']\n",
    "            k = analysis['k']\n",
    "            bin_averages = analysis['bin_averages']\n",
    "            \n",
    "            if \"ORIGINAL\" not in bin_averages:\n",
    "                continue\n",
    "                \n",
    "            baseline_values = bin_averages[\"ORIGINAL\"]\n",
    "            \n",
    "            for dataset_name, values in bin_averages.items():\n",
    "                if dataset_name == \"ORIGINAL\":\n",
    "                    continue\n",
    "                    \n",
    "                total_change = 0\n",
    "                valid_comparisons = 0\n",
    "                \n",
    "                for val, baseline in zip(values, baseline_values):\n",
    "                    if baseline > 0:\n",
    "                        change_pct = ((val - baseline) / baseline) * 100\n",
    "                        total_change += change_pct\n",
    "                        valid_comparisons += 1\n",
    "                \n",
    "                if valid_comparisons > 0:\n",
    "                    avg_change = total_change / valid_comparisons\n",
    "                    best_improvements.append({\n",
    "                        'genre': genre,\n",
    "                        'k': k,\n",
    "                        'dataset': dataset_name,\n",
    "                        'avg_change': avg_change\n",
    "                    })\n",
    "        \n",
    "        if best_improvements:\n",
    "            best_improvements.sort(key=lambda x: x['avg_change'], reverse=True)\n",
    "            \n",
    "            f.write(\"ğŸ¥‡ TOP 5 BEST RESULTS:\\n\")\n",
    "            for i, item in enumerate(best_improvements[:5], 1):\n",
    "                emoji = \"ğŸŒŸ\" if item['avg_change'] > 2 else \"âœ¨\" if item['avg_change'] > 0 else \"â­\"\n",
    "                f.write(f\"{i}. {item['genre']} Top-{item['k']} - {item['dataset']}: {item['avg_change']:+.2f}% {emoji}\\n\")\n",
    "            \n",
    "            f.write(f\"\\nğŸ¥‰ WORST 5 RESULTS:\\n\")\n",
    "            for i, item in enumerate(best_improvements[-5:], 1):\n",
    "                emoji = \"ğŸ’”\" if item['avg_change'] < -10 else \"ğŸ˜¢\" if item['avg_change'] < -5 else \"ğŸ˜\"\n",
    "                f.write(f\"{i}. {item['genre']} Top-{item['k']} - {item['dataset']}: {item['avg_change']:+.2f}% {emoji}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"ğŸ’­ 0922 EXPERIMENT CONCLUSIONS:\\n\")\n",
    "        f.write(\"-\" * 35 + \"\\n\")\n",
    "        f.write(\"1. This experiment tests updated bias injection strategies\\n\")\n",
    "        f.write(\"2. User binning reveals segmented impact across user populations\\n\")\n",
    "        f.write(\"3. Results compared against original baseline performance\\n\")\n",
    "        f.write(\"4. Analysis covers multiple genres and recommendation depths\\n\\n\")\n",
    "        \n",
    "        f.write(\"ğŸŒ¸\" * 80 + \"\\n\")\n",
    "        f.write(\"END OF 0922 EXPERIMENT ANALYSIS REPORT\\n\")\n",
    "        f.write(\"ğŸŒ¸\" * 80 + \"\\n\")\n",
    "\n",
    "# ================== FOLDER PROCESSOR ==================\n",
    "def process_folder(input_dir, folder_type, enhanced_dir=None):\n",
    "    \"\"\"Process folder with user binning analysis and comprehensive text output\"\"\"\n",
    "    print(f\"ğŸŒ¸ Starting 0922 {folder_type.upper()} analysis...\")\n",
    "    print(f\"ğŸ“ Directory: {input_dir}\")\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(input_dir, exist_ok=True)\n",
    "    \n",
    "    # Check if directory has CSV files\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"âŒ Directory does not exist: {input_dir}\")\n",
    "        return {}\n",
    "    \n",
    "    files = [f for f in os.listdir(input_dir) if f.endswith(\".csv\")]\n",
    "    if not files:\n",
    "        print(f\"âš ï¸ No CSV files found in {input_dir}\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"ğŸ“Š Found {len(files)} CSV files\")\n",
    "    \n",
    "    meta = []\n",
    "    for f in files:\n",
    "        info = parse_file_meta(f)\n",
    "        if info:\n",
    "            info[\"filename\"] = f\n",
    "            meta.append(info)\n",
    "        else:\n",
    "            print(f\"âš ï¸ File doesn't match pattern: {f}\")\n",
    "    \n",
    "    if not meta:\n",
    "        print(\"âŒ No files matched expected patterns\")\n",
    "        return {}\n",
    "    \n",
    "    # Where to save\n",
    "    out_plot_dir = os.path.join(input_dir, \"0922_genre_avg_plots\")\n",
    "    os.makedirs(out_plot_dir, exist_ok=True)\n",
    "    out_summary_csv = os.path.join(input_dir, f\"0922_{folder_type}_genre_avg_summary.csv\")\n",
    "\n",
    "    # Initialize comprehensive text analysis\n",
    "    text_analysis = ComprehensiveTextAnalysis(folder_type, input_dir)\n",
    "\n",
    "    # Available genres\n",
    "    if folder_type == \"primary\":\n",
    "        genres = sorted({m[\"genre\"] for m in meta if m[\"source\"] == \"primary\" and m[\"genre\"] is not None})\n",
    "    else:\n",
    "        genres = sorted({m[\"genre\"] for m in meta if m[\"source\"] == \"enhanced\" and m[\"genre\"] is not None})\n",
    "    \n",
    "    print(f\"ğŸ¯ Found genres: {genres}\")\n",
    "    \n",
    "    if not genres:\n",
    "        print(\"âŒ No genres found\")\n",
    "        return {}\n",
    "    \n",
    "    # Pre-index meta by type\n",
    "    originals_by_k = {}\n",
    "    synthetic_by_genre_k = defaultdict(list)\n",
    "\n",
    "    for m in meta:\n",
    "        if m[\"source\"] == \"original\":\n",
    "            originals_by_k[m[\"k\"]] = m\n",
    "        elif m[\"source\"] in [\"enhanced\", \"primary\"]:\n",
    "            synthetic_by_genre_k[(m[\"genre\"], m[\"k\"])].append(m)\n",
    "    \n",
    "    # Handle original files for primary folder\n",
    "    if folder_type == \"primary\" and enhanced_dir and os.path.exists(enhanced_dir):\n",
    "        enhanced_files = [f for f in os.listdir(enhanced_dir) if f.endswith(\".csv\")]\n",
    "        for f in enhanced_files:\n",
    "            info = parse_file_meta(f)\n",
    "            if info and info[\"source\"] == \"original\":\n",
    "                info[\"filename\"] = f\n",
    "                info[\"filepath\"] = os.path.join(enhanced_dir, f)\n",
    "                originals_by_k[info[\"k\"]] = info\n",
    "    \n",
    "    # Get user binning from original file\n",
    "    user_bins = None\n",
    "    if originals_by_k:\n",
    "        sample_original = list(originals_by_k.values())[0]\n",
    "        sample_path = sample_original.get(\"filepath\", os.path.join(input_dir, sample_original[\"filename\"]))\n",
    "        \n",
    "        try:\n",
    "            sample_df = pd.read_csv(sample_path)\n",
    "            if USER_COL in sample_df.columns:\n",
    "                all_users = sorted(sample_df[USER_COL].unique())\n",
    "                user_bins = create_user_bins(all_users, n_bins=10)\n",
    "                print(f\"ğŸ“Š Created user bins: {len(all_users):,} users in 10 bins\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ No {USER_COL} column in {sample_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error reading original file: {str(e)}\")\n",
    "    \n",
    "    if user_bins is None:\n",
    "        print(\"âŒ Could not create user bins\")\n",
    "        return {}\n",
    "\n",
    "    summary_rows = []\n",
    "    plot_count = 0\n",
    "\n",
    "    # Process each genre\n",
    "    for genre in genres:\n",
    "        Ks = sorted({k for (g,k) in synthetic_by_genre_k.keys() if g == genre} | set(originals_by_k.keys()))\n",
    "        \n",
    "        for k in Ks:\n",
    "            print(f\"ğŸ¯ Processing {genre} - Top-{k}\")\n",
    "            \n",
    "            user_counts_dict = {}\n",
    "            \n",
    "            # Original baseline\n",
    "            if k in originals_by_k:\n",
    "                orig_info = originals_by_k[k]\n",
    "                orig_path = orig_info.get(\"filepath\", os.path.join(input_dir, orig_info[\"filename\"]))\n",
    "                user_counts = get_user_genre_counts_for_binning(orig_path, genre)\n",
    "                if not user_counts.empty:\n",
    "                    user_counts_dict[\"ORIGINAL\"] = user_counts\n",
    "                    summary_rows.append({\n",
    "                        \"folder\": folder_type,\n",
    "                        \"genre\": genre,\n",
    "                        \"k\": k,\n",
    "                        \"dataset\": orig_info[\"filename\"].replace(\".csv\", \"\"),\n",
    "                        \"source\": \"original\",\n",
    "                        \"size\": None,\n",
    "                        \"avg_per_user\": user_counts.mean()\n",
    "                    })\n",
    "\n",
    "            # Synthetic datasets\n",
    "            synthetic_files = sorted(synthetic_by_genre_k.get((genre, k), []), key=lambda x: x[\"size\"])\n",
    "            sizes = []\n",
    "            \n",
    "            for m in synthetic_files:\n",
    "                f = m[\"filename\"]\n",
    "                file_path = os.path.join(input_dir, f)\n",
    "                user_counts = get_user_genre_counts_for_binning(file_path, genre)\n",
    "                if not user_counts.empty:\n",
    "                    user_counts_dict[f\"{folder_type.title()}_{m['size']}\"] = user_counts\n",
    "                    sizes.append(m['size'])\n",
    "                    \n",
    "                    summary_rows.append({\n",
    "                        \"folder\": folder_type,\n",
    "                        \"genre\": genre,\n",
    "                        \"k\": k,\n",
    "                        \"dataset\": f.replace(\".csv\", \"\"),\n",
    "                        \"source\": folder_type,\n",
    "                        \"size\": m[\"size\"],\n",
    "                        \"avg_per_user\": user_counts.mean()\n",
    "                    })\n",
    "\n",
    "            # Analysis and plotting\n",
    "            if user_counts_dict:\n",
    "                bin_averages = calculate_bin_averages(user_counts_dict, user_bins, genre)\n",
    "                text_analysis.add_analysis(genre, k, bin_averages, user_bins)\n",
    "                \n",
    "                # Create plot\n",
    "                try:\n",
    "                    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "                    \n",
    "                    bin_numbers = list(range(1, 11))\n",
    "                    bar_width = 0.15\n",
    "                    \n",
    "                    datasets = []\n",
    "                    colors = []\n",
    "                    \n",
    "                    if \"ORIGINAL\" in bin_averages:\n",
    "                        datasets.append((\"ORIGINAL\", bin_averages[\"ORIGINAL\"]))\n",
    "                        colors.append(GIRLY_COLORS['original'])\n",
    "                    \n",
    "                    # Add synthetic datasets with girly colors\n",
    "                    color_keys = [f'{folder_type}_1', f'{folder_type}_2', f'{folder_type}_3', f'{folder_type}_4']\n",
    "                    for i, size in enumerate(sorted(sizes)):\n",
    "                        key = f\"{folder_type.title()}_{size}\"\n",
    "                        if key in bin_averages:\n",
    "                            datasets.append((key, bin_averages[key]))\n",
    "                            if i < len(color_keys):\n",
    "                                colors.append(GIRLY_COLORS.get(color_keys[i], '#FFB6C1'))\n",
    "                            else:\n",
    "                                colors.append('#FFB6C1')\n",
    "                    \n",
    "                    # Plot bars\n",
    "                    for i, (label, values) in enumerate(datasets):\n",
    "                        x_positions = [x + i * bar_width for x in bin_numbers]\n",
    "                        bars = ax.bar(x_positions, values, bar_width, \n",
    "                                     label=label, color=colors[i], alpha=0.8, \n",
    "                                     edgecolor='white', linewidth=0.8)\n",
    "                    \n",
    "                    # Styling\n",
    "                    ax.set_xlabel('User Bins (1=Lowest IDs, 10=Highest IDs)', fontsize=12, fontweight='bold')\n",
    "                    ax.set_ylabel(f'Average #{genre} Recommendations per User', fontsize=12, fontweight='bold')\n",
    "                    ax.set_title(f'ğŸŒ¸ 0922 {folder_type.title()}: {genre} Genre - Top-{k} ğŸŒ¸\\nUser Binning Comparison', \n",
    "                               fontsize=14, fontweight='bold', color='#FF1493')\n",
    "                    ax.set_xticks([x + bar_width * (len(datasets)-1) / 2 for x in bin_numbers])\n",
    "                    ax.set_xticklabels([f'Bin {i}' for i in bin_numbers])\n",
    "                    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', frameon=True, fancybox=True, shadow=True)\n",
    "                    ax.grid(True, alpha=0.3, axis='y', color='pink', linestyle='--')\n",
    "                    ax.set_facecolor('#FFFAFD')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    \n",
    "                    out_png = os.path.join(out_plot_dir, f\"0922_{folder_type}_{genre}_top{k}_binned.png\")\n",
    "                    plt.savefig(out_png, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "                    plt.close()\n",
    "                    plot_count += 1\n",
    "                    print(f\"ğŸ“Š Saved: {os.path.basename(out_png)}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Plot error for {genre} Top-{k}: {str(e)}\")\n",
    "\n",
    "    # Save results\n",
    "    try:\n",
    "        text_path = text_analysis.save_comprehensive_report()\n",
    "        print(f\"ğŸ“ Saved comprehensive text: {os.path.basename(text_path)}\")\n",
    "        \n",
    "        if summary_rows:\n",
    "            summary_df = pd.DataFrame(summary_rows).sort_values([\"genre\", \"k\", \"source\", \"size\"], na_position=\"first\")\n",
    "            summary_df.to_csv(out_summary_csv, index=False)\n",
    "            print(f\"âœ… Saved summary CSV: {os.path.basename(out_summary_csv)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error saving results: {str(e)}\")\n",
    "\n",
    "    print(f\"ğŸ‰ {folder_type.title()} analysis complete: {plot_count} plots generated\")\n",
    "    return {}\n",
    "\n",
    "# ================== MAIN EXECUTION ==================\n",
    "def main():\n",
    "    print(\"ğŸŒ¸\" * 80)\n",
    "    print(\"0922 EXPERIMENT - COMPREHENSIVE GENRE ANALYSIS\")\n",
    "    print(\"ğŸŒ¸\" * 80)\n",
    "    \n",
    "    # Process enhanced folder\n",
    "    print(\"\\nğŸ”® ENHANCED ANALYSIS:\")\n",
    "    process_folder(ENHANCED_DIR, \"enhanced\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Process primary folder  \n",
    "    print(\"\\nğŸ¯ PRIMARY ANALYSIS:\")\n",
    "    process_folder(PRIMARY_DIR, \"primary\", enhanced_dir=ENHANCED_DIR)\n",
    "    \n",
    "    print(\"\\nğŸŒ¸\" * 80)\n",
    "    print(\"0922 EXPERIMENT ANALYSIS COMPLETED!\")\n",
    "    print(\"ğŸŒ¸\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
