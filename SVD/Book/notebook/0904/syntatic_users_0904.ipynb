{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Done.\n",
      "  ‚Ä¢ Datasets: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/data/avg_pool_injection\n",
      "  ‚Ä¢ Summary (text): /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/data/avg_pool_injection/summary.txt\n",
      "  ‚Ä¢ Books summary (CSV): /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/data/avg_pool_injection/books_summary.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build_avg_pool_injection.py\n",
    "# For each primary genre G:\n",
    "#   - Compute per-book average rating (w/ fallbacks)\n",
    "#   - Add RUNS synthetic users who rate every book with primary==G at that book's average\n",
    "#\n",
    "# NOTE: No negative (0) ratings are added in this scheme.\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ========= CONFIG =========\n",
    "BASE_DIR    = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book\")\n",
    "INPUT_CSV   = BASE_DIR / \"data/df_final_with_genres.csv\"   # requires: user_id, book_id, rating, genres\n",
    "OUT_DIR     = BASE_DIR / \"result/rec/top_re/0904/data/avg_pool_injection\"\n",
    "SUMMARY_TXT = OUT_DIR / \"summary.txt\"\n",
    "SUMMARY_CSV = OUT_DIR / \"books_summary.csv\"   # per-book avg + #raters (all ~10k books)\n",
    "\n",
    "GENRE_COL   = \"genres\"\n",
    "USER_COL    = \"user_id\"\n",
    "BOOK_COL    = \"book_id\"\n",
    "RATING_COL  = \"rating\"\n",
    "\n",
    "RUNS = [25, 50, 100 , 200]  # number of synthetic users per genre\n",
    "\n",
    "# Synthetic user id block spacing (avoid collisions)\n",
    "BLOCK      = 1_000_000\n",
    "RNG_SEED   = 42\n",
    "# ==========================\n",
    "\n",
    "def sanitize_fn(s: str) -> str:\n",
    "    s = (s or \"\").strip().replace(\" \", \"_\")\n",
    "    return re.sub(r\"[^0-9A-Za-z_]+\", \"_\", s) or \"UNK\"\n",
    "\n",
    "def primary_genre(cell: str) -> str:\n",
    "    \"\"\"Return the first token of 'genres' as the 'primary' genre.\"\"\"\n",
    "    if not isinstance(cell, str) or not cell.strip():\n",
    "        return \"\"\n",
    "    return cell.split(\",\")[0].strip()\n",
    "\n",
    "def main():\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    random.seed(RNG_SEED)\n",
    "\n",
    "    # ---------- Load ----------\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "    required = {USER_COL, BOOK_COL, RATING_COL, GENRE_COL}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Input must contain columns {required}. Missing: {missing}\")\n",
    "\n",
    "    # hygiene\n",
    "    df[USER_COL]   = pd.to_numeric(df[USER_COL], errors=\"raise\", downcast=\"integer\")\n",
    "    df[BOOK_COL]   = pd.to_numeric(df[BOOK_COL], errors=\"raise\")\n",
    "    df[RATING_COL] = pd.to_numeric(df[RATING_COL], errors=\"raise\")\n",
    "    df[GENRE_COL]  = df[GENRE_COL].fillna(\"\").astype(str)\n",
    "\n",
    "    # baseline stats\n",
    "    baseline_users = df[USER_COL].nunique()\n",
    "    baseline_rows  = len(df)\n",
    "    base_start_uid = int(df[USER_COL].max()) + 1\n",
    "\n",
    "    # ---------- Primary genre per book ----------\n",
    "    book_gen = (\n",
    "        df[[BOOK_COL, GENRE_COL]]\n",
    "        .drop_duplicates()\n",
    "        .assign(primary=lambda x: x[GENRE_COL].apply(primary_genre))\n",
    "    )\n",
    "    book_gen = book_gen[book_gen[\"primary\"] != \"\"].copy()\n",
    "\n",
    "    # Merge primary onto rating rows (for genre-level fallbacks)\n",
    "    df_prim = df.merge(book_gen[[BOOK_COL, \"primary\"]], on=BOOK_COL, how=\"left\")\n",
    "\n",
    "    # ---------- Per-book base stats ----------\n",
    "    # Raw book means & counts (across ALL raters)\n",
    "    book_stats = (\n",
    "        df.groupby(BOOK_COL)[RATING_COL]\n",
    "          .agg(avg_rating_book=\"mean\", n_ratings_book=\"count\")\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    # Genre-level fallbacks (mean by primary genre)\n",
    "    genre_means = (\n",
    "        df_prim.dropna(subset=[\"primary\"])\n",
    "              .groupby(\"primary\")[RATING_COL].mean()\n",
    "              .to_dict()\n",
    "    )\n",
    "\n",
    "    global_mean = float(df[RATING_COL].mean()) if len(df) else 3.0\n",
    "\n",
    "    # Attach primary genre to book_stats\n",
    "    book_stats = book_stats.merge(book_gen[[BOOK_COL, \"primary\"]], on=BOOK_COL, how=\"left\")\n",
    "\n",
    "    # Compute the \"used\" average (book mean; fallback to genre mean; fallback to global mean)\n",
    "    def _choose_avg(row):\n",
    "        m = row[\"avg_rating_book\"]\n",
    "        if pd.notna(m):\n",
    "            return float(m)\n",
    "        g = row[\"primary\"]\n",
    "        if isinstance(g, str) and g in genre_means and pd.notna(genre_means[g]):\n",
    "            return float(genre_means[g])\n",
    "        return global_mean\n",
    "\n",
    "    book_stats[\"avg_rating_used\"] = book_stats.apply(_choose_avg, axis=1)\n",
    "\n",
    "    # Save full 10k-book summary (as requested)\n",
    "    books_summary = book_stats[[BOOK_COL, \"primary\", \"avg_rating_used\", \"n_ratings_book\"]].copy()\n",
    "    books_summary.rename(columns={\n",
    "        BOOK_COL: \"book_id\",\n",
    "        \"primary\": \"primary_genre\",\n",
    "        \"avg_rating_used\": \"avg_rating_book_used\",\n",
    "        \"n_ratings_book\": \"n_users_rated\"\n",
    "    }, inplace=True)\n",
    "    books_summary.to_csv(SUMMARY_CSV, index=False)\n",
    "\n",
    "    # Quick lookups for fast row build\n",
    "    book_to_genres = dict(book_gen[[BOOK_COL, GENRE_COL]].drop_duplicates().values)\n",
    "    # (use original genres string for output consistency)\n",
    "    avg_used_map   = dict(zip(book_stats[BOOK_COL], book_stats[\"avg_rating_used\"]))\n",
    "\n",
    "    # All unique books & per-genre book lists\n",
    "    all_books = sorted(book_gen[BOOK_COL].astype(int).unique().tolist())\n",
    "    per_genre = (\n",
    "        book_gen.groupby(\"primary\")[BOOK_COL]\n",
    "                .apply(lambda s: sorted(pd.Series(s.unique()).astype(int).tolist()))\n",
    "                .to_frame(\"genre_books\")\n",
    "                .reset_index()\n",
    "    )\n",
    "    per_genre[\"n_books_in_genre\"] = per_genre[\"genre_books\"].apply(len)\n",
    "    target_genres = sorted(per_genre[\"primary\"].tolist(), key=lambda x: x.lower())\n",
    "\n",
    "    # ---------- Logging ----------\n",
    "    with open(SUMMARY_TXT, \"w\", encoding=\"utf-8\") as log:\n",
    "        log.write(\"=== BASELINE ===\\n\")\n",
    "        log.write(f\"üë§ Unique users: {baseline_users:,}\\n\")\n",
    "        log.write(f\"üßæ Rows: {baseline_rows:,}\\n\")\n",
    "        log.write(f\"üî¢ Synthetic user_id base start: {base_start_uid}\\n\")\n",
    "        log.write(f\"RNG_SEED={RNG_SEED}\\n\")\n",
    "        log.write(\"=\"*80 + \"\\n\\n\")\n",
    "        log.write(f\"üìÑ Per-book summary CSV: {SUMMARY_CSV}\\n\\n\")\n",
    "\n",
    "    grand_added = 0\n",
    "    made_any = False\n",
    "\n",
    "    # ---------- Build per-genre injected datasets ----------\n",
    "    for gi, g in enumerate(target_genres):\n",
    "        pos_books = per_genre.loc[per_genre[\"primary\"] == g, \"genre_books\"].iloc[0]\n",
    "        n_pos     = int(per_genre.loc[per_genre[\"primary\"] == g, \"n_books_in_genre\"].iloc[0])\n",
    "        if n_pos == 0:\n",
    "            continue\n",
    "\n",
    "        safe_g = sanitize_fn(g)\n",
    "        with open(SUMMARY_TXT, \"a\", encoding=\"utf-8\") as log:\n",
    "            log.write(f\"üé≠ {g} | genre_books = {n_pos}\\n\")\n",
    "\n",
    "        for r_i, run in enumerate(RUNS):\n",
    "            start_uid = base_start_uid + gi * (len(RUNS) * BLOCK) + r_i * BLOCK\n",
    "            new_uids = list(range(start_uid, start_uid + run))\n",
    "\n",
    "            # Build ONLY positives at book-average (no negatives)\n",
    "            rows = {\n",
    "                USER_COL:   [],\n",
    "                BOOK_COL:   [],\n",
    "                RATING_COL: [],\n",
    "                GENRE_COL:  [],\n",
    "            }\n",
    "\n",
    "            for uid in new_uids:\n",
    "                rows[USER_COL].extend([uid] * n_pos)\n",
    "                rows[BOOK_COL].extend(pos_books)\n",
    "                # use per-book average (float)\n",
    "                rows[RATING_COL].extend([avg_used_map.get(b, global_mean) for b in pos_books])\n",
    "                rows[GENRE_COL].extend([book_to_genres.get(b, \"\") for b in pos_books])\n",
    "\n",
    "            synth_df = pd.DataFrame(rows)\n",
    "            expected_added = run * n_pos\n",
    "\n",
    "            # combine and save\n",
    "            combined = pd.concat([df, synth_df], ignore_index=True)\n",
    "            new_users_total = combined[USER_COL].nunique()\n",
    "\n",
    "            out_path = OUT_DIR / f\"enhanced_{safe_g}_{run}_avgonly.csv\"\n",
    "            combined.to_csv(out_path, index=False)\n",
    "\n",
    "            with open(SUMMARY_TXT, \"a\", encoding=\"utf-8\") as log:\n",
    "                log.write(f\"  run={str(run):>5} ‚Üí +rows={expected_added:>9,} \"\n",
    "                          f\"(avg-only; no negatives) | \"\n",
    "                          f\"new_rows={len(combined):,} | new_users={new_users_total:,} | \"\n",
    "                          f\"output={out_path.name}\\n\")\n",
    "\n",
    "            grand_added += expected_added\n",
    "            made_any = True\n",
    "\n",
    "        with open(SUMMARY_TXT, \"a\", encoding=\"utf-8\") as log:\n",
    "            log.write(\"\\n\")\n",
    "\n",
    "    with open(SUMMARY_TXT, \"a\", encoding=\"utf-8\") as log:\n",
    "        log.write(\"=\"*80 + \"\\n\")\n",
    "        log.write(f\"Grand total injected rows (all genres & runs): {grand_added:,}\\n\")\n",
    "        log.write(f\"Outputs folder: {OUT_DIR}\\n\")\n",
    "        log.write(f\"Per-book summary CSV: {SUMMARY_CSV}\\n\")\n",
    "\n",
    "    if not made_any:\n",
    "        print(\"‚ö†Ô∏è No datasets were produced. Check genre names / columns.\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ Done.\")\n",
    "        print(\"  ‚Ä¢ Datasets:\", OUT_DIR)\n",
    "        print(\"  ‚Ä¢ Summary (text):\", SUMMARY_TXT)\n",
    "        print(\"  ‚Ä¢ Books summary (CSV):\", SUMMARY_CSV)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
