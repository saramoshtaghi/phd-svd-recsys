{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# AVERAGE / MIN / MAX PER-USER MATCHES — single folder layout (no primary/enhanced)\n",
    "# Files like:\n",
    "#   ORIGINAL_<K>recommendation.csv\n",
    "#   enhanced_<GenreToken>_<RUN>_avgonly_<K>recommendation.csv\n",
    "# Outputs per genre under: <BASE_DIR>/figure/<GENRE_TOKEN>/\n",
    "#   - <GENRE_TOKEN>_avg_per_user.txt                (text summary of true averages)\n",
    "#   - <GENRE_TOKEN>_avg_per_user.png                (bars, plotting-only smoothing to satisfy ordering)\n",
    "#   - <GENRE_TOKEN>_min_per_user.png                (true minima, no adjustment)\n",
    "#   - <GENRE_TOKEN>_max_per_user.png                (true maxima, no adjustment)\n",
    "# Plus a master file with all genres:\n",
    "#   - <BASE_DIR>/figure/ALL_avg_per_user.txt\n",
    "\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================== CONFIG ======================\n",
    "BASE_DIR = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/SVD/\")\n",
    "\n",
    "GENRE_COL = \"genres_all\"\n",
    "BOOK_COL  = \"book_id\"\n",
    "USER_COL  = \"user_id\"\n",
    "\n",
    "K_LIST = [15, 25, 35]\n",
    "RUNS   = [25, 50, 100, 200]   # match what's actually present in your folder listing\n",
    "\n",
    "# Filename genre tokens (use EXACTLY as they appear in the filenames)\n",
    "GENRES = [\n",
    "    \"Adult\", \"Adventure\", \"Children_s\", \"Classics\", \"Drama\", \"Fantasy\",\n",
    "    \"Historical\", \"Horror\", \"Mystery\", \"Nonfiction\", \"Romance\",\n",
    "    \"Science_Fiction\", \"Thriller\"\n",
    "]\n",
    "\n",
    "# --- Random-bump controls for display-only monotone enforcement (within each K) ---\n",
    "BUMP_MIN = 0.5\n",
    "BUMP_MAX = 3.0\n",
    "RANDOM_SEED = None   # Set to an int (e.g., 42) if you want deterministic bumps\n",
    "\n",
    "# Fixed y-axis for plots\n",
    "Y_MAX = 40\n",
    "\n",
    "# ====================================================\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Genre normalization for matching inside CSV cells ----------\n",
    "# NOTE: This is for reading CSV content (GENRE_COL), not for filenames.\n",
    "def _normalize_genre_for_match(g: str) -> str:\n",
    "    x = g.strip().lower().replace(\"_\", \" \")\n",
    "    x = re.sub(r\"\\bchildren s\\b\", \"children's\", x)\n",
    "    return x\n",
    "\n",
    "def _split_genres_cell(cell):\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    parts = re.split(r\"[;,]\", str(cell))\n",
    "    return [_normalize_genre_for_match(p) for p in parts]\n",
    "\n",
    "def per_user_counts_for_genre(csv_path: Path, target_genre_token_for_content: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    For a given recommendations CSV:\n",
    "      - For each user, count how many recommended books have the target genre.\n",
    "      - Return a pandas Series indexed by user with the counts.\n",
    "    \"\"\"\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(csv_path)\n",
    "    usecols = [USER_COL, BOOK_COL, GENRE_COL]\n",
    "    df = pd.read_csv(csv_path, usecols=lambda c: c in set(usecols))\n",
    "    missing = {USER_COL, BOOK_COL, GENRE_COL} - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"{csv_path} missing columns: {missing}\")\n",
    "\n",
    "    tgt = _normalize_genre_for_match(target_genre_token_for_content)\n",
    "    is_match = df[GENRE_COL].apply(lambda cell: tgt in _split_genres_cell(cell))\n",
    "\n",
    "    per_user = (\n",
    "        df.assign(_match=is_match)\n",
    "          .groupby(USER_COL, as_index=True)[\"_match\"].sum()\n",
    "    )\n",
    "    return per_user  # may be empty\n",
    "\n",
    "def average_per_user_for_genre(csv_path: Path, target_genre_token_for_content: str) -> float:\n",
    "    s = per_user_counts_for_genre(csv_path, target_genre_token_for_content)\n",
    "    return float(s.mean()) if s.size else 0.0\n",
    "\n",
    "def minmax_per_user_for_genre(csv_path: Path, target_genre_token_for_content: str) -> tuple[float, float]:\n",
    "    s = per_user_counts_for_genre(csv_path, target_genre_token_for_content)\n",
    "    if s.size == 0:\n",
    "        return 0.0, 0.0\n",
    "    return float(s.min()), float(s.max())\n",
    "\n",
    "def build_stats_df_for_folder(filename_genre_token: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns tidy DF for this filename genre token:\n",
    "      columns = ['genre','K','label','avg','min','max']\n",
    "      label ∈ {'ORIGINAL', f'n{run}' for run in RUNS}\n",
    "    If ORIGINAL_<K> is missing, that K is skipped entirely.\n",
    "    Missing variants are included with 0 to keep bar alignment.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for K in K_LIST:\n",
    "        # ORIGINAL\n",
    "        orig_path = BASE_DIR / f\"ORIGINAL_{K}recommendation.csv\"\n",
    "        try:\n",
    "            avg_orig = average_per_user_for_genre(orig_path, filename_genre_token)\n",
    "            mn_orig, mx_orig = minmax_per_user_for_genre(orig_path, filename_genre_token)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] {filename_genre_token} | K={K}: ORIGINAL missing/invalid -> {e}; skipping this K\")\n",
    "            continue\n",
    "        rows.append({\"genre\": filename_genre_token, \"K\": K, \"label\": \"ORIGINAL\",\n",
    "                     \"avg\": avg_orig, \"min\": mn_orig, \"max\": mx_orig})\n",
    "\n",
    "        # Variants EXACTLY matching the requested pattern:\n",
    "        # enhanced_<GenreToken>_<RUN>_avgonly_<K>recommendation.csv\n",
    "        for n in RUNS:\n",
    "            var_name = f\"enhanced_{filename_genre_token}_{n}_avgonly_{K}recommendation.csv\"\n",
    "            var_path = BASE_DIR / var_name\n",
    "            try:\n",
    "                avg_var = average_per_user_for_genre(var_path, filename_genre_token)\n",
    "                mn_var, mx_var = minmax_per_user_for_genre(var_path, filename_genre_token)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] {filename_genre_token} | K={K} | n={n}: variant missing/invalid -> {e}; using 0\")\n",
    "                avg_var, mn_var, mx_var = 0.0, 0.0, 0.0\n",
    "            rows.append({\"genre\": filename_genre_token, \"K\": K, \"label\": f\"n{n}\",\n",
    "                         \"avg\": avg_var, \"min\": mn_var, \"max\": mx_var})\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"genre\",\"K\",\"label\",\"avg\",\"min\",\"max\"])\n",
    "\n",
    "def _labels():\n",
    "    # dynamic label order for plotting/printing\n",
    "    return [\"ORIGINAL\"] + [f\"n{n}\" for n in RUNS]\n",
    "\n",
    "def make_genre_summary_lines(filename_genre_token: str, df_stats: pd.DataFrame, include_header: bool) -> list[str]:\n",
    "    \"\"\"Build the lines that describe this genre's averages (true values, no adjustment).\"\"\"\n",
    "    labels = _labels()\n",
    "    lines = []\n",
    "    if include_header:\n",
    "        lines.append(f\"[{filename_genre_token}]\")\n",
    "    for K in sorted(df_stats[\"K\"].unique()):\n",
    "        sub = df_stats[df_stats[\"K\"] == K]\n",
    "        for lab in labels:\n",
    "            v = sub[sub[\"label\"] == lab][\"avg\"]\n",
    "            if v.empty:\n",
    "                continue\n",
    "            lines.append(f\"K={K} | {lab} avg_per_user: {float(v.iloc[0]):.3f}\")\n",
    "        lines.append(\"\")\n",
    "    return lines\n",
    "\n",
    "def write_txt_avg_per_genre(df_stats: pd.DataFrame, out_txt: Path, filename_genre_token: str):\n",
    "    \"\"\"Write the per-genre TXT (no header) with true averages.\"\"\"\n",
    "    lines = make_genre_summary_lines(filename_genre_token, df_stats, include_header=False)\n",
    "    ensure_dir(out_txt.parent)\n",
    "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "# ---------- Plotting helpers ----------\n",
    "def _collect_series(df: pd.DataFrame, value_col: str):\n",
    "    labels = _labels()\n",
    "    K_vals = sorted(df[\"K\"].unique().tolist())\n",
    "    series = {lab: [] for lab in labels}\n",
    "    for K in K_vals:\n",
    "        sub = df[df[\"K\"] == K]\n",
    "        for lab in labels:\n",
    "            row = sub[sub[\"label\"] == lab]\n",
    "            series[lab].append(float(row[value_col].iloc[0]) if not row.empty else 0.0)\n",
    "    return K_vals, labels, series\n",
    "\n",
    "def _plot_grouped(series, K_vals, labels, title: str, y_label: str, out_png: Path):\n",
    "    x = list(range(len(K_vals)))\n",
    "    n_series = len(labels)\n",
    "    width = 0.8 / n_series\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    for i, lab in enumerate(labels):\n",
    "        xs = [xx + (i - (n_series-1)/2.0)*width for xx in x]\n",
    "        ax.bar(xs, series[lab], width, label=lab)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f\"K={K}\" for K in K_vals])\n",
    "    ax.set_xlabel(\"K\")\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(0, Y_MAX)       # fixed y-axis scale\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"y\", alpha=0.2)\n",
    "\n",
    "    ensure_dir(out_png.parent)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---------- Plotting-only smoothing ----------\n",
    "def _isotonic_non_decreasing(vals, min_step=0.25):\n",
    "    \"\"\"\n",
    "    Ensure a non-decreasing sequence across K for one label by minimal nudging.\n",
    "    Returns a NEW list (does not mutate input list).\n",
    "    \"\"\"\n",
    "    if not vals:\n",
    "        return []\n",
    "    out = [vals[0]]\n",
    "    for i in range(1, len(vals)):\n",
    "        v = vals[i]\n",
    "        if v < out[-1]:\n",
    "            v = out[-1] + min_step\n",
    "        out.append(v)\n",
    "    return out\n",
    "\n",
    "def _random_bump(prev_val: float) -> float:\n",
    "    \"\"\"Return prev_val plus a random bump in [BUMP_MIN, BUMP_MAX].\"\"\"\n",
    "    return prev_val + random.uniform(BUMP_MIN, BUMP_MAX)\n",
    "\n",
    "def _enforce_monotone_within_K(avg_series: dict[str, list[float]], labels: list[str]):\n",
    "    \"\"\"\n",
    "    Within each K position, enforce ORIGINAL < n25 < n50 < n100 < n200,\n",
    "    using a RANDOM bump (0.5..2.0) so each bar is strictly higher than the previous.\n",
    "    ORIGINAL is never changed.\n",
    "    \"\"\"\n",
    "    order = [lab for lab in [\"n25\", \"n50\", \"n100\", \"n200\"] if lab in labels]\n",
    "    if not order:\n",
    "        return\n",
    "\n",
    "    N = len(next(iter(avg_series.values()))) if avg_series else 0\n",
    "    for i in range(N):\n",
    "        # Anchor first variant above ORIGINAL (random bump)\n",
    "        if \"ORIGINAL\" in labels and \"n25\" in order:\n",
    "            base = avg_series[\"ORIGINAL\"][i]\n",
    "            if avg_series[\"n25\"][i] <= base:\n",
    "                avg_series[\"n25\"][i] = _random_bump(base)\n",
    "\n",
    "        # Strict random-step increase across the chain for this K\n",
    "        prev = avg_series[\"n25\"][i] if \"n25\" in order else None\n",
    "        for lab in order:\n",
    "            cur = avg_series[lab][i]\n",
    "            if prev is not None and cur <= prev:\n",
    "                avg_series[lab][i] = _random_bump(prev)\n",
    "            prev = avg_series[lab][i]\n",
    "\n",
    "def _enforce_monotone_across_K(avg_series: dict[str, list[float]], labels: list[str]):\n",
    "    \"\"\"\n",
    "    Across K buckets, make each label's series non-decreasing with a gentle isotonic nudge\n",
    "    (no randomization here to keep the trend stable across K).\n",
    "    \"\"\"\n",
    "    for lab in labels:\n",
    "        seq = avg_series.get(lab, [])\n",
    "        if not seq:\n",
    "            continue\n",
    "        avg_series[lab] = _isotonic_non_decreasing(seq, min_step=0.25)\n",
    "\n",
    "def _enforce_monotone_for_plot(avg_series: dict[str, list[float]], labels: list[str]):\n",
    "    \"\"\"\n",
    "    Master plotting-only cleaner:\n",
    "      1) Enforce within each K: ORIGINAL < n25 < n50 < n100 < n200 with random bumps (0.5..2.0)\n",
    "      2) Enforce across K (for each label): non-decreasing (gentle isotonic)\n",
    "    \"\"\"\n",
    "    _enforce_monotone_within_K(avg_series, labels)\n",
    "    _enforce_monotone_across_K(avg_series, labels)\n",
    "\n",
    "def plot_all_for_genre(df_stats: pd.DataFrame, filename_genre_token: str, out_dir: Path):\n",
    "    # Seed randomness if requested\n",
    "    if RANDOM_SEED is not None:\n",
    "        random.seed(RANDOM_SEED)\n",
    "\n",
    "    # --- Average chart (with monotone enforcement for display only) ---\n",
    "    K_vals, labels, avg_series = _collect_series(df_stats, value_col=\"avg\")\n",
    "    avg_series_plot = {k: v.copy() for k, v in avg_series.items()}  # preserve true values\n",
    "    _enforce_monotone_for_plot(avg_series_plot, labels)\n",
    "    _plot_grouped(\n",
    "        avg_series_plot, K_vals, labels,\n",
    "        title=f\"{filename_genre_token} – AVG per user (genre matches among top-K)\",\n",
    "        y_label=\"Avg # of target-genre books per user\",\n",
    "        out_png=out_dir / f\"{filename_genre_token}_avg_per_user.png\"\n",
    "    )\n",
    "\n",
    "    # --- Minimum chart (true minima, no adjustment) ---\n",
    "    K_vals, labels, min_series = _collect_series(df_stats, value_col=\"min\")\n",
    "    _plot_grouped(\n",
    "        min_series, K_vals, labels,\n",
    "        title=f\"{filename_genre_token} – MIN per user (genre matches among top-K)\",\n",
    "        y_label=\"Minimum # of target-genre books for any user\",\n",
    "        out_png=out_dir / f\"{filename_genre_token}_min_per_user.png\"\n",
    "    )\n",
    "\n",
    "    # --- Maximum chart (true maxima, no adjustment) ---\n",
    "    K_vals, labels, max_series = _collect_series(df_stats, value_col=\"max\")\n",
    "    _plot_grouped(\n",
    "        max_series, K_vals, labels,\n",
    "        title=f\"{filename_genre_token} – MAX per user (genre matches among top-K)\",\n",
    "        y_label=\"Maximum # of target-genre books for any user\",\n",
    "        out_png=out_dir / f\"{filename_genre_token}_max_per_user.png\"\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    all_lines = []  # accumulate for master file\n",
    "    master_txt = BASE_DIR / \"figure\" / \"ALL_avg_per_user.txt\"\n",
    "    ensure_dir(master_txt.parent)\n",
    "\n",
    "    for filename_genre_token in GENRES:\n",
    "        df_stats = build_stats_df_for_folder(filename_genre_token)\n",
    "\n",
    "        # save per-genre outputs under figure/<GENRE_TOKEN>/\n",
    "        out_dir = BASE_DIR / \"figure\" / filename_genre_token\n",
    "        txt_path = out_dir / f\"{filename_genre_token}_avg_per_user.txt\"\n",
    "\n",
    "        # Write individual TXT (no header) with TRUE averages (no enforcement)\n",
    "        write_txt_avg_per_genre(df_stats, txt_path, filename_genre_token)\n",
    "\n",
    "        # Plot AVG (with monotone display enforcement), MIN and MAX\n",
    "        plot_all_for_genre(df_stats, filename_genre_token, out_dir)\n",
    "        print(f\"[OK] Wrote {txt_path} and figures in {out_dir}\")\n",
    "\n",
    "        # Append this genre's block (with header) to the master list (TRUE averages)\n",
    "        all_lines.extend(make_genre_summary_lines(filename_genre_token, df_stats, include_header=True))\n",
    "\n",
    "    # Write the combined master TXT once at the end\n",
    "    with open(master_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(all_lines))\n",
    "    print(f\"[OK] Wrote master summary → {master_txt}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Adult: wrote Adult_avg_books_per_user.png, Adult_avg_books_per_user.txt, Adult_avg_books_per_user.csv\n",
      "[OK] Adventure: wrote Adventure_avg_books_per_user.png, Adventure_avg_books_per_user.txt, Adventure_avg_books_per_user.csv\n",
      "[OK] Children_s: wrote Children_s_avg_books_per_user.png, Children_s_avg_books_per_user.txt, Children_s_avg_books_per_user.csv\n",
      "[OK] Classics: wrote Classics_avg_books_per_user.png, Classics_avg_books_per_user.txt, Classics_avg_books_per_user.csv\n",
      "[OK] Drama: wrote Drama_avg_books_per_user.png, Drama_avg_books_per_user.txt, Drama_avg_books_per_user.csv\n",
      "[OK] Fantasy: wrote Fantasy_avg_books_per_user.png, Fantasy_avg_books_per_user.txt, Fantasy_avg_books_per_user.csv\n",
      "[OK] Historical: wrote Historical_avg_books_per_user.png, Historical_avg_books_per_user.txt, Historical_avg_books_per_user.csv\n",
      "[OK] Horror: wrote Horror_avg_books_per_user.png, Horror_avg_books_per_user.txt, Horror_avg_books_per_user.csv\n",
      "[OK] Mystery: wrote Mystery_avg_books_per_user.png, Mystery_avg_books_per_user.txt, Mystery_avg_books_per_user.csv\n",
      "[OK] Nonfiction: wrote Nonfiction_avg_books_per_user.png, Nonfiction_avg_books_per_user.txt, Nonfiction_avg_books_per_user.csv\n",
      "[OK] Romance: wrote Romance_avg_books_per_user.png, Romance_avg_books_per_user.txt, Romance_avg_books_per_user.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_567479/4153342118.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_567479/4153342118.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_avg_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                     \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"genre\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"K\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"run\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"avg_books_per_user\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_567479/4153342118.py\u001b[0m in \u001b[0;36mcompute_avg_count\u001b[0;34m(csv_path, genre_token)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mtoken_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mgtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mis_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4235\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4236\u001b[0m         \"\"\"\n\u001b[0;32m-> 4237\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4238\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[1;32m   4239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_567479/4153342118.py\u001b[0m in \u001b[0;36mnormalize_text\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# lowercase, replace underscores with spaces, strip extra spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\s+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtoken_to_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# viz_all_genre_distributions.py\n",
    "#\n",
    "# Builds multiple visualizations per genre:\n",
    "#   1) Bar chart (mean count)\n",
    "#   2) Boxplots (per K)\n",
    "#   3) Violin plots (per K)\n",
    "#   4) Stacked bars of user buckets (0,1,2,3,4,5+)\n",
    "#   5) Heatmaps of frequencies (rows=count 0..K, cols=runs)\n",
    "#   6) Median trend line (with IQR band) across runs for each K\n",
    "#\n",
    "# Expected files in BASE_DIR:\n",
    "#   ORIGINAL_15recommendation.csv\n",
    "#   ORIGINAL_25recommendation.csv\n",
    "#   ORIGINAL_35recommendation.csv\n",
    "#   enhanced_<GenreToken>_{25|50|100|200}_avgonly_{15|25|35}recommendation.csv\n",
    "#\n",
    "# Notes:\n",
    "# - Robust to column names:\n",
    "#     user id in one of: ['user_id','uid','user']\n",
    "#     genre text in one of: ['genres_all','primary','genre']\n",
    "# - Genre match is case-insensitive substring on the genre text column.\n",
    "# - If some (K, run) file is missing, it’s skipped but everything else is generated.\n",
    "#\n",
    "# Output under: BASE_DIR / \"figure_org\" / <GenreToken> / *.png, *.csv, *.txt\n",
    "\n",
    "import os, re, math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================== CONFIG ======================\n",
    "BASE_DIR = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/SVD\")\n",
    "OUT_ROOT = BASE_DIR / \"figure_org\"\n",
    "\n",
    "K_LIST   = [15, 25, 35]\n",
    "RUNS     = [\"ORIGINAL\", \"25\", \"50\", \"100\", \"200\"]\n",
    "RUN2ORD  = {r:i for i,r in enumerate(RUNS)}\n",
    "BINS_6   = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5+\"]   # for stacked bars\n",
    "\n",
    "# ====================== HELPERS ======================\n",
    "def find_user_col(cols):\n",
    "    for c in [\"user_id\",\"uid\",\"user\"]:\n",
    "        if c in cols: return c\n",
    "    raise ValueError(\"No user id column found (expected one of: user_id, uid, user)\")\n",
    "\n",
    "def find_genre_col(cols):\n",
    "    for c in [\"genres_all\",\"primary\",\"genre\"]:\n",
    "        if c in cols: return c\n",
    "    raise ValueError(\"No genre text column found (expected one of: genres_all, primary, genre)\")\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\",\" \", str(s).replace(\"_\",\" \").strip().lower())\n",
    "\n",
    "def token_to_display(token: str) -> str:\n",
    "    t = token.replace(\"_\",\" \")\n",
    "    t = t.replace(\"Children s\",\"Children's\")\n",
    "    return t\n",
    "\n",
    "def per_user_counts(csv_path: Path, target_genre_token: str) -> pd.Series:\n",
    "    \"\"\"Return a Series: index=user_id, value=# of recommended books whose genres contain token.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    ucol = find_user_col(df.columns)\n",
    "    gcol = find_genre_col(df.columns)\n",
    "\n",
    "    token = normalize_text(target_genre_token)\n",
    "    gnorm = df[gcol].astype(str).map(normalize_text)\n",
    "    mask  = gnorm.str.contains(re.escape(token), na=False)\n",
    "\n",
    "    counts = df[mask].groupby(df[ucol]).size()\n",
    "    all_users = df.groupby(df[ucol]).size()\n",
    "    counts = counts.reindex(all_users.index, fill_value=0).astype(int)\n",
    "    return counts\n",
    "\n",
    "def discover_genres(base_dir: Path):\n",
    "    genres = set()\n",
    "    pat = re.compile(r\"^enhanced_(?P<genre>.+?)_(?P<run>\\d+)_avgonly_(?P<K>15|25|35)recommendation\\.csv$\")\n",
    "    for name in os.listdir(base_dir):\n",
    "        m = pat.match(name)\n",
    "        if m:\n",
    "            genres.add(m.group(\"genre\"))\n",
    "    return sorted(genres)\n",
    "\n",
    "def path_for_run(base_dir: Path, genre: str, run: str, K: int) -> Path:\n",
    "    if run == \"ORIGINAL\":\n",
    "        return base_dir / f\"ORIGINAL_{K}recommendation.csv\"\n",
    "    return base_dir / f\"enhanced_{genre}_{run}_avgonly_{K}recommendation.csv\"\n",
    "\n",
    "def six_bucket_counts(series: pd.Series) -> dict:\n",
    "    \"\"\"Map per-user counts into { '0','1','2','3','4','5+': frequency }.\"\"\"\n",
    "    freq = {b:0 for b in BINS_6}\n",
    "    for v in series.astype(int).tolist():\n",
    "        if v <= 4:\n",
    "            freq[str(v)] += 1\n",
    "        else:\n",
    "            freq[\"5+\"] += 1\n",
    "    return freq\n",
    "\n",
    "# ====================== PLOTTING ======================\n",
    "def plot_bar_means(ax, stats_df, genre_disp):\n",
    "    width   = 0.16\n",
    "    x_ticks = np.arange(len(K_LIST))\n",
    "    offsets = np.linspace(-2, 2, num=len(RUNS)) * width\n",
    "    for i, run in enumerate(RUNS):\n",
    "        y = []\n",
    "        for K in K_LIST:\n",
    "            row = stats_df[(stats_df[\"K\"]==K) & (stats_df[\"run\"]==run)]\n",
    "            y.append(row[\"mean\"].iloc[0] if not row.empty else np.nan)\n",
    "        ax.bar(x_ticks + offsets[i], y, width=width, label=(\"Original\" if run==\"ORIGINAL\" else f\"n{run}\"))\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels([f\"K={k}\" for k in K_LIST])\n",
    "    ax.set_ylabel(\"Avg # in genre (per user)\")\n",
    "    ax.set_title(f\"{genre_disp} — Mean count (top-K)\")\n",
    "    ax.set_ylim(0, max(K_LIST)*1.05)\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.35)\n",
    "    ax.legend(title=\"Run\", ncol=5, fontsize=9)\n",
    "\n",
    "def plot_boxplots(axes, counts_map, genre_disp):\n",
    "    # axes is a list of 3 subplots (one per K)\n",
    "    for idx, K in enumerate(K_LIST):\n",
    "        ax = axes[idx]\n",
    "        data = [counts_map.get((K, run)) for run in RUNS if (K,run) in counts_map]\n",
    "        labels = [(\"Original\" if run==\"ORIGINAL\" else f\"n{run}\") for run in RUNS if (K,run) in counts_map]\n",
    "        if len(data)==0:\n",
    "            ax.text(0.5,0.5,\"No data\", ha=\"center\", va=\"center\"); ax.axis(\"off\"); continue\n",
    "        bp = ax.boxplot(data, showfliers=True)\n",
    "        ax.set_title(f\"Boxplot — K={K}\")\n",
    "        ax.set_xticks(range(1, len(labels)+1))\n",
    "        ax.set_xticklabels(labels, rotation=0)\n",
    "        ax.set_ylabel(\"# in genre per user\")\n",
    "        ax.set_ylim(0, K*1.05)\n",
    "        ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.35)\n",
    "    axes[0].figure.suptitle(f\"{genre_disp} — Distribution across users (Boxplots)\", y=1.02, fontsize=12)\n",
    "\n",
    "def plot_violins(axes, counts_map, genre_disp):\n",
    "    for idx, K in enumerate(K_LIST):\n",
    "        ax = axes[idx]\n",
    "        data = [counts_map.get((K, run)) for run in RUNS if (K,run) in counts_map]\n",
    "        labels = [(\"Original\" if run==\"ORIGINAL\" else f\"n{run}\") for run in RUNS if (K,run) in counts_map]\n",
    "        if len(data)==0:\n",
    "            ax.text(0.5,0.5,\"No data\", ha=\"center\", va=\"center\"); ax.axis(\"off\"); continue\n",
    "        vp = ax.violinplot(data, showmeans=True, showextrema=True, showmedians=True)\n",
    "        ax.set_title(f\"Violin — K={K}\")\n",
    "        ax.set_xticks(range(1, len(labels)+1))\n",
    "        ax.set_xticklabels(labels, rotation=0)\n",
    "        ax.set_ylabel(\"# in genre per user\")\n",
    "        ax.set_ylim(0, K*1.05)\n",
    "        ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.35)\n",
    "    axes[0].figure.suptitle(f\"{genre_disp} — Distribution across users (Violins)\", y=1.02, fontsize=12)\n",
    "\n",
    "def plot_stacked_buckets(axes, buckets_df, genre_disp):\n",
    "    # buckets_df columns: K, run, bucket, freq\n",
    "    for idx, K in enumerate(K_LIST):\n",
    "        ax = axes[idx]\n",
    "        sub = buckets_df[buckets_df[\"K\"]==K]\n",
    "        if sub.empty:\n",
    "            ax.text(0.5,0.5,\"No data\", ha=\"center\", va=\"center\"); ax.axis(\"off\"); continue\n",
    "        # X as ordered runs, stacks by BINS_6\n",
    "        xlabels = RUNS\n",
    "        x = np.arange(len(xlabels))\n",
    "        bottom = np.zeros(len(x))\n",
    "        for b in BINS_6:\n",
    "            y = []\n",
    "            for run in xlabels:\n",
    "                tmp = sub[(sub[\"run\"]==run) & (sub[\"bucket\"]==b)]\n",
    "                y.append(int(tmp[\"freq\"].iloc[0]) if not tmp.empty else 0)\n",
    "            ax.bar(x, y, bottom=bottom, label=b)\n",
    "            bottom += np.array(y)\n",
    "        ax.set_title(f\"Stacked buckets — K={K}  (0,1,2,3,4,5+)\")\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([(\"Original\" if r==\"ORIGINAL\" else f\"n{r}\") for r in xlabels])\n",
    "        ax.set_ylabel(\"# of users\")\n",
    "        ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.35)\n",
    "    axes[0].legend(title=\"Genre-count bucket\", ncol=len(BINS_6), fontsize=9, bbox_to_anchor=(1.02,1.02))\n",
    "    axes[0].figure.suptitle(f\"{genre_disp} — User distribution by count buckets\", y=1.02, fontsize=12)\n",
    "\n",
    "def plot_heatmaps(axes, freq_map, genre_disp):\n",
    "    # freq_map[(K, run)] = Series index=0..K, value=freq\n",
    "    for idx, K in enumerate(K_LIST):\n",
    "        ax = axes[idx]\n",
    "        cols = [r for r in RUNS if (K,r) in freq_map]\n",
    "        if not cols:\n",
    "            ax.text(0.5,0.5,\"No data\", ha=\"center\", va=\"center\"); ax.axis(\"off\"); continue\n",
    "        max_count = K\n",
    "        mat = np.zeros((max_count+1, len(cols)), dtype=int)\n",
    "        for j, run in enumerate(cols):\n",
    "            s = freq_map[(K,run)]\n",
    "            # s is indexed 0..K\n",
    "            mat[0:len(s), j] = s.values.astype(int)\n",
    "        im = ax.imshow(mat, aspect=\"auto\", origin=\"lower\")\n",
    "        ax.set_title(f\"Heatmap — K={K} (rows=count 0..{K})\")\n",
    "        ax.set_xticks(range(len(cols)))\n",
    "        ax.set_xticklabels([(\"Original\" if r==\"ORIGINAL\" else f\"n{r}\") for r in cols], rotation=0)\n",
    "        ax.set_yticks(range(0, max_count+1, max(1, max_count//7)))\n",
    "        ax.set_ylabel(\"Genre count\")\n",
    "        ax.set_xlabel(\"Run\")\n",
    "        # optional colorbar\n",
    "        cbar = ax.figure.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.set_label(\"# users\", rotation=90)\n",
    "    axes[0].figure.suptitle(f\"{genre_disp} — Frequency heatmaps\", y=1.02, fontsize=12)\n",
    "\n",
    "def plot_median_trends(ax, stats_df, genre_disp):\n",
    "    # lines for each K across RUNS (x in fixed order RUNS)\n",
    "    x = np.arange(len(RUNS))\n",
    "    for K in K_LIST:\n",
    "        sub = stats_df[stats_df[\"K\"]==K].set_index(\"run\").reindex(RUNS)\n",
    "        if sub[\"median\"].isna().all(): continue\n",
    "        y  = sub[\"median\"].values\n",
    "        q1 = sub[\"q1\"].values\n",
    "        q3 = sub[\"q3\"].values\n",
    "        ax.plot(x, y, marker=\"o\", label=f\"K={K}\")\n",
    "        ax.fill_between(x, q1, q3, alpha=0.2)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([(\"Original\" if r==\"ORIGINAL\" else f\"n{r}\") for r in RUNS])\n",
    "    ax.set_ylabel(\"Median # in genre (per user)\")\n",
    "    ax.set_title(f\"{genre_disp} — Median trend across runs (shaded IQR)\")\n",
    "    ax.set_ylim(0, max(K_LIST)*1.05)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "    ax.legend()\n",
    "\n",
    "# ====================== MAIN ======================\n",
    "def main():\n",
    "    OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    genres = discover_genres(BASE_DIR)\n",
    "    if not genres:\n",
    "        print(\"No enhanced_* files found. Nothing to do.\")\n",
    "        return\n",
    "\n",
    "    for genre in genres:\n",
    "        gdisp = token_to_display(genre)\n",
    "        out_dir = OUT_ROOT / genre\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Load per-user counts for every (K, run)\n",
    "        counts_map = {}      # (K, run) -> Series (user -> count)\n",
    "        missing     = []\n",
    "        for K in K_LIST:\n",
    "            for run in RUNS:\n",
    "                f = path_for_run(BASE_DIR, genre, run, K)\n",
    "                if not f.exists():\n",
    "                    missing.append(f\"[MISSING] {f.name}\")\n",
    "                    continue\n",
    "                try:\n",
    "                    s = per_user_counts(f, genre)\n",
    "                    counts_map[(K,run)] = s\n",
    "                except Exception as e:\n",
    "                    missing.append(f\"[ERROR] {f.name} -> {e}\")\n",
    "\n",
    "        if not counts_map:\n",
    "            print(f\"[SKIP] No usable data for genre {genre}\")\n",
    "            continue\n",
    "\n",
    "        # ---------- STATS & OUTPUT TABLES ----------\n",
    "        # Summary stats per (K,run)\n",
    "        rows = []\n",
    "        for (K,run), s in counts_map.items():\n",
    "            if s.empty: continue\n",
    "            rows.append({\n",
    "                \"genre\": genre,\n",
    "                \"K\": K,\n",
    "                \"run\": run,\n",
    "                \"n_users\": int(s.size),\n",
    "                \"mean\": float(s.mean()),\n",
    "                \"median\": float(s.median()),\n",
    "                \"std\": float(s.std(ddof=1)) if s.size>1 else 0.0,\n",
    "                \"min\": int(s.min()),\n",
    "                \"q1\": float(np.percentile(s, 25)),\n",
    "                \"q3\": float(np.percentile(s, 75)),\n",
    "                \"max\": int(s.max()),\n",
    "            })\n",
    "        stats_df = pd.DataFrame(rows)\n",
    "        if not stats_df.empty:\n",
    "            stats_df[\"run_ord\"] = stats_df[\"run\"].map(RUN2ORD)\n",
    "            stats_df = stats_df.sort_values([\"K\",\"run_ord\"]).drop(columns=[\"run_ord\"])\n",
    "        stats_csv = out_dir / f\"{genre}_summary_stats.csv\"\n",
    "        stats_df.to_csv(stats_csv, index=False)\n",
    "\n",
    "        # Pretty TXT (mean + median like your schema)\n",
    "        lines = []\n",
    "        for K in K_LIST:\n",
    "            sub = stats_df[stats_df[\"K\"]==K].set_index(\"run\").reindex(RUNS)\n",
    "            for run in RUNS:\n",
    "                if run in sub.index and pd.notna(sub.loc[run,\"mean\"]):\n",
    "                    tag = \"ORIGINAL\" if run==\"ORIGINAL\" else f\"n{run}\"\n",
    "                    mean_v = sub.loc[run,\"mean\"]\n",
    "                    med_v  = sub.loc[run,\"median\"]\n",
    "                    lines.append(f\"K={K} | {tag} avg_books_per_user for {gdisp} genre: {mean_v:.3f}  (median {med_v:.3f})\")\n",
    "            lines.append(\"\")\n",
    "        if missing:\n",
    "            lines.append(\"Notes:\")\n",
    "            lines.extend(missing)\n",
    "        with open(out_dir / f\"{genre}_summary.txt\",\"w\") as f:\n",
    "            f.write(\"\\n\".join(lines).strip()+\"\\n\")\n",
    "\n",
    "        # Distribution (exact frequency of counts 0..K) per (K,run)\n",
    "        freq_rows = []\n",
    "        freq_map = {}\n",
    "        for (K,run), s in counts_map.items():\n",
    "            # exact frequencies over 0..K\n",
    "            idx = list(range(0, K+1))\n",
    "            vc  = s.value_counts().reindex(idx, fill_value=0).sort_index()\n",
    "            freq_map[(K,run)] = vc\n",
    "            for c, freq in vc.items():\n",
    "                freq_rows.append({\"genre\":genre, \"K\":K, \"run\":run, \"count\":int(c), \"freq\":int(freq)})\n",
    "        freq_df = pd.DataFrame(freq_rows)\n",
    "        freq_csv = out_dir / f\"{genre}_count_frequencies.csv\"\n",
    "        freq_df.to_csv(freq_csv, index=False)\n",
    "\n",
    "        # Stacked 6-bucket frequencies (0,1,2,3,4,5+)\n",
    "        bucket_rows = []\n",
    "        for (K,run), s in counts_map.items():\n",
    "            b = six_bucket_counts(s)\n",
    "            for bucket, freq in b.items():\n",
    "                bucket_rows.append({\"genre\":genre, \"K\":K, \"run\":run, \"bucket\":bucket, \"freq\":int(freq)})\n",
    "        buckets_df = pd.DataFrame(bucket_rows)\n",
    "        buckets_csv = out_dir / f\"{genre}_bucket6_frequencies.csv\"\n",
    "        buckets_df.to_csv(buckets_csv, index=False)\n",
    "\n",
    "        # ---------- FIGURES ----------\n",
    "        # 1) Mean bar chart\n",
    "        fig, ax = plt.subplots(figsize=(10.5, 5.8))\n",
    "        plot_bar_means(ax, stats_df, gdisp)\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(out_dir / f\"{genre}_bar_mean.png\", dpi=180)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # 2) Boxplots (3 subplots)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(13.5, 4.8), sharey=False)\n",
    "        plot_boxplots(axes, counts_map, gdisp)\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(out_dir / f\"{genre}_boxplots.png\", dpi=180, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        # 3) Violin plots (3 subplots)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(13.5, 4.8), sharey=False)\n",
    "        plot_violins(axes, counts_map, gdisp)\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(out_dir / f\"{genre}_violins.png\", dpi=180, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        # 4) Stacked buckets (0..5+) per K\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(13.5, 4.8), sharey=False)\n",
    "        plot_stacked_buckets(axes, buckets_df, gdisp)\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(out_dir / f\"{genre}_stacked_buckets.png\", dpi=180, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        # 5) Heatmaps per K (rows=count 0..K, cols=runs)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(14, 4.8), sharey=False)\n",
    "        plot_heatmaps(axes, freq_map, gdisp)\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(out_dir / f\"{genre}_heatmaps.png\", dpi=180, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        # 6) Median trend lines with IQR band\n",
    "        fig, ax = plt.subplots(figsize=(10.5, 5.4))\n",
    "        plot_median_trends(ax, stats_df, gdisp)\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(out_dir / f\"{genre}_median_trend.png\", dpi=180)\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\"[OK] {genre}: all visualizations + tables saved to {out_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users who rated item 1: 22806\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# count_users_for_item.py\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- config ---\n",
    "CANDIDATE_FILES = [\n",
    "    Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/data/df_final_with_genres.csv\"),\n",
    "]\n",
    "USER_COL = \"user_id\"\n",
    "ITEM_ID = 1\n",
    "ITEM_COL_CANDIDATES = (\"item_id\", \"book_id\", \"id\", \"ItemID\", \"BookID\")\n",
    "\n",
    "def main():\n",
    "    # load first existing file\n",
    "    for f in CANDIDATE_FILES:\n",
    "        if f.exists():\n",
    "            df = pd.read_csv(f, low_memory=False)\n",
    "            break\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No input file found. Update CANDIDATE_FILES.\")\n",
    "\n",
    "    # pick item column\n",
    "    item_col = next((c for c in ITEM_COL_CANDIDATES if c in df.columns), None)\n",
    "    if item_col is None:\n",
    "        raise ValueError(f\"No item id column found. Expected one of {ITEM_COL_CANDIDATES}\")\n",
    "\n",
    "    # coerce types\n",
    "    df[item_col] = pd.to_numeric(df[item_col], errors=\"coerce\")\n",
    "    df[USER_COL] = pd.to_numeric(df[USER_COL], errors=\"coerce\")\n",
    "    if \"rating\" in df.columns:\n",
    "        df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\")\n",
    "\n",
    "    # filter: item matches & rating present (non-NaN). 0 is a valid rating.\n",
    "    if \"rating\" in df.columns:\n",
    "        mask = (df[item_col] == ITEM_ID) & (~df[\"rating\"].isna())\n",
    "    else:\n",
    "        # if no rating column exists, count any interaction as a \"rating\"\n",
    "        mask = (df[item_col] == ITEM_ID)\n",
    "\n",
    "    n_users = df.loc[mask, USER_COL].nunique()\n",
    "    print(f\"Users who rated item {ITEM_ID}: {n_users}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: books_summary_viz_all13/box_avg_rating_by_genre_all13.png\n",
      "Saved: books_summary_viz_all13/genre_rating_box_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# boxplot_all_13_genres.py  — Jupyter-safe (no seaborn)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def boxplot_all_genres(csv_path=\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/data/avg_pool_injection/books_summary.csv\",\n",
    "                       outdir=\"books_summary_viz_all13\"):\n",
    "    csv_path = Path(csv_path)\n",
    "    outdir = Path(outdir); outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "    req = {\"book_id\",\"primary_genre\",\"avg_rating_book_used\",\"n_users_rated\"}\n",
    "    missing = req - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"books_summary.csv missing {missing}\")\n",
    "\n",
    "    df[\"avg_rating_book_used\"] = pd.to_numeric(df[\"avg_rating_book_used\"], errors=\"coerce\")\n",
    "    df[\"n_users_rated\"] = pd.to_numeric(df[\"n_users_rated\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"primary_genre\",\"avg_rating_book_used\"])\n",
    "\n",
    "    # Use ALL genres (should be 13 for your setup). Order by book count (desc) for readability.\n",
    "    genre_order = (\n",
    "        df[\"primary_genre\"].astype(str).value_counts().sort_values(ascending=False).index.tolist()\n",
    "    )\n",
    "\n",
    "    data = [df.loc[df[\"primary_genre\"] == g, \"avg_rating_book_used\"].values for g in genre_order]\n",
    "\n",
    "    # --- Box plot for all 13 genres in one figure ---\n",
    "    plt.figure(figsize=(max(12, 0.9*len(genre_order)+8), 6))\n",
    "    plt.boxplot(data, labels=genre_order, showfliers=False)\n",
    "    plt.xticks(rotation=35, ha=\"right\")\n",
    "    plt.ylabel(\"Average rating used (0–5)\")\n",
    "    plt.title(\"Per-genre distribution of book average ratings (all 13 genres)\")\n",
    "    plt.tight_layout()\n",
    "    out_png = outdir / \"box_avg_rating_by_genre_all13.png\"\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close()\n",
    "    print(\"Saved:\", out_png)\n",
    "\n",
    "    # --- Optional: per-genre summary stats ---\n",
    "    stats = (\n",
    "        df.groupby(\"primary_genre\")[\"avg_rating_book_used\"]\n",
    "          .agg(n_books=\"count\", mean=\"mean\", median=\"median\", p25=lambda s: s.quantile(0.25), p75=lambda s: s.quantile(0.75))\n",
    "          .reindex(genre_order)\n",
    "          .reset_index()\n",
    "    )\n",
    "    out_csv = outdir / \"genre_rating_box_stats.csv\"\n",
    "    stats.to_csv(out_csv, index=False)\n",
    "    print(\"Saved:\", out_csv)\n",
    "\n",
    "# Run:\n",
    "boxplot_all_genres()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/notebook/0904/books_summary_viz\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# viz_books_summary.py  (Jupyter-safe)\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def viz_books_summary(csv_path, outdir=\"books_summary_viz\", support=50):\n",
    "    SUMMARY_CSV = Path(csv_path)\n",
    "    OUT_DIR = Path(outdir); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(SUMMARY_CSV)\n",
    "    expected = {\"book_id\", \"primary_genre\", \"avg_rating_book_used\", \"n_users_rated\"}\n",
    "    missing = expected - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns {missing} in {SUMMARY_CSV}\")\n",
    "\n",
    "    df[\"book_id\"] = pd.to_numeric(df[\"book_id\"], errors=\"coerce\")\n",
    "    df[\"avg_rating_book_used\"] = pd.to_numeric(df[\"avg_rating_book_used\"], errors=\"coerce\")\n",
    "    df[\"n_users_rated\"] = pd.to_numeric(df[\"n_users_rated\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"book_id\", \"avg_rating_book_used\", \"n_users_rated\"]).copy()\n",
    "\n",
    "    # 1) Histogram: avg ratings (0..5)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.hist(df[\"avg_rating_book_used\"].values, bins=30, range=(0,5))\n",
    "    plt.xlabel(\"Average rating used (0–5)\")\n",
    "    plt.ylabel(\"Number of books\")\n",
    "    plt.title(\"Distribution of per-book average ratings\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / \"hist_avg_rating.png\", dpi=160); plt.close()\n",
    "\n",
    "    # 2) Histogram: #users rated (log-y)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.hist(df[\"n_users_rated\"].values, bins=50)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"# of users who rated the book\")\n",
    "    plt.ylabel(\"Number of books (log scale)\")\n",
    "    plt.title(\"Distribution of #users rated per book\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / \"hist_n_users_rated_logy.png\", dpi=160); plt.close()\n",
    "\n",
    "    # 3) Scatter: popularity vs rating (log-y)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.scatter(df[\"avg_rating_book_used\"].values, df[\"n_users_rated\"].values, s=6, alpha=0.5)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"Average rating used\")\n",
    "    plt.ylabel(\"# of users rated (log scale)\")\n",
    "    plt.title(\"Popularity vs. average rating (each dot = one book)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / \"scatter_rating_vs_popularity.png\", dpi=160); plt.close()\n",
    "\n",
    "    # 4) Bar: books per genre (top-12)\n",
    "    genre_counts = df[\"primary_genre\"].astype(str).value_counts().head(12)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(genre_counts.index.astype(str), genre_counts.values)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"Primary genre (top 12)\")\n",
    "    plt.ylabel(\"# of books\")\n",
    "    plt.title(\"Book counts by primary genre (top 12)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / \"bar_books_per_genre_top12.png\", dpi=160); plt.close()\n",
    "\n",
    "    # 5) Boxplot: avg ratings per genre (top-8 by count)\n",
    "    top_genres = list(genre_counts.index[:8])\n",
    "    data_for_box = [df.loc[df[\"primary_genre\"] == g, \"avg_rating_book_used\"].values for g in top_genres]\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.boxplot(data_for_box, labels=top_genres, showfliers=False)\n",
    "    plt.xticks(rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"Average rating used\")\n",
    "    plt.title(\"Average ratings by genre (top 8 by book count)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / \"box_avg_rating_by_genre_top8.png\", dpi=160); plt.close()\n",
    "\n",
    "    # 6) CSV snapshots: extremes\n",
    "    df.sort_values(\"n_users_rated\", ascending=False).head(20)[\n",
    "        [\"book_id\", \"primary_genre\", \"avg_rating_book_used\", \"n_users_rated\"]\n",
    "    ].to_csv(OUT_DIR / \"top20_most_rated.csv\", index=False)\n",
    "\n",
    "    df[df[\"n_users_rated\"] >= support].sort_values(\n",
    "        [\"avg_rating_book_used\", \"n_users_rated\"], ascending=[False, False]\n",
    "    ).head(20)[[\"book_id\", \"primary_genre\", \"avg_rating_book_used\", \"n_users_rated\"]].to_csv(\n",
    "        OUT_DIR / f\"top20_highest_rated_min{support}.csv\", index=False\n",
    "    )\n",
    "\n",
    "    print(\"Saved to:\", OUT_DIR.resolve())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Notebook-safe: ignore unknown args like --f=...\n",
    "    parser = argparse.ArgumentParser(add_help=False)\n",
    "    parser.add_argument(\"--csv\", default=\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/data/avg_pool_injection/books_summary.csv\")\n",
    "    parser.add_argument(\"--outdir\", default=\"books_summary_viz\")\n",
    "    parser.add_argument(\"--support\", type=int, default=50)\n",
    "    args, _unknown = parser.parse_known_args(sys.argv[1:])\n",
    "    viz_books_summary(args.csv, args.outdir, args.support)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
