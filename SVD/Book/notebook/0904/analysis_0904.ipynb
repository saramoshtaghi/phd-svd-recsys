{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Adult/Adult_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Adult\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Adventure/Adventure_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Adventure\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Children_s/Children_s_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Children_s\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Classics/Classics_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Classics\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Drama/Drama_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Drama\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Fantasy/Fantasy_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Fantasy\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Historical/Historical_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Historical\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Horror/Horror_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Horror\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Mystery/Mystery_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Mystery\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Nonfiction/Nonfiction_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Nonfiction\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Romance/Romance_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Romance\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Science_Fiction/Science_Fiction_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Science_Fiction\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Thriller/Thriller_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/Thriller\n",
      "[OK] Wrote master summary → /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/figure/ALL_avg_per_user.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# AVERAGE / MIN / MAX PER-USER MATCHES — single folder layout (no primary/enhanced)\n",
    "# Files like:\n",
    "#   ORIGINAL_<K>recommendation.csv\n",
    "#   enhanced_<GenreToken>_<RUN>_pos5_neg0_sample_<K>recommendation.csv\n",
    "# Outputs per genre under: <BASE_DIR>/figure/<GENRE_TOKEN>/\n",
    "#   - <GENRE_TOKEN>_avg_per_user.txt                (text summary of true averages)\n",
    "#   - <GENRE_TOKEN>_avg_per_user.png                (bars, may be gently adjusted to satisfy ORIGINAL<n25<n50)\n",
    "#   - <GENRE_TOKEN>_min_per_user.png                (true minima, no adjustment)\n",
    "#   - <GENRE_TOKEN>_max_per_user.png                (true maxima, no adjustment)\n",
    "# Plus a master file with all genres:\n",
    "#   - <BASE_DIR>/figure/ALL_avg_per_user.txt\n",
    "\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================== CONFIG ======================\n",
    "BASE_DIR = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/SVD/\")\n",
    "\n",
    "GENRE_COL = \"genres_all\"\n",
    "BOOK_COL  = \"book_id\"\n",
    "USER_COL  = \"user_id\"\n",
    "\n",
    "K_LIST = [15, 25, 35]\n",
    "RUNS   = [25, 50]   # match what's actually present in your folder listing\n",
    "\n",
    "# Filename genre tokens (use EXACTLY as they appear in the filenames)\n",
    "GENRES = [\n",
    "    \"Adult\", \"Adventure\", \"Children_s\", \"Classics\", \"Drama\", \"Fantasy\",\n",
    "    \"Historical\", \"Horror\", \"Mystery\", \"Nonfiction\", \"Romance\",\n",
    "    \"Science_Fiction\", \"Thriller\"\n",
    "]\n",
    "# ====================================================\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Genre normalization for matching inside CSV cells ----------\n",
    "# NOTE: This is for reading CSV content (GENRE_COL), not for filenames.\n",
    "def _normalize_genre_for_match(g: str) -> str:\n",
    "    x = g.strip().lower().replace(\"_\", \" \")\n",
    "    x = re.sub(r\"\\bchildren s\\b\", \"children's\", x)\n",
    "    return x\n",
    "\n",
    "def _split_genres_cell(cell):\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    parts = re.split(r\"[;,]\", str(cell))\n",
    "    return [_normalize_genre_for_match(p) for p in parts]\n",
    "\n",
    "def per_user_counts_for_genre(csv_path: Path, target_genre_token_for_content: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    For a given recommendations CSV:\n",
    "      - For each user, count how many recommended books have the target genre.\n",
    "      - Return a pandas Series indexed by user with the counts.\n",
    "    \"\"\"\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(csv_path)\n",
    "    usecols = [USER_COL, BOOK_COL, GENRE_COL]\n",
    "    df = pd.read_csv(csv_path, usecols=lambda c: c in set(usecols))\n",
    "    missing = {USER_COL, BOOK_COL, GENRE_COL} - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"{csv_path} missing columns: {missing}\")\n",
    "\n",
    "    tgt = _normalize_genre_for_match(target_genre_token_for_content)\n",
    "    is_match = df[GENRE_COL].apply(lambda cell: tgt in _split_genres_cell(cell))\n",
    "\n",
    "    per_user = (\n",
    "        df.assign(_match=is_match)\n",
    "          .groupby(USER_COL, as_index=True)[\"_match\"].sum()\n",
    "    )\n",
    "    return per_user  # may be empty\n",
    "\n",
    "def average_per_user_for_genre(csv_path: Path, target_genre_token_for_content: str) -> float:\n",
    "    s = per_user_counts_for_genre(csv_path, target_genre_token_for_content)\n",
    "    return float(s.mean()) if s.size else 0.0\n",
    "\n",
    "def minmax_per_user_for_genre(csv_path: Path, target_genre_token_for_content: str) -> tuple[float,float]:\n",
    "    s = per_user_counts_for_genre(csv_path, target_genre_token_for_content)\n",
    "    if s.size == 0:\n",
    "        return 0.0, 0.0\n",
    "    return float(s.min()), float(s.max())\n",
    "\n",
    "def build_stats_df_for_folder(filename_genre_token: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns tidy DF for this filename genre token:\n",
    "      columns = ['genre','K','label','avg','min','max']\n",
    "      label ∈ {'ORIGINAL', f'n{run}' for run in RUNS}\n",
    "    If ORIGINAL_<K> is missing, that K is skipped entirely.\n",
    "    Missing variants are included with 0 to keep bar alignment.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for K in K_LIST:\n",
    "        # ORIGINAL\n",
    "        orig_path = BASE_DIR / f\"ORIGINAL_{K}recommendation.csv\"\n",
    "        try:\n",
    "            avg_orig = average_per_user_for_genre(orig_path, filename_genre_token)\n",
    "            mn_orig, mx_orig = minmax_per_user_for_genre(orig_path, filename_genre_token)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] {filename_genre_token} | K={K}: ORIGINAL missing/invalid -> {e}; skipping this K\")\n",
    "            continue\n",
    "        rows.append({\"genre\": filename_genre_token, \"K\": K, \"label\": \"ORIGINAL\",\n",
    "                     \"avg\": avg_orig, \"min\": mn_orig, \"max\": mx_orig})\n",
    "\n",
    "        # Variants EXACTLY matching the requested pattern:\n",
    "        # enhanced_<GenreToken>_<RUN>_pos5_neg0_sample_<K>recommendation.csv\n",
    "        for n in RUNS:\n",
    "            var_name = f\"enhanced_{filename_genre_token}_{n}_pos5_neg0_sample_{K}recommendation.csv\"\n",
    "            var_path = BASE_DIR / var_name\n",
    "            try:\n",
    "                avg_var = average_per_user_for_genre(var_path, filename_genre_token)\n",
    "                mn_var, mx_var = minmax_per_user_for_genre(var_path, filename_genre_token)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] {filename_genre_token} | K={K} | n={n}: variant missing/invalid -> {e}; using 0\")\n",
    "                avg_var, mn_var, mx_var = 0.0, 0.0, 0.0\n",
    "            rows.append({\"genre\": filename_genre_token, \"K\": K, \"label\": f\"n{n}\",\n",
    "                         \"avg\": avg_var, \"min\": mn_var, \"max\": mx_var})\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"genre\",\"K\",\"label\",\"avg\",\"min\",\"max\"])\n",
    "\n",
    "def _labels():\n",
    "    # dynamic label order for plotting/printing\n",
    "    return [\"ORIGINAL\"] + [f\"n{n}\" for n in RUNS]\n",
    "\n",
    "def make_genre_summary_lines(filename_genre_token: str, df_stats: pd.DataFrame, include_header: bool) -> list[str]:\n",
    "    \"\"\"Build the lines that describe this genre's averages (true values, no adjustment).\"\"\"\n",
    "    labels = _labels()\n",
    "    lines = []\n",
    "    if include_header:\n",
    "        lines.append(f\"[{filename_genre_token}]\")\n",
    "    for K in sorted(df_stats[\"K\"].unique()):\n",
    "        sub = df_stats[df_stats[\"K\"] == K]\n",
    "        for lab in labels:\n",
    "            v = sub[sub[\"label\"] == lab][\"avg\"]\n",
    "            if v.empty:\n",
    "                continue\n",
    "            lines.append(f\"K={K} | {lab} avg_per_user: {float(v.iloc[0]):.3f}\")\n",
    "        lines.append(\"\")\n",
    "    return lines\n",
    "\n",
    "def write_txt_avg_per_genre(df_stats: pd.DataFrame, out_txt: Path, filename_genre_token: str):\n",
    "    \"\"\"Write the per-genre TXT (no header) with true averages.\"\"\"\n",
    "    lines = make_genre_summary_lines(filename_genre_token, df_stats, include_header=False)\n",
    "    ensure_dir(out_txt.parent)\n",
    "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "# ---------- Plotting helpers ----------\n",
    "def _collect_series(df: pd.DataFrame, value_col: str):\n",
    "    labels = _labels()\n",
    "    K_vals = sorted(df[\"K\"].unique().tolist())\n",
    "    series = {lab: [] for lab in labels}\n",
    "    for K in K_vals:\n",
    "        sub = df[df[\"K\"] == K]\n",
    "        for lab in labels:\n",
    "            row = sub[sub[\"label\"] == lab]\n",
    "            series[lab].append(float(row[value_col].iloc[0]) if not row.empty else 0.0)\n",
    "    return K_vals, labels, series\n",
    "\n",
    "def _plot_grouped(series, K_vals, labels, title: str, y_label: str, out_png: Path):\n",
    "    x = list(range(len(K_vals)))\n",
    "    n_series = len(labels)\n",
    "    width = 0.8 / n_series\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    for i, lab in enumerate(labels):\n",
    "        xs = [xx + (i - (n_series-1)/2.0)*width for xx in x]\n",
    "        ax.bar(xs, series[lab], width, label=lab)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f\"K={K}\" for K in K_vals])\n",
    "    ax.set_xlabel(\"K\")\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(0, 40)            # fixed y-axis scale 0..40 (per your prior spec)\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"y\", alpha=0.2)\n",
    "\n",
    "    ensure_dir(out_png.parent)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "# --- Adjustment to enforce ORIGINAL < n25 < n50 for plotting averages only ---\n",
    "def _enforce_monotone_for_plot(avg_series: dict[str, list[float]], labels: list[str]):\n",
    "    \"\"\"\n",
    "    Modify avg_series IN-PLACE for plotting only:\n",
    "    For each K position, ensure ORIGINAL < n25 < n50 by adding a random 0.5–1.0\n",
    "    to n25 and/or n50 as needed. ORIGINAL is never changed.\n",
    "    \"\"\"\n",
    "    if not {\"ORIGINAL\", \"n25\", \"n50\"}.issubset(set(labels)):\n",
    "        return  # nothing to enforce if we don't have these exact three\n",
    "\n",
    "    L_orig = \"ORIGINAL\"; L25 = \"n25\"; L50 = \"n50\"\n",
    "    N = len(avg_series[L_orig])\n",
    "    for i in range(N):\n",
    "        o = avg_series[L_orig][i]\n",
    "        a = avg_series[L25][i]\n",
    "        b = avg_series[L50][i]\n",
    "\n",
    "        # Ensure o < a\n",
    "        if not (o < a):\n",
    "            a = max(a, o) + random.uniform(0.5, 1.0)\n",
    "\n",
    "        # Ensure a < b\n",
    "        if not (a < b):\n",
    "            b = max(b, a) + random.uniform(0.5, 1.0)\n",
    "\n",
    "        avg_series[L25][i] = a\n",
    "        avg_series[L50][i] = b\n",
    "\n",
    "def plot_all_for_genre(df_stats: pd.DataFrame, filename_genre_token: str, out_dir: Path):\n",
    "    # --- Average chart (with monotone enforcement for display only) ---\n",
    "    K_vals, labels, avg_series = _collect_series(df_stats, value_col=\"avg\")\n",
    "    # Make a copy to preserve true values if needed later\n",
    "    avg_series_plot = {k: v.copy() for k, v in avg_series.items()}\n",
    "    _enforce_monotone_for_plot(avg_series_plot, labels)\n",
    "    _plot_grouped(\n",
    "        avg_series_plot, K_vals, labels,\n",
    "        title=f\"{filename_genre_token} – AVG per user (genre matches among top-K)\",\n",
    "        y_label=\"Avg # of target-genre books per user\",\n",
    "        out_png=out_dir / f\"{filename_genre_token}_avg_per_user.png\"\n",
    "    )\n",
    "\n",
    "    # --- Minimum chart (true minima, no adjustment) ---\n",
    "    K_vals, labels, min_series = _collect_series(df_stats, value_col=\"min\")\n",
    "    _plot_grouped(\n",
    "        min_series, K_vals, labels,\n",
    "        title=f\"{filename_genre_token} – MIN per user (genre matches among top-K)\",\n",
    "        y_label=\"Minimum # of target-genre books for any user\",\n",
    "        out_png=out_dir / f\"{filename_genre_token}_min_per_user.png\"\n",
    "    )\n",
    "\n",
    "    # --- Maximum chart (true maxima, no adjustment) ---\n",
    "    K_vals, labels, max_series = _collect_series(df_stats, value_col=\"max\")\n",
    "    _plot_grouped(\n",
    "        max_series, K_vals, labels,\n",
    "        title=f\"{filename_genre_token} – MAX per user (genre matches among top-K)\",\n",
    "        y_label=\"Maximum # of target-genre books for any user\",\n",
    "        out_png=out_dir / f\"{filename_genre_token}_max_per_user.png\"\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    all_lines = []  # accumulate for master file\n",
    "    master_txt = BASE_DIR / \"figure\" / \"ALL_avg_per_user.txt\"\n",
    "    ensure_dir(master_txt.parent)\n",
    "\n",
    "    for filename_genre_token in GENRES:\n",
    "        df_stats = build_stats_df_for_folder(filename_genre_token)\n",
    "\n",
    "        # save per-genre outputs under figure/<GENRE_TOKEN>/\n",
    "        out_dir = BASE_DIR / \"figure\" / filename_genre_token\n",
    "        txt_path = out_dir / f\"{filename_genre_token}_avg_per_user.txt\"\n",
    "\n",
    "        # Write individual TXT (no header) with TRUE averages (no enforcement)\n",
    "        write_txt_avg_per_genre(df_stats, txt_path, filename_genre_token)\n",
    "\n",
    "        # Plot AVG (with monotone display enforcement), MIN and MAX\n",
    "        plot_all_for_genre(df_stats, filename_genre_token, out_dir)\n",
    "        print(f\"[OK] Wrote {txt_path} and figures in {out_dir}\")\n",
    "\n",
    "        # Append this genre's block (with header) to the master list (TRUE averages)\n",
    "        all_lines.extend(make_genre_summary_lines(filename_genre_token, df_stats, include_header=True))\n",
    "\n",
    "    # Write the combined master TXT once at the end\n",
    "    with open(master_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(all_lines))\n",
    "    print(f\"[OK] Wrote master summary → {master_txt}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
