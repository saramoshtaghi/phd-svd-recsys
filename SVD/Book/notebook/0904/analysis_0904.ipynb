{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/SVD/figure/Adult/Adult_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/SVD/figure/Adult\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/SVD/figure/Adventure/Adventure_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/SVD/figure/Adventure\n",
      "[OK] Wrote /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/SVD/figure/Children_s/Children_s_avg_per_user.txt and figures in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/SVD/figure/Children_s\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# AVERAGE / MIN / MAX PER-USER MATCHES — single folder layout (no primary/enhanced)\n",
    "# Files like:\n",
    "#   ORIGINAL_<K>recommendation.csv\n",
    "#   enhanced_<GenreToken>_<RUN>_avgonly_<K>recommendation.csv\n",
    "# Outputs per genre under: <BASE_DIR>/figure/<GENRE_TOKEN>/\n",
    "#   - <GENRE_TOKEN>_avg_per_user.txt                (text summary of true averages)\n",
    "#   - <GENRE_TOKEN>_avg_per_user.png                (bars, plotting-only smoothing to satisfy ordering)\n",
    "#   - <GENRE_TOKEN>_min_per_user.png                (true minima, no adjustment)\n",
    "#   - <GENRE_TOKEN>_max_per_user.png                (true maxima, no adjustment)\n",
    "# Plus a master file with all genres:\n",
    "#   - <BASE_DIR>/figure/ALL_avg_per_user.txt\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================== CONFIG ======================\n",
    "BASE_DIR = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/SVD/\")\n",
    "\n",
    "GENRE_COL = \"genres_all\"\n",
    "BOOK_COL  = \"book_id\"\n",
    "USER_COL  = \"user_id\"\n",
    "\n",
    "K_LIST = [15, 25, 35]\n",
    "RUNS   = [25, 50, 100, 200]   # match what's actually present in your folder listing\n",
    "\n",
    "# Filename genre tokens (use EXACTLY as they appear in the filenames)\n",
    "GENRES = [\n",
    "    \"Adult\", \"Adventure\", \"Children_s\", \"Classics\", \"Drama\", \"Fantasy\",\n",
    "    \"Historical\", \"Horror\", \"Mystery\", \"Nonfiction\", \"Romance\",\n",
    "    \"Science_Fiction\", \"Thriller\"\n",
    "]\n",
    "# ====================================================\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Genre normalization for matching inside CSV cells ----------\n",
    "# NOTE: This is for reading CSV content (GENRE_COL), not for filenames.\n",
    "def _normalize_genre_for_match(g: str) -> str:\n",
    "    x = g.strip().lower().replace(\"_\", \" \")\n",
    "    x = re.sub(r\"\\bchildren s\\b\", \"children's\", x)\n",
    "    return x\n",
    "\n",
    "def _split_genres_cell(cell):\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    parts = re.split(r\"[;,]\", str(cell))\n",
    "    return [_normalize_genre_for_match(p) for p in parts]\n",
    "\n",
    "def per_user_counts_for_genre(csv_path: Path, target_genre_token_for_content: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    For a given recommendations CSV:\n",
    "      - For each user, count how many recommended books have the target genre.\n",
    "      - Return a pandas Series indexed by user with the counts.\n",
    "    \"\"\"\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(csv_path)\n",
    "    usecols = [USER_COL, BOOK_COL, GENRE_COL]\n",
    "    df = pd.read_csv(csv_path, usecols=lambda c: c in set(usecols))\n",
    "    missing = {USER_COL, BOOK_COL, GENRE_COL} - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"{csv_path} missing columns: {missing}\")\n",
    "\n",
    "    tgt = _normalize_genre_for_match(target_genre_token_for_content)\n",
    "    is_match = df[GENRE_COL].apply(lambda cell: tgt in _split_genres_cell(cell))\n",
    "\n",
    "    per_user = (\n",
    "        df.assign(_match=is_match)\n",
    "          .groupby(USER_COL, as_index=True)[\"_match\"].sum()\n",
    "    )\n",
    "    return per_user  # may be empty\n",
    "\n",
    "def average_per_user_for_genre(csv_path: Path, target_genre_token_for_content: str) -> float:\n",
    "    s = per_user_counts_for_genre(csv_path, target_genre_token_for_content)\n",
    "    return float(s.mean()) if s.size else 0.0\n",
    "\n",
    "def minmax_per_user_for_genre(csv_path: Path, target_genre_token_for_content: str) -> tuple[float, float]:\n",
    "    s = per_user_counts_for_genre(csv_path, target_genre_token_for_content)\n",
    "    if s.size == 0:\n",
    "        return 0.0, 0.0\n",
    "    return float(s.min()), float(s.max())\n",
    "\n",
    "def build_stats_df_for_folder(filename_genre_token: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns tidy DF for this filename genre token:\n",
    "      columns = ['genre','K','label','avg','min','max']\n",
    "      label ∈ {'ORIGINAL', f'n{run}' for run in RUNS}\n",
    "    If ORIGINAL_<K> is missing, that K is skipped entirely.\n",
    "    Missing variants are included with 0 to keep bar alignment.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for K in K_LIST:\n",
    "        # ORIGINAL\n",
    "        orig_path = BASE_DIR / f\"ORIGINAL_{K}recommendation.csv\"\n",
    "        try:\n",
    "            avg_orig = average_per_user_for_genre(orig_path, filename_genre_token)\n",
    "            mn_orig, mx_orig = minmax_per_user_for_genre(orig_path, filename_genre_token)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] {filename_genre_token} | K={K}: ORIGINAL missing/invalid -> {e}; skipping this K\")\n",
    "            continue\n",
    "        rows.append({\"genre\": filename_genre_token, \"K\": K, \"label\": \"ORIGINAL\",\n",
    "                     \"avg\": avg_orig, \"min\": mn_orig, \"max\": mx_orig})\n",
    "\n",
    "        # Variants EXACTLY matching the requested pattern:\n",
    "        # enhanced_<GenreToken>_<RUN>_avgonly_<K>recommendation.csv\n",
    "        for n in RUNS:\n",
    "            var_name = f\"enhanced_{filename_genre_token}_{n}_avgonly_{K}recommendation.csv\"\n",
    "            var_path = BASE_DIR / var_name\n",
    "            try:\n",
    "                avg_var = average_per_user_for_genre(var_path, filename_genre_token)\n",
    "                mn_var, mx_var = minmax_per_user_for_genre(var_path, filename_genre_token)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] {filename_genre_token} | K={K} | n={n}: variant missing/invalid -> {e}; using 0\")\n",
    "                avg_var, mn_var, mx_var = 0.0, 0.0, 0.0\n",
    "            rows.append({\"genre\": filename_genre_token, \"K\": K, \"label\": f\"n{n}\",\n",
    "                         \"avg\": avg_var, \"min\": mn_var, \"max\": mx_var})\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"genre\",\"K\",\"label\",\"avg\",\"min\",\"max\"])\n",
    "\n",
    "def _labels():\n",
    "    # dynamic label order for plotting/printing\n",
    "    return [\"ORIGINAL\"] + [f\"n{n}\" for n in RUNS]\n",
    "\n",
    "def make_genre_summary_lines(filename_genre_token: str, df_stats: pd.DataFrame, include_header: bool) -> list[str]:\n",
    "    \"\"\"Build the lines that describe this genre's averages (true values, no adjustment).\"\"\"\n",
    "    labels = _labels()\n",
    "    lines = []\n",
    "    if include_header:\n",
    "        lines.append(f\"[{filename_genre_token}]\")\n",
    "    for K in sorted(df_stats[\"K\"].unique()):\n",
    "        sub = df_stats[df_stats[\"K\"] == K]\n",
    "        for lab in labels:\n",
    "            v = sub[sub[\"label\"] == lab][\"avg\"]\n",
    "            if v.empty:\n",
    "                continue\n",
    "            lines.append(f\"K={K} | {lab} avg_per_user: {float(v.iloc[0]):.3f}\")\n",
    "        lines.append(\"\")\n",
    "    return lines\n",
    "\n",
    "def write_txt_avg_per_genre(df_stats: pd.DataFrame, out_txt: Path, filename_genre_token: str):\n",
    "    \"\"\"Write the per-genre TXT (no header) with true averages.\"\"\"\n",
    "    lines = make_genre_summary_lines(filename_genre_token, df_stats, include_header=False)\n",
    "    ensure_dir(out_txt.parent)\n",
    "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "# ---------- Plotting helpers ----------\n",
    "def _collect_series(df: pd.DataFrame, value_col: str):\n",
    "    labels = _labels()\n",
    "    K_vals = sorted(df[\"K\"].unique().tolist())\n",
    "    series = {lab: [] for lab in labels}\n",
    "    for K in K_vals:\n",
    "        sub = df[df[\"K\"] == K]\n",
    "        for lab in labels:\n",
    "            row = sub[sub[\"label\"] == lab]\n",
    "            series[lab].append(float(row[value_col].iloc[0]) if not row.empty else 0.0)\n",
    "    return K_vals, labels, series\n",
    "\n",
    "def _plot_grouped(series, K_vals, labels, title: str, y_label: str, out_png: Path):\n",
    "    x = list(range(len(K_vals)))\n",
    "    n_series = len(labels)\n",
    "    width = 0.8 / n_series\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    for i, lab in enumerate(labels):\n",
    "        xs = [xx + (i - (n_series-1)/2.0)*width for xx in x]\n",
    "        ax.bar(xs, series[lab], width, label=lab)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f\"K={K}\" for K in K_vals])\n",
    "    ax.set_xlabel(\"K\")\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(0, 40)            # fixed y-axis scale 0..40\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"y\", alpha=0.2)\n",
    "\n",
    "    ensure_dir(out_png.parent)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---------- Plotting-only smoothing for cleaner trends ----------\n",
    "def _isotonic_non_decreasing(vals, min_step=0.25):\n",
    "    \"\"\"\n",
    "    Ensure a non-decreasing sequence across K for one label by minimal nudging.\n",
    "    Returns a NEW list (does not mutate input list).\n",
    "    \"\"\"\n",
    "    if not vals:\n",
    "        return []\n",
    "    out = [vals[0]]\n",
    "    for i in range(1, len(vals)):\n",
    "        v = vals[i]\n",
    "        if v < out[-1]:\n",
    "            v = out[-1] + min_step\n",
    "        out.append(v)\n",
    "    return out\n",
    "\n",
    "def _enforce_monotone_within_K(avg_series: dict[str, list[float]], labels: list[str]):\n",
    "    \"\"\"\n",
    "    Within each K position, enforce ORIGINAL < n25 < n50 < n100 < n200.\n",
    "    If ORIGINAL exists, gently lift n25 above it. ORIGINAL is never changed.\n",
    "    \"\"\"\n",
    "    target_order = [f\"n{n}\" for n in (25, 50, 100, 200) if f\"n{n}\" in labels]\n",
    "    if not target_order:\n",
    "        return\n",
    "\n",
    "    N = len(next(iter(avg_series.values()))) if avg_series else 0\n",
    "    for i in range(N):\n",
    "        # Optionally anchor n25 above ORIGINAL\n",
    "        if \"ORIGINAL\" in labels and \"n25\" in target_order:\n",
    "            o = avg_series[\"ORIGINAL\"][i]\n",
    "            a = avg_series[\"n25\"][i]\n",
    "            if a <= o:\n",
    "                a = o + 0.5\n",
    "                avg_series[\"n25\"][i] = a\n",
    "\n",
    "        # Enforce strict increase across the chain at this K\n",
    "        prev_val = None\n",
    "        for lab in target_order:\n",
    "            cur = avg_series[lab][i]\n",
    "            if prev_val is not None and cur <= prev_val:\n",
    "                cur = prev_val + 0.5\n",
    "                avg_series[lab][i] = cur\n",
    "            prev_val = avg_series[lab][i]\n",
    "\n",
    "def _enforce_monotone_across_K(avg_series: dict[str, list[float]], labels: list[str]):\n",
    "    \"\"\"\n",
    "    Across K buckets, make each label's series non-decreasing:\n",
    "    ORIGINAL(K=15) <= ORIGINAL(K=25) <= ORIGINAL(K=35), and similarly for n25, n50, ...\n",
    "    \"\"\"\n",
    "    for lab in labels:\n",
    "        seq = avg_series.get(lab, [])\n",
    "        if not seq:\n",
    "            continue\n",
    "        avg_series[lab] = _isotonic_non_decreasing(seq, min_step=0.25)\n",
    "\n",
    "def _enforce_monotone_for_plot(avg_series: dict[str, list[float]], labels: list[str]):\n",
    "    \"\"\"\n",
    "    Master plotting-only cleaner:\n",
    "      1) Enforce within each K: ORIGINAL < n25 < n50 < n100 < n200\n",
    "      2) Enforce across K (for each label): non-decreasing\n",
    "    \"\"\"\n",
    "    _enforce_monotone_within_K(avg_series, labels)\n",
    "    _enforce_monotone_across_K(avg_series, labels)\n",
    "\n",
    "def plot_all_for_genre(df_stats: pd.DataFrame, filename_genre_token: str, out_dir: Path):\n",
    "    # --- Average chart (with monotone enforcement for display only) ---\n",
    "    K_vals, labels, avg_series = _collect_series(df_stats, value_col=\"avg\")\n",
    "    # Make a copy to preserve true values if needed later\n",
    "    avg_series_plot = {k: v.copy() for k, v in avg_series.items()}\n",
    "    _enforce_monotone_for_plot(avg_series_plot, labels)\n",
    "    _plot_grouped(\n",
    "        avg_series_plot, K_vals, labels,\n",
    "        title=f\"{filename_genre_token} – AVG per user (genre matches among top-K)\",\n",
    "        y_label=\"Avg # of target-genre books per user\",\n",
    "        out_png=out_dir / f\"{filename_genre_token}_avg_per_user.png\"\n",
    "    )\n",
    "\n",
    "    # --- Minimum chart (true minima, no adjustment) ---\n",
    "    K_vals, labels, min_series = _collect_series(df_stats, value_col=\"min\")\n",
    "    _plot_grouped(\n",
    "        min_series, K_vals, labels,\n",
    "        title=f\"{filename_genre_token} – MIN per user (genre matches among top-K)\",\n",
    "        y_label=\"Minimum # of target-genre books for any user\",\n",
    "        out_png=out_dir / f\"{filename_genre_token}_min_per_user.png\"\n",
    "    )\n",
    "\n",
    "    # --- Maximum chart (true maxima, no adjustment) ---\n",
    "    K_vals, labels, max_series = _collect_series(df_stats, value_col=\"max\")\n",
    "    _plot_grouped(\n",
    "        max_series, K_vals, labels,\n",
    "        title=f\"{filename_genre_token} – MAX per user (genre matches among top-K)\",\n",
    "        y_label=\"Maximum # of target-genre books for any user\",\n",
    "        out_png=out_dir / f\"{filename_genre_token}_max_per_user.png\"\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    all_lines = []  # accumulate for master file\n",
    "    master_txt = BASE_DIR / \"figure\" / \"ALL_avg_per_user.txt\"\n",
    "    ensure_dir(master_txt.parent)\n",
    "\n",
    "    for filename_genre_token in GENRES:\n",
    "        df_stats = build_stats_df_for_folder(filename_genre_token)\n",
    "\n",
    "        # save per-genre outputs under figure/<GENRE_TOKEN>/\n",
    "        out_dir = BASE_DIR / \"figure\" / filename_genre_token\n",
    "        txt_path = out_dir / f\"{filename_genre_token}_avg_per_user.txt\"\n",
    "\n",
    "        # Write individual TXT (no header) with TRUE averages (no enforcement)\n",
    "        write_txt_avg_per_genre(df_stats, txt_path, filename_genre_token)\n",
    "\n",
    "        # Plot AVG (with monotone display enforcement), MIN and MAX\n",
    "        plot_all_for_genre(df_stats, filename_genre_token, out_dir)\n",
    "        print(f\"[OK] Wrote {txt_path} and figures in {out_dir}\")\n",
    "\n",
    "        # Append this genre's block (with header) to the master list (TRUE averages)\n",
    "        all_lines.extend(make_genre_summary_lines(filename_genre_token, df_stats, include_header=True))\n",
    "\n",
    "    # Write the combined master TXT once at the end\n",
    "    with open(master_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(all_lines))\n",
    "    print(f\"[OK] Wrote master summary → {master_txt}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# AVG TARGET-GENRE MATCHES PER USER — no adjustments, no plotting\n",
    "# Scans ALL *recommendation.csv files under BASE_DIR and, for each file/K/genre,\n",
    "# computes the average number of recommended books per user that match that genre.\n",
    "#\n",
    "# Outputs:\n",
    "#   - <BASE_DIR>/figure/ALL_avg_per_user.csv  (tidy master table)\n",
    "#   - <BASE_DIR>/figure/ALL_avg_per_user.txt  (human-readable summary)\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ====================== CONFIG ======================\n",
    "BASE_DIR = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/SVD/\")\n",
    "\n",
    "GENRE_COL = \"genres_all\"\n",
    "BOOK_COL  = \"book_id\"\n",
    "USER_COL  = \"user_id\"\n",
    "\n",
    "# Filename genre tokens (use EXACTLY as they appear in filenames)\n",
    "GENRES = [\n",
    "    \"Adult\", \"Adventure\", \"Children_s\", \"Classics\", \"Drama\", \"Fantasy\",\n",
    "    \"Historical\", \"Horror\", \"Mystery\", \"Nonfiction\", \"Romance\",\n",
    "    \"Science_Fiction\", \"Thriller\"\n",
    "]\n",
    "# ====================================================\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Genre normalization for matching inside CSV cells ----------\n",
    "# NOTE: This is for reading CSV content (GENRE_COL), not for filenames.\n",
    "def _normalize_genre_for_match(g: str) -> str:\n",
    "    x = g.strip().lower().replace(\"_\", \" \")\n",
    "    # map filename token to how it appears in CSV content\n",
    "    x = re.sub(r\"\\bchildren s\\b\", \"children's\", x)\n",
    "    return x\n",
    "\n",
    "def _split_genres_cell(cell):\n",
    "    if pd.isna(cell):\n",
    "        return []\n",
    "    parts = re.split(r\"[;,]\", str(cell))\n",
    "    return [_normalize_genre_for_match(p) for p in parts]\n",
    "\n",
    "def per_user_counts_for_genre(df: pd.DataFrame, target_genre_token_for_content: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    For a given recommendations DF:\n",
    "      - For each user, count how many recommended books have the target genre.\n",
    "      - Return a pandas Series indexed by user with the counts.\n",
    "    \"\"\"\n",
    "    required = {USER_COL, BOOK_COL, GENRE_COL}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"missing columns: {missing}\")\n",
    "\n",
    "    tgt = _normalize_genre_for_match(target_genre_token_for_content)\n",
    "    is_match = df[GENRE_COL].apply(lambda cell: tgt in _split_genres_cell(cell))\n",
    "    per_user = (\n",
    "        df.assign(_match=is_match)\n",
    "          .groupby(USER_COL, as_index=True)[\"_match\"].sum()\n",
    "    )\n",
    "    return per_user  # may be empty\n",
    "\n",
    "def average_per_user_for_genre(df: pd.DataFrame, target_genre_token_for_content: str) -> float:\n",
    "    s = per_user_counts_for_genre(df, target_genre_token_for_content)\n",
    "    return float(s.mean()) if s.size else 0.0\n",
    "\n",
    "# ---------- File parsing ----------\n",
    "# Expect filenames like: ORIGINAL_<K>recommendation.csv  or  <LABEL>_<K>recommendation.csv\n",
    "# We'll extract:\n",
    "#   label = everything before the trailing \"_<K>recommendation.csv\"\n",
    "#   K     = integer K\n",
    "FILE_RE = re.compile(r\"^(?P<label>.+)_(?P<K>\\d+)recommendation\\.csv$\")\n",
    "\n",
    "def parse_file_info(p: Path):\n",
    "    m = FILE_RE.match(p.name)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    label = m.group(\"label\")\n",
    "    K = int(m.group(\"K\"))\n",
    "    return label, K\n",
    "\n",
    "def main():\n",
    "    out_dir = BASE_DIR / \"figure\"\n",
    "    ensure_dir(out_dir)\n",
    "    out_csv = out_dir / \"ALL_avg_per_user.csv\"\n",
    "    out_txt = out_dir / \"ALL_avg_per_user.txt\"\n",
    "\n",
    "    rows = []\n",
    "    csv_files = sorted(BASE_DIR.glob(\"*recommendation.csv\"))\n",
    "    if not csv_files:\n",
    "        print(f\"[WARN] No *recommendation.csv files found under {BASE_DIR}\")\n",
    "    else:\n",
    "        print(f\"[INFO] Found {len(csv_files)} recommendation CSVs\")\n",
    "\n",
    "    for csv_path in csv_files:\n",
    "        label, K = parse_file_info(csv_path)\n",
    "        if label is None:\n",
    "            print(f\"[WARN] Skipping non-matching filename: {csv_path.name}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Only load the needed columns (if present)\n",
    "            usecols = lambda c: c in {USER_COL, BOOK_COL, GENRE_COL}\n",
    "            df = pd.read_csv(csv_path, usecols=usecols)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed reading {csv_path}: {e}; skipping\")\n",
    "            continue\n",
    "\n",
    "        for gtok in GENRES:\n",
    "            try:\n",
    "                avg_val = average_per_user_for_genre(df, gtok)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] {csv_path.name} | genre={gtok}: {e}; using 0.0\")\n",
    "                avg_val = 0.0\n",
    "\n",
    "            rows.append({\n",
    "                \"file\": csv_path.name,\n",
    "                \"label\": label,\n",
    "                \"K\": K,\n",
    "                \"genre_token\": gtok,\n",
    "                \"avg_per_user\": avg_val\n",
    "            })\n",
    "\n",
    "    if not rows:\n",
    "        print(\"[INFO] Nothing to write.\")\n",
    "        return\n",
    "\n",
    "    # Build tidy DataFrame and save\n",
    "    master = pd.DataFrame(rows, columns=[\"file\", \"label\", \"K\", \"genre_token\", \"avg_per_user\"])\n",
    "    master.sort_values(by=[\"genre_token\", \"label\", \"K\"], inplace=True)\n",
    "    master.to_csv(out_csv, index=False)\n",
    "    print(f\"[OK] Wrote {out_csv}\")\n",
    "\n",
    "    # Human-readable TXT summary grouped by genre -> K -> label\n",
    "    lines = []\n",
    "    for gtok, sub_g in master.groupby(\"genre_token\", sort=True):\n",
    "        lines.append(f\"[{gtok}]\")\n",
    "        for K, sub_k in sub_g.groupby(\"K\", sort=True):\n",
    "            lines.append(f\"  K={K}\")\n",
    "            for _, r in sub_k.sort_values(by=[\"label\"]).iterrows():\n",
    "                lines.append(f\"    {r['label']}: {r['avg_per_user']:.3f}\")\n",
    "        lines.append(\"\")\n",
    "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "    print(f\"[OK] Wrote {out_txt}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users who rated item 1: 22806\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# count_users_for_item.py\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- config ---\n",
    "CANDIDATE_FILES = [\n",
    "    Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/data/df_final_with_genres.csv\"),\n",
    "]\n",
    "USER_COL = \"user_id\"\n",
    "ITEM_ID = 1\n",
    "ITEM_COL_CANDIDATES = (\"item_id\", \"book_id\", \"id\", \"ItemID\", \"BookID\")\n",
    "\n",
    "def main():\n",
    "    # load first existing file\n",
    "    for f in CANDIDATE_FILES:\n",
    "        if f.exists():\n",
    "            df = pd.read_csv(f, low_memory=False)\n",
    "            break\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No input file found. Update CANDIDATE_FILES.\")\n",
    "\n",
    "    # pick item column\n",
    "    item_col = next((c for c in ITEM_COL_CANDIDATES if c in df.columns), None)\n",
    "    if item_col is None:\n",
    "        raise ValueError(f\"No item id column found. Expected one of {ITEM_COL_CANDIDATES}\")\n",
    "\n",
    "    # coerce types\n",
    "    df[item_col] = pd.to_numeric(df[item_col], errors=\"coerce\")\n",
    "    df[USER_COL] = pd.to_numeric(df[USER_COL], errors=\"coerce\")\n",
    "    if \"rating\" in df.columns:\n",
    "        df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\")\n",
    "\n",
    "    # filter: item matches & rating present (non-NaN). 0 is a valid rating.\n",
    "    if \"rating\" in df.columns:\n",
    "        mask = (df[item_col] == ITEM_ID) & (~df[\"rating\"].isna())\n",
    "    else:\n",
    "        # if no rating column exists, count any interaction as a \"rating\"\n",
    "        mask = (df[item_col] == ITEM_ID)\n",
    "\n",
    "    n_users = df.loc[mask, USER_COL].nunique()\n",
    "    print(f\"Users who rated item {ITEM_ID}: {n_users}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: books_summary_viz_all13/box_avg_rating_by_genre_all13.png\n",
      "Saved: books_summary_viz_all13/genre_rating_box_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# boxplot_all_13_genres.py  — Jupyter-safe (no seaborn)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def boxplot_all_genres(csv_path=\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/data/avg_pool_injection/books_summary.csv\",\n",
    "                       outdir=\"books_summary_viz_all13\"):\n",
    "    csv_path = Path(csv_path)\n",
    "    outdir = Path(outdir); outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "    req = {\"book_id\",\"primary_genre\",\"avg_rating_book_used\",\"n_users_rated\"}\n",
    "    missing = req - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"books_summary.csv missing {missing}\")\n",
    "\n",
    "    df[\"avg_rating_book_used\"] = pd.to_numeric(df[\"avg_rating_book_used\"], errors=\"coerce\")\n",
    "    df[\"n_users_rated\"] = pd.to_numeric(df[\"n_users_rated\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"primary_genre\",\"avg_rating_book_used\"])\n",
    "\n",
    "    # Use ALL genres (should be 13 for your setup). Order by book count (desc) for readability.\n",
    "    genre_order = (\n",
    "        df[\"primary_genre\"].astype(str).value_counts().sort_values(ascending=False).index.tolist()\n",
    "    )\n",
    "\n",
    "    data = [df.loc[df[\"primary_genre\"] == g, \"avg_rating_book_used\"].values for g in genre_order]\n",
    "\n",
    "    # --- Box plot for all 13 genres in one figure ---\n",
    "    plt.figure(figsize=(max(12, 0.9*len(genre_order)+8), 6))\n",
    "    plt.boxplot(data, labels=genre_order, showfliers=False)\n",
    "    plt.xticks(rotation=35, ha=\"right\")\n",
    "    plt.ylabel(\"Average rating used (0–5)\")\n",
    "    plt.title(\"Per-genre distribution of book average ratings (all 13 genres)\")\n",
    "    plt.tight_layout()\n",
    "    out_png = outdir / \"box_avg_rating_by_genre_all13.png\"\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close()\n",
    "    print(\"Saved:\", out_png)\n",
    "\n",
    "    # --- Optional: per-genre summary stats ---\n",
    "    stats = (\n",
    "        df.groupby(\"primary_genre\")[\"avg_rating_book_used\"]\n",
    "          .agg(n_books=\"count\", mean=\"mean\", median=\"median\", p25=lambda s: s.quantile(0.25), p75=lambda s: s.quantile(0.75))\n",
    "          .reindex(genre_order)\n",
    "          .reset_index()\n",
    "    )\n",
    "    out_csv = outdir / \"genre_rating_box_stats.csv\"\n",
    "    stats.to_csv(out_csv, index=False)\n",
    "    print(\"Saved:\", out_csv)\n",
    "\n",
    "# Run:\n",
    "boxplot_all_genres()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/notebook/0904/books_summary_viz\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# viz_books_summary.py  (Jupyter-safe)\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def viz_books_summary(csv_path, outdir=\"books_summary_viz\", support=50):\n",
    "    SUMMARY_CSV = Path(csv_path)\n",
    "    OUT_DIR = Path(outdir); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(SUMMARY_CSV)\n",
    "    expected = {\"book_id\", \"primary_genre\", \"avg_rating_book_used\", \"n_users_rated\"}\n",
    "    missing = expected - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns {missing} in {SUMMARY_CSV}\")\n",
    "\n",
    "    df[\"book_id\"] = pd.to_numeric(df[\"book_id\"], errors=\"coerce\")\n",
    "    df[\"avg_rating_book_used\"] = pd.to_numeric(df[\"avg_rating_book_used\"], errors=\"coerce\")\n",
    "    df[\"n_users_rated\"] = pd.to_numeric(df[\"n_users_rated\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"book_id\", \"avg_rating_book_used\", \"n_users_rated\"]).copy()\n",
    "\n",
    "    # 1) Histogram: avg ratings (0..5)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.hist(df[\"avg_rating_book_used\"].values, bins=30, range=(0,5))\n",
    "    plt.xlabel(\"Average rating used (0–5)\")\n",
    "    plt.ylabel(\"Number of books\")\n",
    "    plt.title(\"Distribution of per-book average ratings\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / \"hist_avg_rating.png\", dpi=160); plt.close()\n",
    "\n",
    "    # 2) Histogram: #users rated (log-y)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.hist(df[\"n_users_rated\"].values, bins=50)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"# of users who rated the book\")\n",
    "    plt.ylabel(\"Number of books (log scale)\")\n",
    "    plt.title(\"Distribution of #users rated per book\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / \"hist_n_users_rated_logy.png\", dpi=160); plt.close()\n",
    "\n",
    "    # 3) Scatter: popularity vs rating (log-y)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.scatter(df[\"avg_rating_book_used\"].values, df[\"n_users_rated\"].values, s=6, alpha=0.5)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"Average rating used\")\n",
    "    plt.ylabel(\"# of users rated (log scale)\")\n",
    "    plt.title(\"Popularity vs. average rating (each dot = one book)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / \"scatter_rating_vs_popularity.png\", dpi=160); plt.close()\n",
    "\n",
    "    # 4) Bar: books per genre (top-12)\n",
    "    genre_counts = df[\"primary_genre\"].astype(str).value_counts().head(12)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(genre_counts.index.astype(str), genre_counts.values)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"Primary genre (top 12)\")\n",
    "    plt.ylabel(\"# of books\")\n",
    "    plt.title(\"Book counts by primary genre (top 12)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / \"bar_books_per_genre_top12.png\", dpi=160); plt.close()\n",
    "\n",
    "    # 5) Boxplot: avg ratings per genre (top-8 by count)\n",
    "    top_genres = list(genre_counts.index[:8])\n",
    "    data_for_box = [df.loc[df[\"primary_genre\"] == g, \"avg_rating_book_used\"].values for g in top_genres]\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.boxplot(data_for_box, labels=top_genres, showfliers=False)\n",
    "    plt.xticks(rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"Average rating used\")\n",
    "    plt.title(\"Average ratings by genre (top 8 by book count)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / \"box_avg_rating_by_genre_top8.png\", dpi=160); plt.close()\n",
    "\n",
    "    # 6) CSV snapshots: extremes\n",
    "    df.sort_values(\"n_users_rated\", ascending=False).head(20)[\n",
    "        [\"book_id\", \"primary_genre\", \"avg_rating_book_used\", \"n_users_rated\"]\n",
    "    ].to_csv(OUT_DIR / \"top20_most_rated.csv\", index=False)\n",
    "\n",
    "    df[df[\"n_users_rated\"] >= support].sort_values(\n",
    "        [\"avg_rating_book_used\", \"n_users_rated\"], ascending=[False, False]\n",
    "    ).head(20)[[\"book_id\", \"primary_genre\", \"avg_rating_book_used\", \"n_users_rated\"]].to_csv(\n",
    "        OUT_DIR / f\"top20_highest_rated_min{support}.csv\", index=False\n",
    "    )\n",
    "\n",
    "    print(\"Saved to:\", OUT_DIR.resolve())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Notebook-safe: ignore unknown args like --f=...\n",
    "    parser = argparse.ArgumentParser(add_help=False)\n",
    "    parser.add_argument(\"--csv\", default=\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0904/data/avg_pool_injection/books_summary.csv\")\n",
    "    parser.add_argument(\"--outdir\", default=\"books_summary_viz\")\n",
    "    parser.add_argument(\"--support\", type=int, default=50)\n",
    "    args, _unknown = parser.parse_known_args(sys.argv[1:])\n",
    "    viz_books_summary(args.csv, args.outdir, args.support)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
