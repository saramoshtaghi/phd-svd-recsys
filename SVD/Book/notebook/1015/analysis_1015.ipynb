{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysisis(also saved as .py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Found 1 pairs. Inventory written to /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/SVD_pair/result/pair_summary/figs_per_pos/_inventory\n",
      "[OK] Tall summary saved: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/SVD_pair/result/pair_summary/figs_per_pos/PAIR_POS_K_N_tall.csv\n",
      "[OK] Figures written to: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/SVD_pair/result/pair_summary/figs_per_pos/figures\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# summarize_pairs_figs_per_pos.py\n",
    "#\n",
    "# One figure per (pair, pos), each with 3 bins for K in {15,25,35}.\n",
    "# Bars inside each bin: Original, n=25, n=50, n=100, n=200.\n",
    "# Filenames expected:\n",
    "#   ORIGINAL_{K}recommendation.csv (under SVD_pair root)\n",
    "#   fpair_<A>__<B>_<n>u_pos{5|7}_neg0_all_{K}recommendation.csv (under SVD_pair/{5,7})\n",
    "#\n",
    "# Output:\n",
    "#   result/pair_summary/figs_per_pos/\n",
    "#     - figures/<pair_slug>__pos5.png\n",
    "#     - figures/<pair_slug>__pos7.png\n",
    "#   plus a tall CSV with all computed averages for convenience.\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Tuple, List, Set, Optional, Dict\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # headless\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ======== CONFIG ========\n",
    "BASE = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/SVD_pair\")\n",
    "ORIG_DIR = BASE                      # ORIGINAL_{K}recommendation.csv lives here\n",
    "POS_DIRS = [BASE / \"5\", BASE / \"7\"]  # poisoned branches /5 and /7\n",
    "\n",
    "OUT_ROOT = BASE / \"result\" / \"pair_summary\" / \"figs_per_pos\"\n",
    "FIG_DIR  = OUT_ROOT / \"figures\"\n",
    "INV_DIR  = OUT_ROOT / \"_inventory\"\n",
    "\n",
    "K_LIST = [15, 25, 35]\n",
    "N_LIST = [25, 50, 100, 200]\n",
    "\n",
    "# ======== HELPERS ========\n",
    "def slugify_pair(a: str, b: str) -> str:\n",
    "    import re as _re\n",
    "    def sg(x): return _re.sub(r\"[^A-Za-z0-9]+\", \"_\", x).strip(\"_\").lower()\n",
    "    a2, b2 = sorted([a, b], key=lambda x: x.lower())\n",
    "    return f\"{sg(a2)}__{sg(b2)}\"\n",
    "\n",
    "def normalize_tag(t: str) -> str:\n",
    "    t = str(t).strip().replace(\"_\", \" \")\n",
    "    if t == \"Children s\":\n",
    "        t = \"Children's\"\n",
    "    low = t.lower()\n",
    "    if low == \"science fiction\": t = \"Science Fiction\"\n",
    "    elif low == \"historical\":    t = \"Historical\"\n",
    "    elif low == \"nonfiction\":    t = \"Nonfiction\"\n",
    "    elif low == \"thriller\":      t = \"Thriller\"\n",
    "    elif low == \"drama\":         t = \"Drama\"\n",
    "    elif low == \"fantasy\":       t = \"Fantasy\"\n",
    "    elif low == \"mystery\":       t = \"Mystery\"\n",
    "    elif low == \"romance\":       t = \"Romance\"\n",
    "    elif low == \"horror\":        t = \"Horror\"\n",
    "    elif low == \"classics\":      t = \"Classics\"\n",
    "    elif low == \"adventure\":     t = \"Adventure\"\n",
    "    elif low == \"adult\":         t = \"Adult\"\n",
    "    return t\n",
    "\n",
    "def book_has_both(gen_all: str, A: str, B: str) -> bool:\n",
    "    if pd.isna(gen_all) or not str(gen_all).strip():\n",
    "        return False\n",
    "    parts = [x.strip() for x in str(gen_all).split(\",\") if str(x).strip()]\n",
    "    tags = [normalize_tag(x) for x in parts]\n",
    "    return (A in tags) and (B in tags)\n",
    "\n",
    "def per_user_avg_pair_count(rec_df: pd.DataFrame, A: str, B: str) -> Tuple[float, int]:\n",
    "    \"\"\"\n",
    "    rec_df columns expected: user_id, book_id, genres_all\n",
    "    Returns (average_count_per_user, num_users_in_this_csv)\n",
    "    \"\"\"\n",
    "    need = {\"user_id\", \"book_id\", \"genres_all\"}\n",
    "    missing = need - set(rec_df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"CSV missing columns: {missing}\")\n",
    "    users = rec_df[\"user_id\"].drop_duplicates().sort_values()\n",
    "    users_count = int(users.shape[0])\n",
    "    mask = rec_df[\"genres_all\"].apply(lambda s: book_has_both(s, A, B))\n",
    "    pair_df = rec_df[mask].copy()\n",
    "    if pair_df.empty:\n",
    "        return (0.0, users_count)\n",
    "    per_user = (\n",
    "        pair_df.groupby(\"user_id\", as_index=False)[\"book_id\"]\n",
    "               .count()\n",
    "               .rename(columns={\"book_id\": \"count\"})\n",
    "    )\n",
    "    all_users = pd.DataFrame({\"user_id\": users})\n",
    "    all_users = all_users.merge(per_user, on=\"user_id\", how=\"left\").fillna({\"count\": 0})\n",
    "    return (float(all_users[\"count\"].mean()), users_count)\n",
    "\n",
    "def injected_files_for_pair_k_n(pos_dir: Path, A: str, B: str, k: int, n: int) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Match fpair_<A>__<B>_<n>u_pos{5|7}_neg0_all_{k}recommendation.csv (order-insensitive for A/B).\n",
    "    \"\"\"\n",
    "    aT = re.sub(r\"_+\", \"_\", A.replace(\" \", \"_\").replace(\"'\", \"_\")).strip(\"_\")\n",
    "    bT = re.sub(r\"_+\", \"_\", B.replace(\" \", \"_\").replace(\"'\", \"_\")).strip(\"_\")\n",
    "    pat1 = re.compile(rf\"^fpair_{aT}__{bT}_{n}u_pos[57]_neg0_all_{k}recommendation\\.csv$\")\n",
    "    pat2 = re.compile(rf\"^fpair_{bT}__{aT}_{n}u_pos[57]_neg0_all_{k}recommendation\\.csv$\")\n",
    "    out: List[Path] = []\n",
    "    for p in pos_dir.glob(f\"*neg0_all_{k}recommendation.csv\"):\n",
    "        if pat1.match(p.name) or pat2.match(p.name):\n",
    "            out.append(p)\n",
    "    return sorted(out)\n",
    "\n",
    "def discover_pairs_from_dirs(pos_dirs: Iterable[Path], k_list: Iterable[int], n_list: Iterable[int]) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Parse file names under /5 and /7, return unique unordered (A,B) pairs present for valid K and n.\n",
    "    \"\"\"\n",
    "    pair_set: Set[Tuple[str, str]] = set()\n",
    "    regex = re.compile(\n",
    "        r\"^fpair_(?P<A>[A-Za-z0-9_']+)__(?P<B>[A-Za-z0-9_']+)_(?P<N>\\d+)u_pos[57]_neg0_all_(?P<K>\\d+)recommendation\\.csv$\"\n",
    "    )\n",
    "    valid_k = set(map(int, k_list))\n",
    "    valid_n = set(map(int, n_list))\n",
    "    for pos_dir in pos_dirs:\n",
    "        for p in pos_dir.glob(\"fpair_*u_pos*_neg0_all_*recommendation.csv\"):\n",
    "            m = regex.match(p.name)\n",
    "            if not m:\n",
    "                continue\n",
    "            k = int(m.group(\"K\"))\n",
    "            n = int(m.group(\"N\"))\n",
    "            if k not in valid_k or n not in valid_n:\n",
    "                continue\n",
    "            A_disp = normalize_tag(m.group(\"A\").replace(\"_\", \" \"))\n",
    "            B_disp = normalize_tag(m.group(\"B\").replace(\"_\", \" \"))\n",
    "            a_c, b_c = sorted([A_disp, B_disp], key=lambda x: x.lower())\n",
    "            pair_set.add((a_c, b_c))\n",
    "    return sorted(pair_set, key=lambda ab: (ab[0].lower(), ab[1].lower()))\n",
    "\n",
    "def original_file_for_k(orig_dir: Path, k: int) -> Optional[Path]:\n",
    "    p = orig_dir / f\"ORIGINAL_{k}recommendation.csv\"\n",
    "    return p if p.exists() else None\n",
    "\n",
    "def load_rec_csv(fp: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(fp, low_memory=False)\n",
    "    if \"genres_all\" not in df.columns:\n",
    "        if \"genre_g1\" in df.columns and \"genre_g2\" in df.columns:\n",
    "            df[\"genres_all\"] = df[[\"genre_g1\", \"genre_g2\"]].fillna(\"\").agg(\n",
    "                lambda x: \", \".join([t for t in [x[\"genre_g1\"], x[\"genre_g2\"]] if str(t).strip()]), axis=1\n",
    "            )\n",
    "        else:\n",
    "            df[\"genres_all\"] = \"\"\n",
    "    return df\n",
    "\n",
    "def plot_pair_pos_three_bins(pair_slug: str, A: str, B: str, pos_label: str,\n",
    "                             data_by_k: Dict[int, Dict[str, float]], out_png: Path):\n",
    "    \"\"\"\n",
    "    data_by_k: {K: {\"Original\": v0, \"25\": v25, \"50\": v50, \"100\": v100, \"200\": v200}}\n",
    "    \"\"\"\n",
    "    ks = sorted(data_by_k.keys())\n",
    "    groups = [\"Original\", \"25\", \"50\", \"100\", \"200\"]\n",
    "    # Build matrix values in K order:\n",
    "    vals = [[data_by_k.get(k, {}).get(g, 0.0) for g in groups] for k in ks]\n",
    "\n",
    "    # Plot: 3 bins (ks), 5 bars each\n",
    "    width = 0.16\n",
    "    x = range(len(ks))\n",
    "    plt.figure(figsize=(8, 4.2), dpi=160)\n",
    "\n",
    "    for j, g in enumerate(groups):\n",
    "        offs = [(i + (j - 2)*width) for i in x]  # center the 5 bars around each bin\n",
    "        plt.bar(offs, [vals[i][j] for i in range(len(ks))], width=width, label=(\"n=\"+g if g!=\"Original\" else \"Original\"))\n",
    "\n",
    "    plt.xticks(list(x), [f\"Top-{k}\" for k in ks])\n",
    "    plt.ylabel(\"Avg # of pair-books in Top-K per user\")\n",
    "    plt.title(f\"{A} + {B} â€” POS={pos_label}\")\n",
    "    plt.legend(ncol=3, fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_png)\n",
    "    plt.close()\n",
    "\n",
    "# ======== MAIN ========\n",
    "def main():\n",
    "    OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "    FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    INV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Discover pairs from poisoned dirs\n",
    "    PAIRS = discover_pairs_from_dirs(POS_DIRS, K_LIST, N_LIST)\n",
    "    if not PAIRS:\n",
    "        print(\"[WARN] No pairs found in /5 or /7.\")\n",
    "        return\n",
    "\n",
    "    with open(INV_DIR / \"discovered_pairs.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for a, b in PAIRS: f.write(f\"{a},{b}\\n\")\n",
    "    pd.DataFrame(PAIRS, columns=[\"A\",\"B\"]).to_csv(INV_DIR / \"discovered_pairs.csv\", index=False)\n",
    "    print(f\"[OK] Found {len(PAIRS)} pairs. Inventory written to {INV_DIR}\")\n",
    "\n",
    "    # Preload ORIGINAL per K (same for all pairs, but per-pair avg differs)\n",
    "    original_df_by_k: Dict[int, Optional[pd.DataFrame]] = {}\n",
    "    for k in K_LIST:\n",
    "        fp = original_file_for_k(ORIG_DIR, k)\n",
    "        if fp is None:\n",
    "            print(f\"[WARN] Missing ORIGINAL_{k}recommendation.csv in {ORIG_DIR}\")\n",
    "            original_df_by_k[k] = None\n",
    "        else:\n",
    "            original_df_by_k[k] = load_rec_csv(fp)\n",
    "\n",
    "    # Collect tall rows for all (pair, pos, K, n)\n",
    "    tall_rows = []  # columns: A,B,pair,pos,K,n,avg_count,users\n",
    "\n",
    "    # ORIGINAL tall rows (n=\"ORIGINAL\")\n",
    "    for (A, B) in PAIRS:\n",
    "        for k in K_LIST:\n",
    "            dfO = original_df_by_k.get(k)\n",
    "            if dfO is None: \n",
    "                continue\n",
    "            avgc, users_cnt = per_user_avg_pair_count(dfO, A, B)\n",
    "            tall_rows.append({\n",
    "                \"A\": A, \"B\": B, \"pair\": slugify_pair(A,B),\n",
    "                \"pos\": \"ORIGINAL\", \"K\": k, \"n\": \"ORIGINAL\",\n",
    "                \"avg_count\": avgc, \"users\": users_cnt\n",
    "            })\n",
    "\n",
    "    # Poisoned tall rows (per N separately; no averaging)\n",
    "    for pos_dir in POS_DIRS:\n",
    "        pos_label = pos_dir.name  # \"5\" or \"7\"\n",
    "        for (A, B) in PAIRS:\n",
    "            for k in K_LIST:\n",
    "                for n in N_LIST:\n",
    "                    files = injected_files_for_pair_k_n(pos_dir, A, B, k, n)\n",
    "                    if not files:\n",
    "                        continue\n",
    "                    # In case multiple files match (shouldn't, but safe): average them\n",
    "                    vals, users = [], []\n",
    "                    for f in files:\n",
    "                        try:\n",
    "                            df = load_rec_csv(f)\n",
    "                            avgc, users_cnt = per_user_avg_pair_count(df, A, B)\n",
    "                            vals.append(avgc); users.append(users_cnt)\n",
    "                        except Exception as e:\n",
    "                            print(f\"[ERROR] Reading {f}: {e}\")\n",
    "                    if vals:\n",
    "                        tall_rows.append({\n",
    "                            \"A\": A, \"B\": B, \"pair\": slugify_pair(A,B),\n",
    "                            \"pos\": pos_label, \"K\": k, \"n\": str(n),\n",
    "                            \"avg_count\": float(sum(vals)/len(vals)),\n",
    "                            \"users\": max(users) if users else 0\n",
    "                        })\n",
    "\n",
    "    # Save tall CSV\n",
    "    if tall_rows:\n",
    "        dft = pd.DataFrame(tall_rows)\n",
    "        out_csv = OUT_ROOT / \"PAIR_POS_K_N_tall.csv\"\n",
    "        dft.sort_values(by=[\"pair\",\"pos\",\"K\",\"n\"], inplace=True)\n",
    "        dft.to_csv(out_csv, index=False)\n",
    "        print(f\"[OK] Tall summary saved: {out_csv}\")\n",
    "    else:\n",
    "        print(\"[WARN] No rows computed. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Make figures: One figure per pair & per pos (5 and 7), each with 3 bins (K) and 5 bars (Original, 25,50,100,200)\n",
    "    dft = pd.read_csv(out_csv)\n",
    "    # ensure strings\n",
    "    dft[\"n\"] = dft[\"n\"].astype(str)\n",
    "    # iterate pairs\n",
    "    for (A, B) in PAIRS:\n",
    "        pair_slug = slugify_pair(A, B)\n",
    "        for pos_label in [\"5\", \"7\"]:\n",
    "            sub = dft[(dft[\"pair\"] == pair_slug) & (dft[\"pos\"].isin([\"ORIGINAL\", pos_label]))]\n",
    "            if sub.empty:\n",
    "                continue\n",
    "            # Build data_by_k\n",
    "            data_by_k: Dict[int, Dict[str, float]] = {}\n",
    "            for k in K_LIST:\n",
    "                data_by_k[k] = {\"Original\": 0.0, \"25\": 0.0, \"50\": 0.0, \"100\": 0.0, \"200\": 0.0}\n",
    "                # Original\n",
    "                sO = sub[(sub[\"K\"] == k) & (sub[\"pos\"] == \"ORIGINAL\") & (sub[\"n\"] == \"ORIGINAL\")]\n",
    "                if not sO.empty:\n",
    "                    data_by_k[k][\"Original\"] = float(sO.iloc[0][\"avg_count\"])\n",
    "                # N runs under this pos\n",
    "                for n_str in [\"25\",\"50\",\"100\",\"200\"]:\n",
    "                    sN = sub[(sub[\"K\"] == k) & (sub[\"pos\"] == pos_label) & (sub[\"n\"] == n_str)]\n",
    "                    if not sN.empty:\n",
    "                        data_by_k[k][n_str] = float(sN.iloc[0][\"avg_count\"])\n",
    "\n",
    "            out_png = FIG_DIR / f\"{pair_slug}__pos{pos_label}.png\"\n",
    "            plot_pair_pos_three_bins(pair_slug, A, B, pos_label, data_by_k, out_png)\n",
    "\n",
    "    print(f\"[OK] Figures written to: {FIG_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
