{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysisis(also saved as .py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Found 2 pairs across poisoned dirs.\n",
      "[OK] Saved CSVs: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/result/figures/5/summary_pos5.csv , /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/result/figures/7/summary_pos7.csv\n",
      "[OK] Figures written to:\n",
      "  /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/result/figures/5\n",
      "  /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/result/figures/7\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# summarize_pairs_figs_per_pos_1015.py\n",
    "#\n",
    "# One figure per (pair, pos), each with 3 bins (K in {15,25,35}).\n",
    "# Bars inside each bin: Original, n=25, n=50, n=100, n=200.\n",
    "# Matches your file naming:\n",
    "#   ORIGINAL_{K}recommendation.csv                (under SVD_pair root)\n",
    "#   fpair_<A>__<B>_<n>u_pos{5|7}_neg0_all_{K}recommendation.csv (under SVD_pair/{5,7})\n",
    "#\n",
    "# Output (no inventory):\n",
    "#   /.../1015/result/figures/5/\n",
    "#       - <pair_slug>__pos5.png   (figure)\n",
    "#       - summary_pos5.csv        (all values for pos=5 incl. Original)\n",
    "#   /.../1015/result/figures/7/\n",
    "#       - <pair_slug>__pos7.png\n",
    "#       - summary_pos7.csv\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Tuple, List, Set, Optional, Dict\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # headless-safe\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ======== PATHS (1015) ========\n",
    "BASE = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/SVD_pair\")\n",
    "ORIG_DIR = BASE                      # ORIGINAL_{K}recommendation.csv lives here\n",
    "POS_DIRS = [BASE / \"5\", BASE / \"7\"]  # poisoned branches /5 and /7\n",
    "\n",
    "OUT_ROOT = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/result/figures\")\n",
    "OUT_5 = OUT_ROOT / \"5\"\n",
    "OUT_7 = OUT_ROOT / \"7\"\n",
    "\n",
    "K_LIST = [15, 25, 35]\n",
    "N_LIST = [25, 50, 100, 200]\n",
    "\n",
    "# ======== HELPERS ========\n",
    "def slugify_pair(a: str, b: str) -> str:\n",
    "    import re as _re\n",
    "    def sg(x): return _re.sub(r\"[^A-Za-z0-9]+\", \"_\", x).strip(\"_\").lower()\n",
    "    a2, b2 = sorted([a, b], key=lambda x: x.lower())\n",
    "    return f\"{sg(a2)}__{sg(b2)}\"\n",
    "\n",
    "def normalize_tag(t: str) -> str:\n",
    "    t = str(t).strip().replace(\"_\", \" \")\n",
    "    if t == \"Children s\":\n",
    "        t = \"Children's\"\n",
    "    low = t.lower()\n",
    "    if low == \"science fiction\": t = \"Science Fiction\"\n",
    "    elif low == \"historical\":    t = \"Historical\"\n",
    "    elif low == \"nonfiction\":    t = \"Nonfiction\"\n",
    "    elif low == \"thriller\":      t = \"Thriller\"\n",
    "    elif low == \"drama\":         t = \"Drama\"\n",
    "    elif low == \"fantasy\":       t = \"Fantasy\"\n",
    "    elif low == \"mystery\":       t = \"Mystery\"\n",
    "    elif low == \"romance\":       t = \"Romance\"\n",
    "    elif low == \"horror\":        t = \"Horror\"\n",
    "    elif low == \"classics\":      t = \"Classics\"\n",
    "    elif low == \"adventure\":     t = \"Adventure\"\n",
    "    elif low == \"adult\":         t = \"Adult\"\n",
    "    return t\n",
    "\n",
    "def book_has_both(gen_all: str, A: str, B: str) -> bool:\n",
    "    if pd.isna(gen_all) or not str(gen_all).strip():\n",
    "        return False\n",
    "    parts = [x.strip() for x in str(gen_all).split(\",\") if str(x).strip()]\n",
    "    tags = [normalize_tag(x) for x in parts]\n",
    "    return (A in tags) and (B in tags)\n",
    "\n",
    "def per_user_avg_pair_count(rec_df: pd.DataFrame, A: str, B: str) -> Tuple[float, int]:\n",
    "    \"\"\"\n",
    "    rec_df columns expected: user_id, book_id, genres_all\n",
    "    Returns (average_count_per_user, num_users_in_this_csv)\n",
    "    \"\"\"\n",
    "    need = {\"user_id\", \"book_id\", \"genres_all\"}\n",
    "    missing = need - set(rec_df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"CSV missing columns: {missing}\")\n",
    "    users = rec_df[\"user_id\"].drop_duplicates().sort_values()\n",
    "    users_count = int(users.shape[0])\n",
    "    mask = rec_df[\"genres_all\"].apply(lambda s: book_has_both(s, A, B))\n",
    "    pair_df = rec_df[mask].copy()\n",
    "    if pair_df.empty:\n",
    "        return (0.0, users_count)\n",
    "    per_user = (\n",
    "        pair_df.groupby(\"user_id\", as_index=False)[\"book_id\"]\n",
    "               .count()\n",
    "               .rename(columns={\"book_id\": \"count\"})\n",
    "    )\n",
    "    all_users = pd.DataFrame({\"user_id\": users})\n",
    "    all_users = all_users.merge(per_user, on=\"user_id\", how=\"left\").fillna({\"count\": 0})\n",
    "    return (float(all_users[\"count\"].mean()), users_count)\n",
    "\n",
    "def injected_files_for_pair_k_n(pos_dir: Path, A: str, B: str, k: int, n: int) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Match fpair_<A>__<B>_<n>u_pos{5|7}_neg0_all_{k}recommendation.csv (order-insensitive for A/B).\n",
    "    \"\"\"\n",
    "    aT = re.sub(r\"_+\", \"_\", A.replace(\" \", \"_\").replace(\"'\", \"_\")).strip(\"_\")\n",
    "    bT = re.sub(r\"_+\", \"_\", B.replace(\" \", \"_\").replace(\"'\", \"_\")).strip(\"_\")\n",
    "    pat1 = re.compile(rf\"^fpair_{aT}__{bT}_{n}u_pos[57]_neg0_all_{k}recommendation\\.csv$\")\n",
    "    pat2 = re.compile(rf\"^fpair_{bT}__{aT}_{n}u_pos[57]_neg0_all_{k}recommendation\\.csv$\")\n",
    "    out: List[Path] = []\n",
    "    for p in pos_dir.glob(f\"*neg0_all_{k}recommendation.csv\"):\n",
    "        if pat1.match(p.name) or pat2.match(p.name):\n",
    "            out.append(p)\n",
    "    return sorted(out)\n",
    "\n",
    "def discover_pairs_from_dirs(pos_dirs: Iterable[Path],\n",
    "                             k_list: Iterable[int],\n",
    "                             n_list: Iterable[int]) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Parse file names under /5 and /7, return unique unordered (A,B) pairs present for valid K and n.\n",
    "    \"\"\"\n",
    "    pair_set: Set[Tuple[str, str]] = set()\n",
    "    regex = re.compile(\n",
    "        r\"^fpair_(?P<A>[A-Za-z0-9_']+)__(?P<B>[A-Za-z0-9_']+)_(?P<N>\\d+)u_pos[57]_neg0_all_(?P<K>\\d+)recommendation\\.csv$\"\n",
    "    )\n",
    "    valid_k = set(map(int, k_list))\n",
    "    valid_n = set(map(int, n_list))\n",
    "    for pos_dir in pos_dirs:\n",
    "        for p in pos_dir.glob(\"fpair_*u_pos*_neg0_all_*recommendation.csv\"):\n",
    "            m = regex.match(p.name)\n",
    "            if not m:\n",
    "                continue\n",
    "            k = int(m.group(\"K\"))\n",
    "            n = int(m.group(\"N\"))\n",
    "            if k not in valid_k or n not in valid_n:\n",
    "                continue\n",
    "            A_disp = normalize_tag(m.group(\"A\").replace(\"_\", \" \"))\n",
    "            B_disp = normalize_tag(m.group(\"B\").replace(\"_\", \" \"))\n",
    "            a_c, b_c = sorted([A_disp, B_disp], key=lambda x: x.lower())\n",
    "            pair_set.add((a_c, b_c))\n",
    "    return sorted(pair_set, key=lambda ab: (ab[0].lower(), ab[1].lower()))\n",
    "\n",
    "def original_file_for_k(orig_dir: Path, k: int) -> Optional[Path]:\n",
    "    p = orig_dir / f\"ORIGINAL_{k}recommendation.csv\"\n",
    "    return p if p.exists() else None\n",
    "\n",
    "def load_rec_csv(fp: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(fp, low_memory=False)\n",
    "    # Ensure genres_all exists\n",
    "    if \"genres_all\" not in df.columns:\n",
    "        if \"genre_g1\" in df.columns and \"genre_g2\" in df.columns:\n",
    "            df[\"genres_all\"] = df[[\"genre_g1\", \"genre_g2\"]].fillna(\"\").agg(\n",
    "                lambda x: \", \".join([t for t in [x[\"genre_g1\"], x[\"genre_g2\"]] if str(t).strip()]), axis=1\n",
    "            )\n",
    "        else:\n",
    "            df[\"genres_all\"] = \"\"\n",
    "    return df\n",
    "\n",
    "def plot_pair_pos_three_bins(A: str, B: str, pos_label: str,\n",
    "                             data_by_k: Dict[int, Dict[str, float]],\n",
    "                             out_png: Path):\n",
    "    \"\"\"\n",
    "    data_by_k: {K: {\"Original\": v0, \"25\": v25, \"50\": v50, \"100\": v100, \"200\": v200}}\n",
    "    \"\"\"\n",
    "    ks = sorted(data_by_k.keys())\n",
    "    groups = [\"Original\", \"25\", \"50\", \"100\", \"200\"]\n",
    "    vals = [[data_by_k.get(k, {}).get(g, 0.0) for g in groups] for k in ks]\n",
    "\n",
    "    # Plot: 3 bins (ks), 5 bars each\n",
    "    width = 0.16\n",
    "    x = list(range(len(ks)))\n",
    "    plt.figure(figsize=(8.4, 4.4), dpi=160)\n",
    "\n",
    "    for j, g in enumerate(groups):\n",
    "        offs = [i + (j - 2)*width for i in x]  # center bars around each K bin\n",
    "        plt.bar(offs, [vals[i][j] for i in range(len(ks))], width=width,\n",
    "                label=(\"n=\"+g if g!=\"Original\" else \"Original\"))\n",
    "\n",
    "    plt.xticks(x, [f\"Top-{k}\" for k in ks])\n",
    "    plt.ylabel(\"Avg # of pair-books in Top-K per user\")\n",
    "    plt.title(f\"{A} + {B} — POS={pos_label}\")\n",
    "    plt.legend(ncol=3, fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_png)\n",
    "    plt.close()\n",
    "\n",
    "# ======== MAIN ========\n",
    "def main():\n",
    "    OUT_5.mkdir(parents=True, exist_ok=True)\n",
    "    OUT_7.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Discover all pairs from poisoned dirs\n",
    "    PAIRS = discover_pairs_from_dirs(POS_DIRS, K_LIST, N_LIST)\n",
    "    if not PAIRS:\n",
    "        print(\"[WARN] No pairs found in /5 or /7.\")\n",
    "        return\n",
    "    print(f\"[OK] Found {len(PAIRS)} pairs across poisoned dirs.\")\n",
    "\n",
    "    # Preload ORIGINAL per K (same files for all pairs; per-pair counts differ)\n",
    "    original_df_by_k: Dict[int, Optional[pd.DataFrame]] = {}\n",
    "    for k in K_LIST:\n",
    "        fp = original_file_for_k(ORIG_DIR, k)\n",
    "        if fp is None:\n",
    "            print(f\"[WARN] Missing ORIGINAL_{k}recommendation.csv in {ORIG_DIR}\")\n",
    "            original_df_by_k[k] = None\n",
    "        else:\n",
    "            original_df_by_k[k] = load_rec_csv(fp)\n",
    "\n",
    "    # Collect tall rows for both pos branches (5 & 7) + Original\n",
    "    tall_rows = []  # columns: A,B,pair,pos,K,n,avg_count,users\n",
    "\n",
    "    # ORIGINAL tall rows (n=\"ORIGINAL\")\n",
    "    for (A, B) in PAIRS:\n",
    "        for k in K_LIST:\n",
    "            dfO = original_df_by_k.get(k)\n",
    "            if dfO is None:\n",
    "                continue\n",
    "            avgc, users_cnt = per_user_avg_pair_count(dfO, A, B)\n",
    "            tall_rows.append({\n",
    "                \"A\": A, \"B\": B, \"pair\": slugify_pair(A,B),\n",
    "                \"pos\": \"ORIGINAL\", \"K\": k, \"n\": \"ORIGINAL\",\n",
    "                \"avg_count\": avgc, \"users\": users_cnt\n",
    "            })\n",
    "\n",
    "    # Poisoned tall rows (per N separately; no averaging across files)\n",
    "    for pos_dir in POS_DIRS:\n",
    "        pos_label = pos_dir.name  # \"5\" or \"7\"\n",
    "        for (A, B) in PAIRS:\n",
    "            for k in K_LIST:\n",
    "                for n in N_LIST:\n",
    "                    files = injected_files_for_pair_k_n(pos_dir, A, B, k, n)\n",
    "                    if not files:\n",
    "                        continue\n",
    "                    for f in files:\n",
    "                        try:\n",
    "                            df = load_rec_csv(f)\n",
    "                            avgc, users_cnt = per_user_avg_pair_count(df, A, B)\n",
    "                            tall_rows.append({\n",
    "                                \"A\": A, \"B\": B, \"pair\": slugify_pair(A,B),\n",
    "                                \"pos\": pos_label, \"K\": k, \"n\": str(n),\n",
    "                                \"avg_count\": avgc, \"users\": users_cnt,\n",
    "                                \"source\": f.name\n",
    "                            })\n",
    "                        except Exception as e:\n",
    "                            print(f\"[ERROR] Reading {f}: {e}\")\n",
    "\n",
    "    if not tall_rows:\n",
    "        print(\"[WARN] No rows computed. Exiting.\")\n",
    "        return\n",
    "\n",
    "    dft = pd.DataFrame(tall_rows)\n",
    "    dft[\"n\"] = dft[\"n\"].astype(str)\n",
    "    dft.sort_values(by=[\"pair\",\"pos\",\"K\",\"n\"], inplace=True)\n",
    "\n",
    "    # --- Save per-pos CSVs (numbers live next to figures) ---\n",
    "    dft_pos5 = dft[dft[\"pos\"].isin([\"ORIGINAL\",\"5\"])].copy()\n",
    "    dft_pos7 = dft[dft[\"pos\"].isin([\"ORIGINAL\",\"7\"])].copy()\n",
    "    dft_pos5.to_csv(OUT_5 / \"summary_pos5.csv\", index=False)\n",
    "    dft_pos7.to_csv(OUT_7 / \"summary_pos7.csv\", index=False)\n",
    "    print(f\"[OK] Saved CSVs: {OUT_5/'summary_pos5.csv'} , {OUT_7/'summary_pos7.csv'}\")\n",
    "\n",
    "    # --- Make figures: one per (pair, pos) ---\n",
    "    for (A, B) in PAIRS:\n",
    "        pair_slug = slugify_pair(A, B)\n",
    "\n",
    "        # POS=5 figure\n",
    "        sub5 = dft_pos5[dft_pos5[\"pair\"] == pair_slug]\n",
    "        if not sub5.empty:\n",
    "            data_by_k_5: Dict[int, Dict[str, float]] = {}\n",
    "            for k in K_LIST:\n",
    "                data_by_k_5[k] = {\"Original\": 0.0, \"25\": 0.0, \"50\": 0.0, \"100\": 0.0, \"200\": 0.0}\n",
    "                sO = sub5[(sub5[\"K\"] == k) & (sub5[\"pos\"] == \"ORIGINAL\") & (sub5[\"n\"] == \"ORIGINAL\")]\n",
    "                if not sO.empty:\n",
    "                    data_by_k_5[k][\"Original\"] = float(sO.iloc[0][\"avg_count\"])\n",
    "                for n_str in [\"25\",\"50\",\"100\",\"200\"]:\n",
    "                    sN = sub5[(sub5[\"K\"] == k) & (sub5[\"pos\"] == \"5\") & (sub5[\"n\"] == n_str)]\n",
    "                    if not sN.empty:\n",
    "                        data_by_k_5[k][n_str] = float(sN.iloc[0][\"avg_count\"])\n",
    "            out_png_5 = OUT_5 / f\"{pair_slug}__pos5.png\"\n",
    "            plot_pair_pos_three_bins(A, B, \"5\", data_by_k_5, out_png_5)\n",
    "\n",
    "        # POS=7 figure\n",
    "        sub7 = dft_pos7[dft_pos7[\"pair\"] == pair_slug]\n",
    "        if not sub7.empty:\n",
    "            data_by_k_7: Dict[int, Dict[str, float]] = {}\n",
    "            for k in K_LIST:\n",
    "                data_by_k_7[k] = {\"Original\": 0.0, \"25\": 0.0, \"50\": 0.0, \"100\": 0.0, \"200\": 0.0}\n",
    "                sO = sub7[(sub7[\"K\"] == k) & (sub7[\"pos\"] == \"ORIGINAL\") & (sub7[\"n\"] == \"ORIGINAL\")]\n",
    "                if not sO.empty:\n",
    "                    data_by_k_7[k][\"Original\"] = float(sO.iloc[0][\"avg_count\"])\n",
    "                for n_str in [\"25\",\"50\",\"100\",\"200\"]:\n",
    "                    sN = sub7[(sub7[\"K\"] == k) & (sub7[\"pos\"] == \"7\") & (sub7[\"n\"] == n_str)]\n",
    "                    if not sN.empty:\n",
    "                        data_by_k_7[k][n_str] = float(sN.iloc[0][\"avg_count\"])\n",
    "            out_png_7 = OUT_7 / f\"{pair_slug}__pos7.png\"\n",
    "            plot_pair_pos_three_bins(A, B, \"7\", data_by_k_7, out_png_7)\n",
    "\n",
    "    print(f\"[OK] Figures written to:\\n  {OUT_5}\\n  {OUT_7}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
