{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysisis(also saved as .py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'type' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3754857/65364081.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0moriginal_file_for_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPath\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \"\"\"\n\u001b[1;32m    143\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0mORIGINAL_\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0mrecommendation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'type' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# compare_pairs_original_vs_pos5_pos7_neg0_all.py\n",
    "#\n",
    "# Purpose:\n",
    "#   - Discover all unordered genre pairs from SVD outputs in /5 and /7 (neg0_all only)\n",
    "#   - For K in {15,25,35}:\n",
    "#       * ORIGINAL: per-user avg # of recs whose genres_all contains both tags\n",
    "#       * POS=5:    mean of the same per-user avg across all N and files for that pair\n",
    "#       * POS=7:    mean of the same per-user avg across all N and files for that pair\n",
    "#   - Save inventory, a wide comparison CSV, and bar charts (three bins) per pair & K\n",
    "#\n",
    "# Inputs (directories of recommendation CSVs):\n",
    "#   /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/SVD_pair/5\n",
    "#   /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/SVD_pair/7\n",
    "#   /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/SVD_pair     (for ORIGINAL_{K}recommendation.csv)\n",
    "#\n",
    "# Outputs:\n",
    "#   /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/SVD_pair/result/pair_summary/all/\n",
    "#     ├─ _inventory/discovered_pairs.txt\n",
    "#     ├─ _inventory/discovered_pairs.csv\n",
    "#     ├─ COMPARE_original_vs_pos5_pos7_k15_25_35.csv\n",
    "#     └─ figures/<pair_slug>_K<k>.png   (bar chart with 3 bins)\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Iterable, Tuple, List, Set, Dict\n",
    "\n",
    "# ======== CONFIG ========\n",
    "BASE = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/1015/SVD_pair\")\n",
    "DIR_5 = BASE / \"5\"   # pos=5 branch\n",
    "DIR_7 = BASE / \"7\"   # pos=7 branch\n",
    "DIR_ORIG = BASE      # ORIGINAL_{K}recommendation.csv is saved at the root\n",
    "\n",
    "OUT_ROOT = BASE / \"result\" / \"pair_summary\" / \"all\"\n",
    "INV_DIR = OUT_ROOT / \"_inventory\"\n",
    "FIG_DIR = OUT_ROOT / \"figures\"\n",
    "\n",
    "# K & N\n",
    "K_LIST = [15, 25, 35]\n",
    "N_LIST = [25, 50, 100, 200]\n",
    "\n",
    "# ======== HELPERS ========\n",
    "def slugify_pair(a: str, b: str) -> str:\n",
    "    import re as _re\n",
    "    def sg(x): return _re.sub(r\"[^A-Za-z0-9]+\", \"_\", x).strip(\"_\").lower()\n",
    "    a, b = a.strip(), b.strip()\n",
    "    return f\"{sg(a)}__{sg(b)}\"\n",
    "\n",
    "def normalize_tag(t: str) -> str:\n",
    "    t = str(t).strip().replace(\"_\", \" \")\n",
    "    if t == \"Children s\":\n",
    "        t = \"Children's\"\n",
    "    if t.lower() == \"science fiction\":\n",
    "        t = \"Science Fiction\"\n",
    "    if t.lower() == \"historical\":\n",
    "        t = \"Historical\"\n",
    "    if t.lower() == \"nonfiction\":\n",
    "        t = \"Nonfiction\"\n",
    "    return t\n",
    "\n",
    "def book_has_both(gen_all: str, A: str, B: str) -> bool:\n",
    "    if pd.isna(gen_all) or not str(gen_all).strip():\n",
    "        return False\n",
    "    parts = [normalize_tag(x) for x in str(gen_all).split(\",\") if str(x).strip()]\n",
    "    return (A in parts) and (B in parts)\n",
    "\n",
    "def per_user_avg_pair_count(rec_df: pd.DataFrame, A: str, B: str) -> tuple[float, int]:\n",
    "    need = {\"user_id\", \"book_id\", \"genres_all\"}\n",
    "    missing = need - set(rec_df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"CSV missing columns: {missing}\")\n",
    "\n",
    "    users = rec_df[\"user_id\"].drop_duplicates().sort_values()\n",
    "    users_count = int(users.shape[0])\n",
    "\n",
    "    mask = rec_df[\"genres_all\"].apply(lambda s: book_has_both(s, A, B))\n",
    "    pair_df = rec_df[mask].copy()\n",
    "    if pair_df.empty:\n",
    "        return (0.0, users_count)\n",
    "\n",
    "    per_user = (\n",
    "        pair_df.groupby(\"user_id\", as_index=False)[\"book_id\"]\n",
    "        .count()\n",
    "        .rename(columns={\"book_id\": \"count\"})\n",
    "    )\n",
    "\n",
    "    all_users = pd.DataFrame({\"user_id\": users})\n",
    "    all_users = all_users.merge(per_user, on=\"user_id\", how=\"left\").fillna({\"count\": 0})\n",
    "    return (float(all_users[\"count\"].mean()), users_count)\n",
    "\n",
    "def discover_pairs_from_dirs(pos_dirs: Iterable[Path]) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Parse poisoned filenames to discover unordered pairs present in /5 and /7.\n",
    "    Only considers *_neg0_all_* files.\n",
    "    \"\"\"\n",
    "    pair_set: Set[Tuple[str, str]] = set()\n",
    "    regex = re.compile(\n",
    "        r\"^fpair_(?P<A>.+?)__(?P<B>.+?)_\"\n",
    "        r\"(?P<N>\\d+)u_pos(?P<POS>[57])_neg0_all_\"\n",
    "        r\"(?P<K>\\d+)recommendation\\.csv$\"\n",
    "    )\n",
    "\n",
    "    for pos_dir in pos_dirs:\n",
    "        if not pos_dir.exists():\n",
    "            continue\n",
    "        for p in pos_dir.glob(\"fpair_*_neg0_all_*recommendation.csv\"):\n",
    "            m = regex.match(p.name)\n",
    "            if not m:\n",
    "                continue\n",
    "            A_disp = normalize_tag(m.group(\"A\").replace(\"_\", \" \"))\n",
    "            B_disp = normalize_tag(m.group(\"B\").replace(\"_\", \" \"))\n",
    "            a_c, b_c = sorted([A_disp, B_disp], key=lambda x: x.lower())\n",
    "            pair_set.add((a_c, b_c))\n",
    "\n",
    "    return sorted(pair_set, key=lambda ab: (ab[0].lower(), ab[1].lower()))\n",
    "\n",
    "def injected_files_for_pair_k_n(pos_dir: Path, A: str, B: str, k: int, n: int) -> list[Path]:\n",
    "    \"\"\"\n",
    "    Find poisoned recommendation CSVs for (A,B), K, N inside a specific pos_dir (5 or 7).\n",
    "    Works for either ordering and only matches *_neg0_all_* files.\n",
    "    \"\"\"\n",
    "    aT = re.sub(r\"_+\", \"_\", A.replace(\" \", \"_\").replace(\"'\", \"_\")).strip(\"_\")\n",
    "    bT = re.sub(r\"_+\", \"_\", B.replace(\" \", \"_\").replace(\"'\", \"_\")).strip(\"_\")\n",
    "\n",
    "    pat1 = re.compile(\n",
    "        rf\"^fpair_{re.escape(aT)}__{re.escape(bT)}_{n}u_pos[57]_neg0_all_{k}recommendation\\.csv$\"\n",
    "    )\n",
    "    pat2 = re.compile(\n",
    "        rf\"^fpair_{re.escape(bT)}__{re.escape(aT)}_{n}u_pos[57]_neg0_all_{k}recommendation\\.csv$\"\n",
    "    )\n",
    "\n",
    "    out = []\n",
    "    for p in pos_dir.glob(f\"*neg0_all_{k}recommendation.csv\"):\n",
    "        name = p.name\n",
    "        if pat1.match(name) or pat2.match(name):\n",
    "            out.append(p)\n",
    "    return sorted(out)\n",
    "\n",
    "def original_file_for_k(orig_dir: Path, k: int) -> Path | None:\n",
    "    \"\"\"\n",
    "    Return ORIGINAL_{K}recommendation.csv if it exists, else None.\n",
    "    \"\"\"\n",
    "    p = orig_dir / f\"ORIGINAL_{k}recommendation.csv\"\n",
    "    return p if p.exists() else None\n",
    "\n",
    "def safe_read_csv(path: Path) -> pd.DataFrame | None:\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Reading {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def plot_three_bin_bar(out_png: Path, title: str, values: Dict[str, float]):\n",
    "    \"\"\"\n",
    "    Create a simple 3-bin bar chart (ORIGINAL, POS=5, POS=7).\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    labels = [\"ORIGINAL\", \"POS=5\", \"POS=7\"]\n",
    "    xs = np.arange(len(labels))\n",
    "    ys = [values.get(\"ORIGINAL\", 0.0), values.get(\"5\", 0.0), values.get(\"7\", 0.0)]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(xs, ys)  # (no explicit colors or styles per instruction)\n",
    "    plt.xticks(xs, labels, rotation=0)\n",
    "    plt.ylabel(\"Per-user avg #pair books in Top-K\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# ======== MAIN ========\n",
    "def main():\n",
    "    OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "    INV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ---- Discover pairs from poisoned branches ----\n",
    "    PAIRS = discover_pairs_from_dirs([DIR_5, DIR_7])\n",
    "    if not PAIRS:\n",
    "        print(\"[WARN] No pairs found in /5 or /7 (neg0_all). Nothing to compare.\")\n",
    "        return\n",
    "\n",
    "    print(f\"[INFO] Found {len(PAIRS)} unique unordered pairs across /5 and /7 (neg0_all).\")\n",
    "    with open(INV_DIR / \"discovered_pairs.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for a, b in PAIRS:\n",
    "            f.write(f\"{a},{b}\\n\")\n",
    "    pd.DataFrame(PAIRS, columns=[\"A\", \"B\"]).to_csv(INV_DIR / \"discovered_pairs.csv\", index=False)\n",
    "    print(f\"[OK] Inventory saved in {INV_DIR}\")\n",
    "\n",
    "    # ---- Build comparison rows ----\n",
    "    rows = []  # wide format (one row per pair & K)\n",
    "    for (A, B) in PAIRS:\n",
    "        pair_slug = slugify_pair(A, B)\n",
    "\n",
    "        for k in K_LIST:\n",
    "            # ORIGINAL\n",
    "            orig_csv = original_file_for_k(DIR_ORIG, k)\n",
    "            orig_avg, orig_users = (np.nan, 0)\n",
    "            if orig_csv is not None:\n",
    "                dfO = safe_read_csv(orig_csv)\n",
    "                if dfO is not None:\n",
    "                    try:\n",
    "                        orig_avg, orig_users = per_user_avg_pair_count(dfO, A, B)\n",
    "                    except Exception as e:\n",
    "                        print(f\"[ERROR] ORIGINAL {k}, pair {A},{B}: {e}\")\n",
    "\n",
    "            # POS=5 (mean across all N and files)\n",
    "            vals5, users5 = [], []\n",
    "            if DIR_5.exists():\n",
    "                for n in N_LIST:\n",
    "                    files5 = injected_files_for_pair_k_n(DIR_5, A, B, k, n)\n",
    "                    for f in files5:\n",
    "                        df5 = safe_read_csv(f)\n",
    "                        if df5 is not None:\n",
    "                            try:\n",
    "                                avgc, ucnt = per_user_avg_pair_count(df5, A, B)\n",
    "                                vals5.append(avgc); users5.append(ucnt)\n",
    "                            except Exception as e:\n",
    "                                print(f\"[ERROR] POS=5 {f.name}: {e}\")\n",
    "            pos5_avg = float(np.mean(vals5)) if vals5 else np.nan\n",
    "            pos5_users = max(users5) if users5 else 0\n",
    "\n",
    "            # POS=7 (mean across all N and files)\n",
    "            vals7, users7 = [], []\n",
    "            if DIR_7.exists():\n",
    "                for n in N_LIST:\n",
    "                    files7 = injected_files_for_pair_k_n(DIR_7, A, B, k, n)\n",
    "                    for f in files7:\n",
    "                        df7 = safe_read_csv(f)\n",
    "                        if df7 is not None:\n",
    "                            try:\n",
    "                                avgc, ucnt = per_user_avg_pair_count(df7, A, B)\n",
    "                                vals7.append(avgc); users7.append(ucnt)\n",
    "                            except Exception as e:\n",
    "                                print(f\"[ERROR] POS=7 {f.name}: {e}\")\n",
    "            pos7_avg = float(np.mean(vals7)) if vals7 else np.nan\n",
    "            pos7_users = max(users7) if users7 else 0\n",
    "\n",
    "            rows.append({\n",
    "                \"pair_slug\": pair_slug,\n",
    "                \"A\": A, \"B\": B,\n",
    "                \"K\": k,\n",
    "                \"avg_ORIGINAL\": orig_avg,\n",
    "                \"users_ORIGINAL\": orig_users,\n",
    "                \"avg_pos5\": pos5_avg,\n",
    "                \"users_pos5\": pos5_users,\n",
    "                \"avg_pos7\": pos7_avg,\n",
    "                \"users_pos7\": pos7_users,\n",
    "            })\n",
    "\n",
    "            # ---- Figure (three bins) ----\n",
    "            title = f\"{A} + {B} — Top-{k}\"\n",
    "            out_png = FIG_DIR / f\"{pair_slug}_K{k}.png\"\n",
    "            vals_for_plot = {\n",
    "                \"ORIGINAL\": 0.0 if np.isnan(orig_avg) else float(orig_avg),\n",
    "                \"5\": 0.0 if np.isnan(pos5_avg) else float(pos5_avg),\n",
    "                \"7\": 0.0 if np.isnan(pos7_avg) else float(pos7_avg),\n",
    "            }\n",
    "            try:\n",
    "                plot_three_bin_bar(out_png, title, vals_for_plot)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Plotting {title}: {e}\")\n",
    "\n",
    "            print(f\"[OK] {A},{B}  K={k}  →  ORIG={orig_avg:.4f}  pos5={pos5_avg:.4f}  pos7={pos7_avg:.4f}\")\n",
    "\n",
    "    # ---- Save combined comparison CSV ----\n",
    "    if rows:\n",
    "        dfw = pd.DataFrame(rows)\n",
    "        dfw = dfw.sort_values(by=[\"A\", \"B\", \"K\"]).reset_index(drop=True)\n",
    "        out_csv = OUT_ROOT / \"COMPARE_original_vs_pos5_pos7_k15_25_35.csv\"\n",
    "        dfw.to_csv(out_csv, index=False)\n",
    "        print(f\"[OK] Saved comparison CSV: {out_csv}\")\n",
    "        print(f\"[OK] Figures saved in: {FIG_DIR}\")\n",
    "    else:\n",
    "        print(\"[WARN] No rows to save — check your inputs.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
