{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-surprise in /home/moshtasa/.local/lib/python3.9/site-packages (1.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/moshtasa/.local/lib/python3.9/site-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/anaconda3/lib/python3.9/site-packages (from scikit-surprise) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from scikit-surprise) (1.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/data/goodbooks-10k/books.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'decade'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdecade\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcount(),unique\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:7721\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   7716\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m   7718\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[1;32m   7719\u001b[0m \u001b[38;5;66;03m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[1;32m   7720\u001b[0m \u001b[38;5;66;03m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[0;32m-> 7721\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7724\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7727\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7729\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   7730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    880\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 882\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'decade'"
     ]
    }
   ],
   "source": [
    "df_final.groupby('decade')['book_id'].count(),unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "decade",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "842c2f86-ab1a-4345-b01a-5e2fcf5455a9",
       "rows": [
        [
         "1920",
         "89"
        ],
        [
         "1930",
         "121"
        ],
        [
         "1940",
         "155"
        ],
        [
         "1950",
         "210"
        ],
        [
         "1960",
         "272"
        ],
        [
         "1970",
         "400"
        ],
        [
         "1980",
         "704"
        ],
        [
         "1990",
         "1360"
        ],
        [
         "2000",
         "3121"
        ],
        [
         "2010",
         "3067"
        ],
        [
         "Ancient Books",
         "480"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 11
       }
      },
      "text/plain": [
       "decade\n",
       "1920               89\n",
       "1930              121\n",
       "1940              155\n",
       "1950              210\n",
       "1960              272\n",
       "1970              400\n",
       "1980              704\n",
       "1990             1360\n",
       "2000             3121\n",
       "2010             3067\n",
       "Ancient Books     480\n",
       "Name: book_id, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.groupby('decade')['book_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rating",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ea7a6d54-8aed-4888-be52-6ab8b5b46354",
       "rows": [
        [
         "count",
         "5970537.0"
        ],
        [
         "mean",
         "3.9196665224585328"
        ],
        [
         "std",
         "0.9910472682840205"
        ],
        [
         "min",
         "1.0"
        ],
        [
         "25%",
         "3.0"
        ],
        [
         "50%",
         "4.0"
        ],
        [
         "75%",
         "5.0"
        ],
        [
         "max",
         "5.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/plain": [
       "count    5.970537e+06\n",
       "mean     3.919667e+00\n",
       "std      9.910473e-01\n",
       "min      1.000000e+00\n",
       "25%      3.000000e+00\n",
       "50%      4.000000e+00\n",
       "75%      5.000000e+00\n",
       "max      5.000000e+00\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'book_id', 'rating', 'decade'], dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "decade",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "6f677dca-ce60-4b81-9a05-5bfe5b3b8fd1",
       "rows": [
        [
         "0",
         "1",
         "258",
         "5",
         "2000"
        ],
        [
         "1",
         "2",
         "4081",
         "4",
         "2000"
        ],
        [
         "2",
         "2",
         "260",
         "5",
         "1930"
        ],
        [
         "3",
         "2",
         "9296",
         "5",
         "1970"
        ],
        [
         "4",
         "2",
         "2318",
         "3",
         "1990"
        ],
        [
         "5",
         "2",
         "26",
         "4",
         "2000"
        ],
        [
         "6",
         "2",
         "315",
         "3",
         "1990"
        ],
        [
         "7",
         "2",
         "33",
         "4",
         "1990"
        ],
        [
         "8",
         "2",
         "301",
         "5",
         "Ancient Books"
        ],
        [
         "9",
         "2",
         "2686",
         "5",
         "2000"
        ],
        [
         "10",
         "2",
         "3753",
         "5",
         "2000"
        ],
        [
         "11",
         "2",
         "8519",
         "5",
         "1970"
        ],
        [
         "12",
         "4",
         "70",
         "4",
         "1980"
        ],
        [
         "13",
         "4",
         "264",
         "3",
         "1920"
        ],
        [
         "14",
         "4",
         "388",
         "4",
         "1980"
        ],
        [
         "15",
         "4",
         "18",
         "5",
         "1990"
        ],
        [
         "16",
         "4",
         "27",
         "5",
         "2000"
        ],
        [
         "17",
         "4",
         "21",
         "5",
         "2000"
        ],
        [
         "18",
         "4",
         "2",
         "5",
         "1990"
        ],
        [
         "19",
         "4",
         "23",
         "5",
         "1990"
        ],
        [
         "20",
         "4",
         "24",
         "5",
         "2000"
        ],
        [
         "21",
         "4",
         "964",
         "4",
         "1970"
        ],
        [
         "22",
         "4",
         "103",
         "5",
         "Ancient Books"
        ],
        [
         "23",
         "4",
         "255",
         "2",
         "1950"
        ],
        [
         "24",
         "4",
         "35",
         "5",
         "1980"
        ],
        [
         "25",
         "4",
         "287",
         "3",
         "1940"
        ],
        [
         "26",
         "4",
         "337",
         "4",
         "1990"
        ],
        [
         "27",
         "4",
         "26",
         "3",
         "2000"
        ],
        [
         "28",
         "4",
         "84",
         "4",
         "1990"
        ],
        [
         "29",
         "4",
         "58",
         "4",
         "Ancient Books"
        ],
        [
         "30",
         "4",
         "1117",
         "3",
         "1990"
        ],
        [
         "31",
         "4",
         "660",
         "3",
         "1980"
        ],
        [
         "32",
         "4",
         "111",
         "2",
         "2000"
        ],
        [
         "33",
         "4",
         "5",
         "4",
         "1920"
        ],
        [
         "34",
         "4",
         "413",
         "4",
         "Ancient Books"
        ],
        [
         "35",
         "4",
         "8",
         "4",
         "1950"
        ],
        [
         "36",
         "4",
         "2172",
         "4",
         "1960"
        ],
        [
         "37",
         "4",
         "65",
         "4",
         "1960"
        ],
        [
         "38",
         "4",
         "297",
         "4",
         "1960"
        ],
        [
         "39",
         "4",
         "45",
         "4",
         "2000"
        ],
        [
         "40",
         "4",
         "113",
         "4",
         "1960"
        ],
        [
         "41",
         "4",
         "325",
         "5",
         "1980"
        ],
        [
         "42",
         "4",
         "476",
         "3",
         "1970"
        ],
        [
         "43",
         "6",
         "6351",
         "4",
         "2000"
        ],
        [
         "44",
         "8",
         "2732",
         "5",
         "Ancient Books"
        ],
        [
         "45",
         "8",
         "1432",
         "3",
         "Ancient Books"
        ],
        [
         "46",
         "8",
         "479",
         "4",
         "Ancient Books"
        ],
        [
         "47",
         "8",
         "3020",
         "5",
         "Ancient Books"
        ],
        [
         "48",
         "8",
         "6195",
         "4",
         "1920"
        ],
        [
         "49",
         "8",
         "614",
         "4",
         "1920"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5970537
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970532</th>\n",
       "      <td>49925</td>\n",
       "      <td>510</td>\n",
       "      <td>5</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970533</th>\n",
       "      <td>49925</td>\n",
       "      <td>528</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970534</th>\n",
       "      <td>49925</td>\n",
       "      <td>722</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970535</th>\n",
       "      <td>49925</td>\n",
       "      <td>949</td>\n",
       "      <td>5</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970536</th>\n",
       "      <td>49925</td>\n",
       "      <td>1023</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5970537 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  book_id  rating decade\n",
       "0              1      258       5   2000\n",
       "1              2     4081       4   2000\n",
       "2              2      260       5   1930\n",
       "3              2     9296       5   1970\n",
       "4              2     2318       3   1990\n",
       "...          ...      ...     ...    ...\n",
       "5970532    49925      510       5   1990\n",
       "5970533    49925      528       4   1990\n",
       "5970534    49925      722       4   1990\n",
       "5970535    49925      949       5   1990\n",
       "5970536    49925     1023       4   1990\n",
       "\n",
       "[5970537 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [76], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m reader \u001b[38;5;241m=\u001b[39m Reader(rating_scale\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load data into Surprise format\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m data \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mload_from_df(df_final[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]], reader)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Split into train and test sets\u001b[39;00m\n\u001b[1;32m     14\u001b[0m trainset, testset \u001b[38;5;241m=\u001b[39m train_test_split(data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/surprise/dataset.py:167\u001b[0m, in \u001b[0;36mDataset.load_from_df\u001b[0;34m(cls, df, reader)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_df\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, reader):\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a dataset from a pandas dataframe.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    Use this if you want to use a custom dataset that is stored in a pandas\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m            specified.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDatasetAutoFolds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/surprise/dataset.py:262\u001b[0m, in \u001b[0;36mDatasetAutoFolds.__init__\u001b[0;34m(self, ratings_file, reader, df)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m df\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_ratings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    263\u001b[0m         (uid, iid, \u001b[38;5;28mfloat\u001b[39m(r), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    265\u001b[0m     ]\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify ratings file or dataframe.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/surprise/dataset.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m df\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_ratings \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 263\u001b[0m         (uid, iid, \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    265\u001b[0m     ]\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify ratings file or dataframe.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# ---------------------\n",
    "# Load dataset\n",
    "# ---------------------\n",
    "df_final = pd.read_csv(\"df_original.csv\")  # Ensure the file is in the same directory\n",
    "\n",
    "# Optional: Convert user_id and book_id to strings (Surprise handles strings better)\n",
    "df_final['user_id'] = df_final['user_id'].astype(str)\n",
    "df_final['book_id'] = df_final['book_id'].astype(str)\n",
    "\n",
    "# ---------------------\n",
    "# Prepare Surprise Dataset\n",
    "# ---------------------\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_final[['user_id', 'book_id', 'rating']], reader)\n",
    "\n",
    "# Split into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# ---------------------\n",
    "# Train SVD model\n",
    "# ---------------------\n",
    "svd = SVD(n_factors=100, random_state=42)\n",
    "svd.fit(trainset)\n",
    "\n",
    "# ---------------------\n",
    "# Evaluate RMSE\n",
    "# ---------------------\n",
    "predictions = svd.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "# ---------------------\n",
    "# Generate Top-25 Recommendations per User\n",
    "# ---------------------\n",
    "all_user_ids = df_final['user_id'].unique()\n",
    "all_book_ids = df_final['book_id'].unique()\n",
    "\n",
    "user_recommendations = {}\n",
    "\n",
    "print(\"Generating recommendations...\")\n",
    "for i, user_id in enumerate(all_user_ids):\n",
    "    rated_books = df_final[df_final['user_id'] == user_id]['book_id'].tolist()\n",
    "    unseen_books = [book for book in all_book_ids if book not in rated_books]\n",
    "    \n",
    "    preds = [(book, svd.predict(user_id, book).est) for book in unseen_books]\n",
    "    top_preds = sorted(preds, key=lambda x: x[1], reverse=True)[:25]\n",
    "    \n",
    "    user_recommendations[user_id] = [book for book, _ in top_preds]\n",
    "    \n",
    "    if i % 500 == 0:\n",
    "        print(f\"Processed {i}/{len(all_user_ids)} users\")\n",
    "\n",
    "# ---------------------\n",
    "# Save Recommendations to CSV\n",
    "# ---------------------\n",
    "with open('user_recommendations.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['user_id', 'recommended_books'])\n",
    "    for user_id, books in user_recommendations.items():\n",
    "        writer.writerow([user_id, ','.join(map(str, books))])\n",
    "\n",
    "# ---------------------\n",
    "# Save RMSE to a text file\n",
    "# ---------------------\n",
    "with open('svd_rmse.txt', 'w') as f:\n",
    "    f.write(f\"RMSE: {rmse:.4f}\\n\")\n",
    "\n",
    "# ---------------------\n",
    "# Optional: Load and display a preview\n",
    "# ---------------------\n",
    "df_recommendations = pd.read_csv('user_recommendations.csv')\n",
    "print(\"\\nSample recommendations:\")\n",
    "print(df_recommendations.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
