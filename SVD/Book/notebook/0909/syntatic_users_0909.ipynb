{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Done.\n",
      "  â€¢ Datasets: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0909/data/improved_synthetic_heavy_pos7_neg0\n",
      "  â€¢ Summary: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0909/data/improved_synthetic_heavy_pos7_neg0/summary.txt\n",
      "  â€¢ Summary CSV: /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0909/data/improved_synthetic_heavy_pos7_neg0/summary.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# build_heavy_bias_pos5_neg0.py\n",
    "# For each primary genre G:\n",
    "#   - positives: all books with primary==G rated 5\n",
    "#   - negatives: all other books rated 0  (configurable: ALL or sampled)\n",
    "#\n",
    "# IMPORTANT: Train Surprise with Reader(rating_scale=(0, 5)) to accept zeros.\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ========= CONFIG =========\n",
    "BASE_DIR    = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book\")\n",
    "INPUT_CSV   = BASE_DIR / \"data/df_final_with_genres.csv\"   # requires: user_id, book_id, rating, genres\n",
    "OUT_DIR     = BASE_DIR / \"result/rec/top_re/0909/data/improved_synthetic_heavy_pos7_neg0\"\n",
    "SUMMARY_TXT = OUT_DIR / \"summary.txt\"\n",
    "SUMMARY_CSV = OUT_DIR / \"summary.csv\"\n",
    "\n",
    "GENRE_COL   = \"genres\"\n",
    "USER_COL    = \"user_id\"\n",
    "BOOK_COL    = \"book_id\"\n",
    "RATING_COL  = \"rating\"\n",
    "\n",
    "RUNS = [25, 50, 100, 200]  # number of synthetic users per genre\n",
    "\n",
    "POS_RATING  = 7\n",
    "NEG_RATING  = 0\n",
    "\n",
    "# ---- NEGATIVE assignment mode ----\n",
    "# \"all\"    â†’ rate EVERY non-target book as 0  (exactly what you asked; WARNING: HUGE FILES)\n",
    "# \"sample\" â†’ sample a subset of non-target books per user to keep datasets manageable\n",
    "ZERO_MODE   = \"sample\"   # change to \"all\" for literal â€œrate rest 0â€\n",
    "NEG_RATIO   = 4          # when ZERO_MODE=\"sample\": negatives per user â‰ˆ NEG_RATIO * (#positives)\n",
    "RNG_SEED    = 42         # deterministic sampling\n",
    "# ================================\n",
    "\n",
    "def sanitize_fn(s: str) -> str:\n",
    "    s = (s or \"\").strip().replace(\" \", \"_\")\n",
    "    return re.sub(r\"[^0-9A-Za-z_]+\", \"_\", s) or \"UNK\"\n",
    "\n",
    "def primary_genre(cell: str) -> str:\n",
    "    if not isinstance(cell, str) or not cell.strip():\n",
    "        return \"\"\n",
    "    return cell.split(\",\")[0].strip()\n",
    "\n",
    "def main():\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    random.seed(RNG_SEED)\n",
    "\n",
    "    # ---------- Load ----------\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "    required = {USER_COL, BOOK_COL, RATING_COL, GENRE_COL}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Input must contain columns {required}. Missing: {missing}\")\n",
    "\n",
    "    # hygiene\n",
    "    df[USER_COL]   = pd.to_numeric(df[USER_COL], errors=\"raise\", downcast=\"integer\")\n",
    "    df[BOOK_COL]   = pd.to_numeric(df[BOOK_COL], errors=\"raise\")\n",
    "    df[RATING_COL] = pd.to_numeric(df[RATING_COL], errors=\"raise\")\n",
    "    df[GENRE_COL]  = df[GENRE_COL].fillna(\"\").astype(str)\n",
    "\n",
    "    # baseline stats\n",
    "    baseline_users = df[USER_COL].nunique()\n",
    "    baseline_rows  = len(df)\n",
    "    base_start_uid = int(df[USER_COL].max()) + 1\n",
    "\n",
    "    # lookups\n",
    "    book_to_genres = dict(df[[BOOK_COL, GENRE_COL]].drop_duplicates().values)\n",
    "\n",
    "    # primary genre per book (dedup by book)\n",
    "    book_gen = (df[[BOOK_COL, GENRE_COL]].drop_duplicates()\n",
    "                  .assign(_primary=lambda x: x[GENRE_COL].apply(primary_genre)))\n",
    "    book_gen = book_gen[book_gen[\"_primary\"] != \"\"].copy()\n",
    "\n",
    "    # all unique books and per-genre positive book lists\n",
    "    all_books = sorted(book_gen[BOOK_COL].astype(int).unique().tolist())\n",
    "    per_genre = (\n",
    "        book_gen.groupby(\"_primary\")[BOOK_COL]\n",
    "        .apply(lambda s: sorted(pd.Series(s.unique()).astype(int).tolist()))\n",
    "        .to_frame(\"pos_books\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    per_genre[\"n_pos\"] = per_genre[\"pos_books\"].apply(len)\n",
    "\n",
    "    target_genres = sorted(per_genre[\"_primary\"].tolist(), key=lambda x: x.lower())\n",
    "\n",
    "    # ID block to avoid collisions\n",
    "    BLOCK = 1_000_000\n",
    "\n",
    "    # logging\n",
    "    rows_summary = []\n",
    "    with open(SUMMARY_TXT, \"w\", encoding=\"utf-8\") as log:\n",
    "        log.write(\"=== BASELINE ===\\n\")\n",
    "        log.write(f\"ðŸ‘¤ Unique users: {baseline_users:,}\\n\")\n",
    "        log.write(f\"ðŸ§¾ Rows: {baseline_rows:,}\\n\")\n",
    "        log.write(f\"ðŸ”¢ Synthetic user_id base start: {base_start_uid}\\n\")\n",
    "        log.write(f\"ZERO_MODE={ZERO_MODE} | NEG_RATIO={NEG_RATIO} | RNG_SEED={RNG_SEED}\\n\")\n",
    "        log.write(\"=\"*80 + \"\\n\\n\")\n",
    "\n",
    "    grand_added = 0\n",
    "    made_any = False\n",
    "\n",
    "    for gi, g in enumerate(target_genres):\n",
    "        pos_books = per_genre.loc[per_genre[\"_primary\"] == g, \"pos_books\"].iloc[0]\n",
    "        n_pos     = int(per_genre.loc[per_genre[\"_primary\"] == g, \"n_pos\"].iloc[0])\n",
    "        if n_pos == 0:\n",
    "            continue\n",
    "\n",
    "        pos_set = set(pos_books)\n",
    "        neg_pool = [b for b in all_books if b not in pos_set]\n",
    "\n",
    "        safe_g = sanitize_fn(g)\n",
    "        with open(SUMMARY_TXT, \"a\", encoding=\"utf-8\") as log:\n",
    "            log.write(f\"ðŸŽ­ {g} | positives (primary-genre books) = {n_pos} | neg_pool = {len(neg_pool)}\\n\")\n",
    "\n",
    "        for r_i, run in enumerate(RUNS):\n",
    "            start_uid = base_start_uid + gi * (len(RUNS) * BLOCK) + r_i * BLOCK\n",
    "            new_uids = list(range(start_uid, start_uid + run))\n",
    "\n",
    "            # ----- choose negatives (either ALL or sampled) -----\n",
    "            if ZERO_MODE == \"all\":\n",
    "                neg_books_for_all_users = neg_pool  # WARNING: huge\n",
    "            else:\n",
    "                # sample a fixed subset once per (genre, run), same for all new users (fast & reproducible)\n",
    "                target_neg = min(len(neg_pool), NEG_RATIO * n_pos)\n",
    "                rng = random.Random(RNG_SEED + gi*1000 + r_i)\n",
    "                neg_books_for_all_users = rng.sample(neg_pool, target_neg) if target_neg > 0 else []\n",
    "\n",
    "            n_neg = len(neg_books_for_all_users)\n",
    "\n",
    "            # ----- build synthetic block -----\n",
    "            # Positives (5)\n",
    "            pos_rows = {\n",
    "                USER_COL:   [uid for uid in new_uids for _ in range(n_pos)],\n",
    "                BOOK_COL:   [b for _ in new_uids for b in pos_books],\n",
    "                RATING_COL: [POS_RATING] * (run * n_pos),\n",
    "                GENRE_COL:  [book_to_genres.get(b, \"\") for _ in new_uids for b in pos_books],\n",
    "            }\n",
    "\n",
    "            # Negatives (0)\n",
    "            neg_rows = {\n",
    "                USER_COL:   [uid for uid in new_uids for _ in range(n_neg)],\n",
    "                BOOK_COL:   [b for _ in new_uids for b in neg_books_for_all_users],\n",
    "                RATING_COL: [NEG_RATING] * (run * n_neg),\n",
    "                GENRE_COL:  [book_to_genres.get(b, \"\") for _ in new_uids for b in neg_books_for_all_users],\n",
    "            }\n",
    "\n",
    "            synth_df = pd.concat([pd.DataFrame(pos_rows), pd.DataFrame(neg_rows)], ignore_index=True)\n",
    "            expected_added = run * (n_pos + n_neg)\n",
    "\n",
    "            # quick check\n",
    "            assert len(synth_df) == expected_added, f\"Row count mismatch for {g}, run={run}\"\n",
    "\n",
    "            # combine and save\n",
    "            combined = pd.concat([df, synth_df], ignore_index=True)\n",
    "            new_users_total = combined[USER_COL].nunique()\n",
    "\n",
    "            out_path = OUT_DIR / f\"f_{safe_g}_{run}_pos7_neg0_{ZERO_MODE}.csv\"\n",
    "            combined.to_csv(out_path, index=False)\n",
    "\n",
    "            with open(SUMMARY_TXT, \"a\", encoding=\"utf-8\") as log:\n",
    "                log.write(f\"  run={str(run):>5} â†’ +rows={expected_added:>12,} \"\n",
    "                          f\"(pos={run*n_pos:,}, neg={run*n_neg:,}) | \"\n",
    "                          f\"new_rows={len(combined):,} | new_users={new_users_total:,}\\n\")\n",
    "\n",
    "            rows_summary.append({\n",
    "                \"genre\": g,\n",
    "                \"safe_genre\": safe_g,\n",
    "                \"run_users\": run,\n",
    "                \"n_pos_books\": n_pos,\n",
    "                \"n_neg_books_per_user\": n_neg if ZERO_MODE==\"all\" else n_neg,\n",
    "                \"rows_added\": expected_added,\n",
    "                \"rows_pos\": run*n_pos,\n",
    "                \"rows_neg\": run*n_neg,\n",
    "                \"zero_mode\": ZERO_MODE,\n",
    "                \"neg_ratio\": NEG_RATIO if ZERO_MODE==\"sample\" else None,\n",
    "                \"output_csv\": str(out_path)\n",
    "            })\n",
    "\n",
    "            grand_added += expected_added\n",
    "            made_any = True\n",
    "\n",
    "        with open(SUMMARY_TXT, \"a\", encoding=\"utf-8\") as log:\n",
    "            log.write(\"\\n\")\n",
    "\n",
    "    if rows_summary:\n",
    "        pd.DataFrame(rows_summary).to_csv(SUMMARY_CSV, index=False)\n",
    "\n",
    "    with open(SUMMARY_TXT, \"a\", encoding=\"utf-8\") as log:\n",
    "        log.write(\"=\"*80 + \"\\n\")\n",
    "        log.write(f\"Grand total injected rows (all genres & runs): {grand_added:,}\\n\")\n",
    "        log.write(f\"Outputs folder: {OUT_DIR}\\n\")\n",
    "        log.write(f\"Per-run summary CSV: {SUMMARY_CSV}\\n\")\n",
    "\n",
    "    if not made_any:\n",
    "        print(\"âš ï¸ No datasets were produced. Check genre names / columns.\")\n",
    "    else:\n",
    "        print(\"\\nâœ… Done.\")\n",
    "        print(\"  â€¢ Datasets:\", OUT_DIR)\n",
    "        print(\"  â€¢ Summary:\", SUMMARY_TXT)\n",
    "        print(\"  â€¢ Summary CSV:\", SUMMARY_CSV)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# sanity_check_pair_injection.py\n",
    "#\n",
    "# Validates datasets produced by build_pair_bias_pos5and7_neg0.py\n",
    "# It scans BOTH .../PAIR_INJECTION/5/ and .../PAIR_INJECTION/7/ folders.\n",
    "#\n",
    "# For each file fpair_{G1}__{G2}_{RUN}u_pos{POS}_neg{NEG}_{MODE}.csv it checks:\n",
    "#  - Synthetic users = users not in baseline INPUT_CSV\n",
    "#  - Synthetic users count == RUN (parsed from filename)\n",
    "#  - Positives have rating == POS and are exactly the books tagged with BOTH G1 & G2\n",
    "#  - Negatives (if any) have rating == 0 and do NOT include any pair-books\n",
    "#  - No duplicate (user_id, book_id)\n",
    "#  - Uniform per-user counts for positives (== #pair_books); for ZERO_MODE=\"all\", negatives per user == |AllBooks - PairBooks|\n",
    "#  - Added rows equal to RUN * (pos_per_user + inferred_neg_per_user) (robust to ZERO_MODE=\"sample\")\n",
    "#\n",
    "# Outputs:\n",
    "#   - manifest.csv at PAIR_INJECTION root, listing all validated files\n",
    "#   - sanity_report.csv at PAIR_INJECTION root, with PASS/FAIL and reasons\n",
    "#   - console summary\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ========= CONFIG (align with your generator paths) =========\n",
    "BASE_DIR     = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book\")\n",
    "INPUT_CSV    = BASE_DIR / \"data/df_final_with_genres.csv\"\n",
    "PAIR_ROOT    = BASE_DIR / \"result/rec/top_re/0929/PAIR_INJECTION\"  # has subfolders 5/ and 7/\n",
    "\n",
    "GENRE_COL    = \"genres\"\n",
    "USER_COL     = \"user_id\"\n",
    "BOOK_COL     = \"book_id\"\n",
    "RATING_COL   = \"rating\"\n",
    "# ============================================================\n",
    "\n",
    "def parse_genres(cell: str):\n",
    "    if not isinstance(cell, str) or not cell.strip():\n",
    "        return []\n",
    "    parts = [p.strip() for p in cell.split(\",\") if p.strip()]\n",
    "    # dedupe while preserving order\n",
    "    seen, out = set(), []\n",
    "    for p in parts:\n",
    "        if p not in seen:\n",
    "            out.append(p); seen.add(p)\n",
    "    return out\n",
    "\n",
    "def load_baseline():\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "    required = {USER_COL, BOOK_COL, RATING_COL, GENRE_COL}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in baseline: {missing}\")\n",
    "    df[USER_COL]   = pd.to_numeric(df[USER_COL], errors=\"raise\", downcast=\"integer\")\n",
    "    df[BOOK_COL]   = pd.to_numeric(df[BOOK_COL], errors=\"raise\")\n",
    "    df[RATING_COL] = pd.to_numeric(df[RATING_COL], errors=\"raise\")\n",
    "    df[GENRE_COL]  = df[GENRE_COL].fillna(\"\").astype(str)\n",
    "    return df\n",
    "\n",
    "def build_book_genre_index(baseline_df):\n",
    "    \"\"\"Return: all_books(list[int]), book->set(genres), discovered GENRES list (sorted).\"\"\"\n",
    "    books = baseline_df[[BOOK_COL, GENRE_COL]].drop_duplicates(subset=[BOOK_COL]).copy()\n",
    "    books[\"genre_list\"] = books[GENRE_COL].apply(parse_genres)\n",
    "    books = books[books[\"genre_list\"].map(len) > 0].copy()\n",
    "    all_books = sorted(books[BOOK_COL].astype(int).unique().tolist())\n",
    "    book_to_set = dict(zip(books[BOOK_COL].astype(int), books[\"genre_list\"].apply(set)))\n",
    "    genres = sorted({g for gl in books[\"genre_list\"] for g in gl})\n",
    "    return all_books, book_to_set, genres\n",
    "\n",
    "def parse_filename(name: str):\n",
    "    \"\"\"\n",
    "    Expected: fpair_{G1}__{G2}_{RUN}u_pos{POS}_neg{NEG}_{MODE}.csv\n",
    "              e.g., fpair_Fantasy__Horror_25u_pos7_neg0_sample.csv\n",
    "    Returns dict or None.\n",
    "    \"\"\"\n",
    "    m = re.match(r\"^fpair_(.+)__(.+)_(\\d+)u_pos(\\d+)_neg(NA|0|\\d+)_(\\w+)\\.csv$\", name)\n",
    "    if not m:\n",
    "        return None\n",
    "    g1, g2, run, pos, neg, mode = m.groups()\n",
    "    return {\n",
    "        \"g1_safe\": g1,\n",
    "        \"g2_safe\": g2,\n",
    "        \"run\": int(run),\n",
    "        \"pos\": int(pos),\n",
    "        \"neg_str\": neg,\n",
    "        \"mode\": mode\n",
    "    }\n",
    "\n",
    "def unsanitize(s: str):\n",
    "    # In generator we only replaced non [0-9A-Za-z_] with '_' and spaces with '_'.\n",
    "    # We cannot invert perfectly; we'll match by comparing against discovered genres\n",
    "    # using simple equality first; if not found, try space/underscore swaps as fallback.\n",
    "    return s.replace(\"_\", \" \")\n",
    "\n",
    "def resolve_genre(safe_name: str, GENRES: list[str]):\n",
    "    # Exact match\n",
    "    for g in GENRES:\n",
    "        if safe_name == g:\n",
    "            return g\n",
    "    # Replace underscores with spaces and try\n",
    "    candidate = unsanitize(safe_name)\n",
    "    for g in GENRES:\n",
    "        if candidate.lower() == g.lower():\n",
    "            return g\n",
    "    # Last resort: case-insensitive underscore-insensitive\n",
    "    s_norm = safe_name.replace(\"_\", \"\").lower()\n",
    "    for g in GENRES:\n",
    "        if s_norm == g.replace(\"_\", \"\").replace(\" \", \"\").lower():\n",
    "            return g\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    pair5_dir = PAIR_ROOT / \"5\"\n",
    "    pair7_dir = PAIR_ROOT / \"7\"\n",
    "\n",
    "    if not pair5_dir.exists() and not pair7_dir.exists():\n",
    "        print(f\"âš ï¸ Neither {pair5_dir} nor {pair7_dir} exists. Aborting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    baseline = load_baseline()\n",
    "    baseline_users = set(baseline[USER_COL].unique().tolist())\n",
    "    all_books, book_to_set, GENRES = build_book_genre_index(baseline)\n",
    "\n",
    "    # Collect files\n",
    "    files = []\n",
    "    for sub in [pair5_dir, pair7_dir]:\n",
    "        if sub.exists():\n",
    "            files.extend(sorted([p for p in sub.glob(\"fpair_*_pos*_.csv\")]))  # unlikely\n",
    "            files.extend(sorted([p for p in sub.glob(\"fpair_*_pos*.csv\")]))\n",
    "    files = sorted(set(files))\n",
    "\n",
    "    if not files:\n",
    "        print(\"âš ï¸ No fpair_*.csv files found under PAIR_INJECTION/5|7.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    manifest_rows = []\n",
    "    report_rows = []\n",
    "    total_pass = 0\n",
    "    total_fail = 0\n",
    "\n",
    "    for fp in files:\n",
    "        info = parse_filename(fp.name)\n",
    "        if not info:\n",
    "            # Skip unknown names but record them\n",
    "            report_rows.append({\n",
    "                \"file\": str(fp), \"status\": \"SKIP\",\n",
    "                \"reason\": \"Filename not recognized\",\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # infer pos folder (5 or 7) from the parent; also compare with POS in filename\n",
    "        pos_folder = int(fp.parent.name) if fp.parent.name.isdigit() else info[\"pos\"]\n",
    "        pos_from_name = info[\"pos\"]\n",
    "        if pos_folder != pos_from_name:\n",
    "            note = f\"pos_folder={pos_folder} differs from pos_in_name={pos_from_name}\"\n",
    "\n",
    "        # resolve safe genre tokens back to actual discovered genre names\n",
    "        g1 = resolve_genre(info[\"g1_safe\"], GENRES)\n",
    "        g2 = resolve_genre(info[\"g2_safe\"], GENRES)\n",
    "        if g1 is None or g2 is None:\n",
    "            report_rows.append({\n",
    "                \"file\": str(fp), \"status\": \"FAIL\",\n",
    "                \"reason\": f\"Could not resolve genres: '{info['g1_safe']}' or '{info['g2_safe']}' to discovered list\",\n",
    "            })\n",
    "            total_fail += 1\n",
    "            continue\n",
    "\n",
    "        # Build pair-books: books containing BOTH genres (unordered)\n",
    "        pair_books = [b for b in all_books if g1 in book_to_set[b] and g2 in book_to_set[b]]\n",
    "        n_pair = len(pair_books)\n",
    "        pair_set = set(pair_books)\n",
    "\n",
    "        # Load combined file\n",
    "        dfc = pd.read_csv(fp)\n",
    "        dfc[USER_COL]   = pd.to_numeric(dfc[USER_COL], errors=\"raise\", downcast=\"integer\")\n",
    "        dfc[BOOK_COL]   = pd.to_numeric(dfc[BOOK_COL], errors=\"raise\")\n",
    "        dfc[RATING_COL] = pd.to_numeric(dfc[RATING_COL], errors=\"raise\")\n",
    "        dfc[GENRE_COL]  = dfc[GENRE_COL].fillna(\"\").astype(str)\n",
    "\n",
    "        synth_users = sorted(list(set(dfc[USER_COL].unique()) - baseline_users))\n",
    "        problems = []\n",
    "\n",
    "        # Check synthetic user count\n",
    "        if len(synth_users) != info[\"run\"]:\n",
    "            problems.append(f\"synth_users={len(synth_users)} != run={info['run']}\")\n",
    "\n",
    "        synth_rows = dfc[dfc[USER_COL].isin(synth_users)].copy()\n",
    "\n",
    "        # Ratings in synthetic block\n",
    "        allowed = {info[\"pos\"]}\n",
    "        if info[\"mode\"] != \"none\" and info[\"neg_str\"] != \"NA\":\n",
    "            allowed.add(0)\n",
    "        bad_ratings = synth_rows[~synth_rows[RATING_COL].isin(allowed)]\n",
    "        if len(bad_ratings) > 0:\n",
    "            problems.append(f\"ratings_outside_allowed={sorted(bad_ratings[RATING_COL].unique().tolist())}\")\n",
    "\n",
    "        # Split pos/neg\n",
    "        pos_rows = synth_rows[synth_rows[RATING_COL] == info[\"pos\"]]\n",
    "        neg_rows = synth_rows[synth_rows[RATING_COL] == 0] if 0 in allowed else synth_rows.iloc[0:0]\n",
    "\n",
    "        # Positives: must be only on pair books\n",
    "        bad_pos = pos_rows[~pos_rows[BOOK_COL].isin(pair_set)]\n",
    "        if len(bad_pos) > 0:\n",
    "            problems.append(f\"{len(bad_pos)} positive rows not in pair-books (|pair|={n_pair})\")\n",
    "\n",
    "        # Negatives: must NOT include pair books\n",
    "        if not neg_rows.empty:\n",
    "            bad_neg = neg_rows[neg_rows[BOOK_COL].isin(pair_set)]\n",
    "            if len(bad_neg) > 0:\n",
    "                problems.append(f\"{len(bad_neg)} negative rows overlap pair-books\")\n",
    "\n",
    "        # Per-user counts uniformity\n",
    "        # Pos per user should be exactly n_pair\n",
    "        if n_pair > 0:\n",
    "            pos_per_user = pos_rows.groupby(USER_COL)[BOOK_COL].nunique()\n",
    "            if not pos_per_user.empty:\n",
    "                bad_users_pos = pos_per_user[pos_per_user != n_pair]\n",
    "                if len(bad_users_pos) > 0:\n",
    "                    problems.append(f\"{len(bad_users_pos)} users do not have exactly {n_pair} positive books\")\n",
    "        else:\n",
    "            if len(pos_rows) > 0:\n",
    "                problems.append(\"n_pair=0 but positive rows exist (should not happen)\")\n",
    "\n",
    "        # Neg per user uniformity:\n",
    "        neg_per_user_counts = None\n",
    "        if not neg_rows.empty:\n",
    "            neg_per_user_counts = neg_rows.groupby(USER_COL)[BOOK_COL].nunique()\n",
    "            # If mode==\"all\" expect exact |AllBooks - PairBooks|\n",
    "            if info[\"mode\"] == \"all\":\n",
    "                expected_neg = len(set(all_books) - pair_set)\n",
    "                bad_users_neg = neg_per_user_counts[neg_per_user_counts != expected_neg]\n",
    "                if len(bad_users_neg) > 0:\n",
    "                    problems.append(f\"{len(bad_users_neg)} users do not have exactly {expected_neg} negative books\")\n",
    "            # If \"sample\", at least require uniformity (all users same count)\n",
    "            if info[\"mode\"] == \"sample\":\n",
    "                if neg_per_user_counts.nunique() > 1:\n",
    "                    problems.append(\"negatives per user vary under 'sample' mode (expected uniform sample size)\")\n",
    "\n",
    "        # Duplicates (user, book)\n",
    "        dup_pairs = synth_rows.duplicated(subset=[USER_COL, BOOK_COL]).sum()\n",
    "        if dup_pairs > 0:\n",
    "            problems.append(f\"duplicate (user,book) rows among synthetic: {dup_pairs}\")\n",
    "\n",
    "        # Added rows check (robust to 'sample'):\n",
    "        pos_per_user_val = n_pair if n_pair > 0 else 0\n",
    "        neg_per_user_val = int(neg_per_user_counts.median()) if neg_per_user_counts is not None and not neg_per_user_counts.empty else 0\n",
    "        expected_added = info[\"run\"] * (pos_per_user_val + neg_per_user_val)\n",
    "        if len(synth_rows) != expected_added:\n",
    "            problems.append(f\"added_rows={len(synth_rows)} != expected_inferred={expected_added} (pos/user={pos_per_user_val}, neg/userâ‰ˆ{neg_per_user_val}, run={info['run']})\")\n",
    "\n",
    "        status = \"PASS\" if not problems else \"FAIL\"\n",
    "        total_pass += (status == \"PASS\")\n",
    "        total_fail += (status == \"FAIL\")\n",
    "\n",
    "        manifest_rows.append({\n",
    "            \"file\": str(fp),\n",
    "            \"pos_folder\": pos_folder,\n",
    "            \"pair\": f\"{g1} + {g2}\",\n",
    "            \"g1\": g1, \"g2\": g2,\n",
    "            \"run\": info[\"run\"],\n",
    "            \"pos_in_name\": info[\"pos\"],\n",
    "            \"mode\": info[\"mode\"],\n",
    "            \"n_pair_books\": n_pair\n",
    "        })\n",
    "\n",
    "        report_rows.append({\n",
    "            \"file\": str(fp),\n",
    "            \"status\": status,\n",
    "            \"g1\": g1, \"g2\": g2,\n",
    "            \"run\": info[\"run\"],\n",
    "            \"pos\": info[\"pos\"],\n",
    "            \"mode\": info[\"mode\"],\n",
    "            \"n_pair_books\": n_pair,\n",
    "            \"synth_users\": len(synth_users),\n",
    "            \"pos_rows\": len(pos_rows),\n",
    "            \"neg_rows\": len(neg_rows),\n",
    "            \"problems\": \" | \".join(problems) if problems else \"\"\n",
    "        })\n",
    "\n",
    "    # Write outputs at PAIR_ROOT\n",
    "    manifest_path = PAIR_ROOT / \"manifest.csv\"\n",
    "    report_path   = PAIR_ROOT / \"sanity_report.csv\"\n",
    "    pd.DataFrame(manifest_rows).to_csv(manifest_path, index=False)\n",
    "    pd.DataFrame(report_rows).to_csv(report_path, index=False)\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\n=== PAIR INJECTION SANITY CHECK ===\")\n",
    "    print(f\"Files checked: {len([r for r in report_rows if r['status'] in ('PASS','FAIL')])}\")\n",
    "    print(f\"PASS: {total_pass} | FAIL: {total_fail}\")\n",
    "    print(f\"Manifest: {manifest_path}\")\n",
    "    print(f\"Report:   {report_path}\")\n",
    "\n",
    "    if total_fail > 0:\n",
    "        df_rep = pd.DataFrame(report_rows)\n",
    "        print(\"\\nFirst 10 failures:\")\n",
    "        cols = [\"file\", \"status\", \"pair\", \"run\", \"pos\", \"mode\", \"problems\"]\n",
    "        print(df_rep[df_rep[\"status\"] == \"FAIL\"][cols].head(10).to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
