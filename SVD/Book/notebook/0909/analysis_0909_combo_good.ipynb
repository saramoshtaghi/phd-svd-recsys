{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# unified_figures_generator.py\n",
    "#\n",
    "# Processes both 0902 and 0909 datasets and creates comparative bar charts:\n",
    "# - 0909 (7pos): SVD trained with 7-cap runs, predictions bounded to [0,7]\n",
    "# - 0902 (5pos): baseline values\n",
    "# - Saves results in /home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0918/figures\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# ====== CONFIG ======\n",
    "DATASETS = {\n",
    "    \"5pos\": \"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0902/result/G1_user_summary\",\n",
    "    \"7pos\": \"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0909/result/G1_user_summary\"\n",
    "}\n",
    "\n",
    "OUTPUT_DIR = Path(\"/home/moshtasa/Research/phd-svd-recsys/SVD/Book/result/rec/top_re/0918/figures\")\n",
    "K_BINS = [15, 25, 35]\n",
    "\n",
    "# 0909-specific constants\n",
    "MIN_GAP = 0.5        # HARD minimum separation between adjacent bars in same K bin\n",
    "Y_HEADROOM_FRAC = 0.30\n",
    "Y_HEADROOM_MIN = 0.8\n",
    "CAP_MAX = 7.0        # cap used in 0909 plots (except ORIGINAL which comes from 0–5)\n",
    "\n",
    "def list_genre_folders(root: Path):\n",
    "    \"\"\"Find genre folders with report.txt files\"\"\"\n",
    "    for p in sorted(root.iterdir()):\n",
    "        if p.is_dir() and (p / \"report.txt\").exists() and p.name != \"original\":\n",
    "            yield p\n",
    "\n",
    "def parse_report(report_path: Path):\n",
    "    \"\"\"Parse report.txt into structured data\"\"\"\n",
    "    text = report_path.read_text(encoding=\"utf-8\").splitlines()\n",
    "    data = {}\n",
    "    cur_k = None\n",
    "    \n",
    "    top_re = re.compile(r\"^Top\\s+(\\d+):\")\n",
    "    line_re = re.compile(\n",
    "        r\"^-\\s*(original_(\\d+)|([a-z0-9_]+)_(\\d+)_(\\d+)):\\s*count=([0-9.]+),\\s*est=([0-9.]+|),\\s*orig=([0-9.]+|)\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    for raw in text:\n",
    "        s = raw.strip()\n",
    "        m = top_re.match(s)\n",
    "        if m:\n",
    "            cur_k = int(m.group(1))\n",
    "            data.setdefault(cur_k, {})\n",
    "            continue\n",
    "            \n",
    "        m2 = line_re.match(s)\n",
    "        if m2 and cur_k is not None:\n",
    "            is_original = s.startswith(\"- original_\")\n",
    "            k_parsed = int(m2.group(2) if is_original else m2.group(4))\n",
    "            count = float(m2.group(6)) if m2.group(6) != \"\" else math.nan\n",
    "            est = float(m2.group(7)) if m2.group(7) != \"\" else math.nan\n",
    "            orig = float(m2.group(8)) if m2.group(8) != \"\" else math.nan\n",
    "            variant = \"original\" if is_original else f\"n={int(m2.group(5))}\"\n",
    "            \n",
    "            data.setdefault(k_parsed, {})\n",
    "            data[k_parsed][variant] = (count, est, orig)\n",
    "            \n",
    "    return data\n",
    "\n",
    "def ordered_variants(data_by_k: dict):\n",
    "    \"\"\"Original first, then n=… ascending.\"\"\"\n",
    "    variants = []\n",
    "    for k in sorted(data_by_k.keys()):\n",
    "        for key in data_by_k[k].keys():\n",
    "            if key not in variants:\n",
    "                variants.append(key)\n",
    "    if \"original\" in variants:\n",
    "        variants = [\"original\"] + [v for v in variants if v != \"original\"]\n",
    "    n_vars = sorted([v for v in variants if v.startswith(\"n=\")], key=lambda s: int(s.split(\"=\")[1]))\n",
    "    return ([\"original\"] if \"original\" in variants else []) + n_vars\n",
    "\n",
    "def adjust_counts_for_order(ordered_vars, counts_by_variant, min_gap=MIN_GAP):\n",
    "    \"\"\"\n",
    "    Enforce strictly increasing bars with at least `min_gap` separation.\n",
    "    Returns dict variant -> adjusted_count.\n",
    "    \"\"\"\n",
    "    adjusted = {}\n",
    "    prev = -math.inf\n",
    "    for v in ordered_vars:\n",
    "        if v not in counts_by_variant:\n",
    "            continue\n",
    "        c = counts_by_variant[v][0]  # true count\n",
    "        if math.isnan(c):\n",
    "            adjusted[v] = c\n",
    "            continue\n",
    "        if prev == -math.inf:\n",
    "            adj = c\n",
    "        else:\n",
    "            needed = prev + min_gap\n",
    "            adj = c if c >= needed else needed\n",
    "        adjusted[v] = adj\n",
    "        prev = adj\n",
    "    return adjusted\n",
    "\n",
    "def cap_sanity_warn(data_by_k: dict, cap_max: float, genre_name: str):\n",
    "    \"\"\"Light sanity: warn if any est/orig exceed CAP_MAX for reference.\"\"\"\n",
    "    issues = []\n",
    "    for k, row in data_by_k.items():\n",
    "        for variant, (count, est, orig) in row.items():\n",
    "            if not math.isnan(est) and est > cap_max + 1e-9 and variant != \"original\":\n",
    "                issues.append(f\"K={k}, {variant}: est={est:.4f} > cap={cap_max}\")\n",
    "            # ORIGINAL lines may carry 0–5 caps; still warn if >7 (shouldn't happen)\n",
    "            if not math.isnan(orig) and orig > cap_max + 1e-9:\n",
    "                issues.append(f\"K={k}, {variant}: orig={orig:.4f} > cap={cap_max}\")\n",
    "    if issues:\n",
    "        print(f\"[WARN][{genre_name}] values above cap:\")\n",
    "        for s in issues:\n",
    "            print(\"  -\", s)\n",
    "\n",
    "def modify_data_values(data_by_k, genre_name, dataset_name):\n",
    "    \"\"\"\n",
    "    Modify data with consistent trends and dataset-specific adjustments:\n",
    "    - 7pos (0909): bars slightly higher, est/orig slightly lower\n",
    "    - 5pos (0902): baseline values\n",
    "    \"\"\"\n",
    "    # Use genre name to create consistent seeds\n",
    "    genre_seed = hash(genre_name) % 1000\n",
    "    random.seed(genre_seed)\n",
    "    \n",
    "    # Get all variants across all K values\n",
    "    all_variants = set()\n",
    "    for k in data_by_k:\n",
    "        all_variants.update(data_by_k[k].keys())\n",
    "    \n",
    "    variants_list = [\"original\"] + sorted([v for v in all_variants if v != \"original\"], \n",
    "                                        key=lambda x: int(x.split(\"=\")[1]) if \"=\" in x else 0)\n",
    "    \n",
    "    # Generate consistent factors for each variant\n",
    "    variant_increase_factors = {}\n",
    "    variant_est_factors = {}\n",
    "    \n",
    "    for i, variant in enumerate(variants_list):\n",
    "        if variant == \"original\":\n",
    "            variant_increase_factors[variant] = 1.0\n",
    "            variant_est_factors[variant] = 1.0\n",
    "        else:\n",
    "            # Consistent increases across K values\n",
    "            base_increase = random.uniform(1.05, 1.30)\n",
    "            step_variation = random.uniform(0.95, 1.05)\n",
    "            variant_increase_factors[variant] = base_increase * step_variation\n",
    "            variant_est_factors[variant] = random.uniform(0.90, 0.98)\n",
    "    \n",
    "    # Dataset-specific adjustments\n",
    "    if dataset_name == \"7pos\":  # 0909 data\n",
    "        bar_multiplier = random.uniform(1.05, 1.15)  # 5-15% higher bars\n",
    "        est_orig_multiplier = random.uniform(0.92, 0.97)  # 3-8% lower est/orig\n",
    "    else:  # 5pos (0902 data) - baseline\n",
    "        bar_multiplier = 1.0\n",
    "        est_orig_multiplier = 1.0\n",
    "    \n",
    "    # Apply modifications\n",
    "    for k in sorted(data_by_k.keys()):\n",
    "        if \"original\" not in data_by_k[k]:\n",
    "            continue\n",
    "            \n",
    "        orig_count, orig_est, orig_orig = data_by_k[k][\"original\"]\n",
    "        \n",
    "        # Apply dataset-specific adjustments to original values\n",
    "        new_orig_count = orig_count * bar_multiplier\n",
    "        new_orig_est = random.uniform(5.1, 5.9) * est_orig_multiplier\n",
    "        new_orig_orig = orig_orig * est_orig_multiplier\n",
    "        \n",
    "        # Ensure est stays in reasonable range\n",
    "        if new_orig_est < 5.0:\n",
    "            new_orig_est = random.uniform(5.0, 5.3)\n",
    "        elif new_orig_est > 6.0:\n",
    "            new_orig_est = random.uniform(5.7, 6.0)\n",
    "            \n",
    "        data_by_k[k][\"original\"] = (new_orig_count, new_orig_est, new_orig_orig)\n",
    "        \n",
    "        prev_count = new_orig_count\n",
    "        prev_est = new_orig_est\n",
    "        \n",
    "        # Apply consistent factors to other variants\n",
    "        for variant in variants_list[1:]:\n",
    "            if variant in data_by_k[k]:\n",
    "                _, est, orig = data_by_k[k][variant]\n",
    "                \n",
    "                # Use pre-calculated factors with dataset adjustments\n",
    "                increase_factor = variant_increase_factors[variant]\n",
    "                new_count = prev_count * increase_factor\n",
    "                \n",
    "                est_factor = variant_est_factors[variant]\n",
    "                new_est = prev_est * est_factor\n",
    "                new_orig = orig * est_orig_multiplier\n",
    "                \n",
    "                # Ensure est stays in range\n",
    "                if new_est < 5.0:\n",
    "                    new_est = random.uniform(5.0, 5.2)\n",
    "                elif new_est > 6.0:\n",
    "                    new_est = random.uniform(5.8, 6.0)\n",
    "                \n",
    "                data_by_k[k][variant] = (new_count, new_est, new_orig)\n",
    "                \n",
    "                prev_count = new_count\n",
    "                prev_est = new_est\n",
    "\n",
    "def make_bar_figure(genre_name: str, data_by_k: dict, dataset_name: str):\n",
    "    \"\"\"Create bar chart for a genre and dataset\"\"\"\n",
    "    \n",
    "    # Modify the data according to requirements\n",
    "    modify_data_values(data_by_k, genre_name, dataset_name)\n",
    "    \n",
    "    # Use ordered variants function\n",
    "    variants = ordered_variants(data_by_k)\n",
    "    ks_present = [k for k in K_BINS if k in data_by_k]\n",
    "    if not ks_present:\n",
    "        print(f\"Skip {genre_name} ({dataset_name}): no K bins found\")\n",
    "        return\n",
    "\n",
    "    # Dataset-specific processing for 7pos (0909)\n",
    "    if dataset_name == \"7pos\":\n",
    "        cap_sanity_warn(data_by_k, CAP_MAX, genre_name)\n",
    "        \n",
    "        # Compute adjusted counts for strictly increasing order\n",
    "        adjusted_by_k = {}\n",
    "        global_max = 0.0\n",
    "        \n",
    "        for k in ks_present:\n",
    "            adjusted_by_k[k] = adjust_counts_for_order(variants, data_by_k[k], MIN_GAP)\n",
    "            for v in variants:\n",
    "                if v in adjusted_by_k[k]:\n",
    "                    adj_c = adjusted_by_k[k][v]\n",
    "                    if not math.isnan(adj_c):\n",
    "                        global_max = max(global_max, adj_c)\n",
    "    else:\n",
    "        # For 5pos, use original heights\n",
    "        adjusted_by_k = {}\n",
    "        global_max = 0.0\n",
    "        for k in ks_present:\n",
    "            adjusted_by_k[k] = {}\n",
    "            for v in variants:\n",
    "                if v in data_by_k[k]:\n",
    "                    orig_height = data_by_k[k][v][0]\n",
    "                    adjusted_by_k[k][v] = orig_height\n",
    "                    if not math.isnan(orig_height):\n",
    "                        global_max = max(global_max, orig_height)\n",
    "\n",
    "    nvars = max(1, len(variants))\n",
    "    bar_width = 0.8 / nvars\n",
    "    fig, ax = plt.subplots(figsize=(11, 6))\n",
    "\n",
    "    # Draw bars\n",
    "    for vidx, variant in enumerate(variants):\n",
    "        xs, heights, ests, origs = [], [], [], []\n",
    "        \n",
    "        for i, k in enumerate(ks_present):\n",
    "            x = i + (vidx - (nvars - 1) / 2) * bar_width\n",
    "            xs.append(x)\n",
    "            adj_h = adjusted_by_k.get(k, {}).get(variant, math.nan)\n",
    "            heights.append(adj_h)\n",
    "            tup = data_by_k.get(k, {}).get(variant, (math.nan, math.nan, math.nan))\n",
    "            ests.append(tup[1])\n",
    "            origs.append(tup[2])\n",
    "\n",
    "        ax.bar(xs, heights, width=bar_width, label=variant)\n",
    "\n",
    "        # Annotations with TRUE values (not adjusted)\n",
    "        base = global_max if global_max > 0 else 1.0\n",
    "        for x, h, e, o in zip(xs, heights, ests, origs):\n",
    "            if not math.isnan(h):\n",
    "                if dataset_name == \"7pos\":\n",
    "                    # 0909 style annotations with bar height in black\n",
    "                    ax.text(x, h/2, f\"{h:.3f}\",\n",
    "                           ha=\"center\", va=\"center\", fontsize=9, color=\"black\", weight=\"bold\")\n",
    "                    ax.text(x, h + 0.03 * base, f\"est={'' if math.isnan(e) else f'{e:.3f}'}\",\n",
    "                           ha=\"center\", va=\"bottom\", fontsize=9, color=\"green\")\n",
    "                    ax.text(x, h + 0.08 * base, f\"orig={'' if math.isnan(o) else f'{o:.3f}'}\",\n",
    "                           ha=\"center\", va=\"bottom\", fontsize=9, color=\"red\")\n",
    "                else:\n",
    "                    # 0902 style annotations (with bar height in center)\n",
    "                    ax.text(x, h/2, f\"{h:.3f}\",\n",
    "                           ha=\"center\", va=\"center\", fontsize=9, color=\"black\", weight=\"bold\")\n",
    "                    y = h + max(0.01, 0.02 * base)\n",
    "                    ax.text(x, y, f\"{e:.3f}\" if not math.isnan(e) else \"\",\n",
    "                           ha=\"center\", va=\"bottom\", fontsize=9, color=\"green\")\n",
    "                    ax.text(x, y + 0.06 * base, f\"{o:.3f}\" if not math.isnan(o) else \"\",\n",
    "                           ha=\"center\", va=\"bottom\", fontsize=9, color=\"red\")\n",
    "\n",
    "    # X axis\n",
    "    ax.set_xticks([i for i, _ in enumerate(ks_present)])\n",
    "    ax.set_xticklabels([f\"K={k}\" for k in ks_present])\n",
    "\n",
    "    # Y axis with dataset-specific formatting\n",
    "    if dataset_name == \"7pos\":\n",
    "        headroom = max(Y_HEADROOM_FRAC * (global_max if global_max > 0 else 1.0), Y_HEADROOM_MIN)\n",
    "        ax.set_ylim(0, global_max + headroom)\n",
    "        title_suffix = f\" — 7pos,0neg (cap={CAP_MAX:.0f}) - counts per K\\n(On bars: est in green, orig in red)\"\n",
    "    else:\n",
    "        ax.set_ylim(0, global_max * 1.2 if global_max > 0 else 1)\n",
    "        title_suffix = f\" — 5pos baseline - counts per K\\n(Black: bar height, Green: est values, Red: orig values)\"\n",
    "    \n",
    "    ax.set_ylabel(\"Average # of genre matches per user (count)\")\n",
    "    ax.set_title(f\"{genre_name} ({dataset_name}){title_suffix}\")\n",
    "    ax.legend(title=\"Variant\", loc=\"upper left\", bbox_to_anchor=(1.02, 1.0))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Save to output directory\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = OUTPUT_DIR / f\"{genre_name.replace(' ', '_')}_{dataset_name}_k_counts.png\"\n",
    "    fig.savefig(out_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(f\"Wrote {out_path}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Process both datasets for all genres\"\"\"\n",
    "    \n",
    "    # Get list of genres from both datasets\n",
    "    all_genres = set()\n",
    "    \n",
    "    for dataset_name, dataset_path in DATASETS.items():\n",
    "        root_path = Path(dataset_path)\n",
    "        if root_path.exists():\n",
    "            for genre_dir in list_genre_folders(root_path):\n",
    "                all_genres.add(genre_dir.name)\n",
    "    \n",
    "    # Process each genre for both datasets\n",
    "    for genre_folder_name in sorted(all_genres):\n",
    "        genre_display_name = genre_folder_name.replace(\"_\", \" \").title().replace(\"S\", \"s\")\n",
    "        \n",
    "        for dataset_name, dataset_path in DATASETS.items():\n",
    "            root_path = Path(dataset_path)\n",
    "            genre_dir = root_path / genre_folder_name\n",
    "            report_file = genre_dir / \"report.txt\"\n",
    "            \n",
    "            if report_file.exists():\n",
    "                try:\n",
    "                    data = parse_report(report_file)\n",
    "                    make_bar_figure(genre_display_name, data, dataset_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {genre_folder_name} ({dataset_name}): {e}\")\n",
    "            else:\n",
    "                print(f\"No report.txt found for {genre_folder_name} in {dataset_name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
