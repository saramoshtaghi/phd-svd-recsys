{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.23.5 in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-surprise==1.1.0 in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (1.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (from scikit-surprise==1.1.0) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (from scikit-surprise==1.1.0) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (from scikit-surprise==1.1.0) (1.13.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-surprise==1.1.0) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-surprise==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating  decade\n",
      "0      196      242       3  1990.0\n",
      "1      186      302       3  1990.0\n",
      "2       22      377       1  1990.0\n",
      "3      244       51       2  1990.0\n",
      "4      166      346       1  1990.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to your local dataset directory\n",
    "dataset_path = \"/Users/saramoshtaghi/Documents/Research/Recommender Systems/RS/data/ml-100k\"\n",
    "\n",
    "# Load ratings data (assumes the file is 'u.data' in the ml-100k folder)\n",
    "df_ratings = pd.read_csv(f\"{dataset_path}/u.data\", sep='\\t', header=None, \n",
    "                         names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Convert item_id to integer\n",
    "df_ratings['item_id'] = df_ratings['item_id'].astype(int)\n",
    "\n",
    "# Define movie metadata columns based on u.item structure\n",
    "movie_columns = ['item_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
    "                 'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime',\n",
    "                 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
    "                 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "# Load movie metadata from local u.item file\n",
    "df_movies = pd.read_csv(f\"{dataset_path}/u.item\", sep='|', encoding='latin-1',\n",
    "                        names=movie_columns, usecols=['item_id', 'release_date'])\n",
    "\n",
    "# Convert item_id in df_movies to int\n",
    "df_movies['item_id'] = df_movies['item_id'].astype(int)\n",
    "\n",
    "# Merge ratings with movie release dates\n",
    "df_final = pd.merge(df_ratings, df_movies, on='item_id', how='left')\n",
    "\n",
    "# Drop timestamp as it's not needed\n",
    "df_final.drop(columns=['timestamp'], inplace=True)\n",
    "\n",
    "# Convert release_date to datetime, handling missing values\n",
    "df_final['release_date'] = pd.to_datetime(df_final['release_date'], errors='coerce')\n",
    "\n",
    "# Extract the year from release_date\n",
    "df_final['year'] = df_final['release_date'].dt.year\n",
    "\n",
    "# Create a new column 'decade' by rounding down the year to the nearest decade\n",
    "df_final['decade'] = (df_final['year'] // 10) * 10\n",
    "\n",
    "# Drop the 'year' and 'release_date' columns as they're no longer needed\n",
    "df_final.drop(columns=['year', 'release_date'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the final DataFrame\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the df_final dataset as a CSV file in the current directory\n",
    "df_final.to_csv(\"df_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Users Movie Count:\n",
      "user_id           942\n",
      "movies_watched    685\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = df_final \n",
    "# Select 10 random unique users from the dataset\n",
    "random_users = np.random.choice(df['user_id'].unique(), 200, replace=False)\n",
    "\n",
    "# Count how many movies each user watched\n",
    "user_movie_counts = df[df['user_id'].isin(random_users)].groupby('user_id')['item_id'].count()\n",
    "\n",
    "# Convert to DataFrame for better display\n",
    "df_user_movie_counts = user_movie_counts.reset_index()\n",
    "df_user_movie_counts.columns = ['user_id', 'movies_watched']\n",
    "\n",
    "# Display the result\n",
    "print(\"Random Users Movie Count:\")\n",
    "print(df_user_movie_counts.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of movies watched by any user in the entire dataset: 737\n",
      "Minimum number of movies watched by any user in the entire dataset: 20\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "df = df_final  # Assuming df_final is the DataFrame you're working with\n",
    "\n",
    "# Count how many movies each user watched in the entire dataset\n",
    "user_movie_counts_all = df.groupby('user_id')['item_id'].count()\n",
    "\n",
    "# Get the maximum count of movies rated by any user in the entire dataset\n",
    "max_movie_count_all = user_movie_counts_all.max()\n",
    "min_movie_count_all = user_movie_counts_all.min()\n",
    "print(\"Maximum number of movies watched by any user in the entire dataset:\", max_movie_count_all)\n",
    "print(\"Minimum number of movies watched by any user in the entire dataset:\", min_movie_count_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Decades Available: [1990. 1960. 1970. 1950. 1980. 1940. 1930. 1920.]\n",
      "Total Unique Movies Available: 1682\n",
      "Starting User ID for New Users: 944\n",
      "\n",
      "Movies Per Decade:\n",
      "   decade  movie_count\n",
      "0  1920.0            2\n",
      "1  1930.0           29\n",
      "2  1940.0           45\n",
      "3  1950.0           54\n",
      "4  1960.0           43\n",
      "5  1970.0           53\n",
      "6  1980.0          107\n",
      "7  1990.0         1348\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure df_final exists (Load your dataset if needed)\n",
    "# df_final = pd.read_csv(\"your_dataset.csv\")  # Uncomment if df_final is not loaded\n",
    "\n",
    "# Extract unique decades\n",
    "unique_decades = df_final['decade'].dropna().unique()\n",
    "\n",
    "# Extract unique item_ids and count total movies\n",
    "existing_item_ids = df_final['item_id'].unique()\n",
    "total_movies = df_final['item_id'].nunique()\n",
    "\n",
    "# Extract the last user ID in df_final and define a starting point for new users\n",
    "max_existing_user_id = df_final['user_id'].max()\n",
    "num_new_users = 40\n",
    "new_user_start_id = max_existing_user_id + 1\n",
    "\n",
    "# Count movies per decade\n",
    "movies_per_decade = df_final.groupby('decade')['item_id'].nunique().reset_index(name='movie_count')\n",
    "\n",
    "print(\"Unique Decades Available:\", unique_decades)\n",
    "print(\"Total Unique Movies Available:\", total_movies)\n",
    "print(\"Starting User ID for New Users:\", new_user_start_id)\n",
    "print(\"\\nMovies Per Decade:\")\n",
    "print(movies_per_decade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_new_users_dataset(num_new_users, users_per_decade, start_user_id, df_final):\n",
    "    # List to store new user data\n",
    "    new_users_data = []\n",
    "    \n",
    "    # Define fixed decades\n",
    "    decades = [1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990]\n",
    "\n",
    "    # ✅ Loop to create new users\n",
    "    for i in range(num_new_users):\n",
    "        user_id = start_user_id + i  # Generate unique user ID\n",
    "        \n",
    "        # Handle case when index exceeds available decades\n",
    "        if i // users_per_decade >= len(decades):\n",
    "            favorite_decade = decades[-1]  # Assign the last available decade if overflow\n",
    "        else:\n",
    "            favorite_decade = decades[i // users_per_decade]  # Assign a favorite decade for the user\n",
    "\n",
    "        # 🎥 Get all movies from the selected favorite decade\n",
    "        movies_from_fav_decade = df_final[df_final['decade'] == favorite_decade]['item_id'].unique()\n",
    "\n",
    "        # 🎯 Assign a rating of 5.0 only for movies in the favorite decade\n",
    "        for item_id in movies_from_fav_decade:\n",
    "            new_users_data.append([user_id, item_id, 5.0, favorite_decade])\n",
    "\n",
    "    # ✅ Convert new users' data into a DataFrame\n",
    "    df_new_users = pd.DataFrame(new_users_data, columns=['user_id', 'item_id', 'rating', 'decade'])\n",
    "\n",
    "    # 🔄 Merge the new users' data with the original dataset\n",
    "    df_merged = pd.concat([df_final, df_new_users], ignore_index=True)\n",
    "\n",
    "    print(f\"✅ New dataset generated for {num_new_users} users with {users_per_decade} users per decade.\")\n",
    "    print(f\"🔹 New dataset size: {df_merged.shape}\")\n",
    "    \n",
    "    return df_merged, df_new_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Initial number of rows in the original dataset: 100000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Count initial rows in the original dataset\n",
    "initial_rows = df_final.shape[0]\n",
    "print(f\"✅ Initial number of rows in the original dataset: {initial_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ New dataset generated for 40 users with 5 users per decade.\n",
      "🔹 New dataset size: (108405, 4)\n",
      "✅ New dataset generated for 80 users with 10 users per decade.\n",
      "🔹 New dataset size: (116810, 4)\n",
      "✅ New dataset generated for 120 users with 15 users per decade.\n",
      "🔹 New dataset size: (125215, 4)\n"
     ]
    }
   ],
   "source": [
    "# Generate dataset for 40 new users (5 users per decade)\n",
    "df_40_40, df_new_40 = create_new_users_dataset(40, 5, 944, df_final)\n",
    "\n",
    "# Generate dataset for 80 new users (10 users per decade)\n",
    "df_40_80, df_new_80 = create_new_users_dataset(80, 10, 944, df_final)\n",
    "\n",
    "# Generate dataset for 120 new users (15 users per decade)\n",
    "df_40_120, df_new_120 = create_new_users_dataset(120, 15, 944, df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All 40 new users have 1 and only 1 favorite decade.\n",
      "✅ All 80 new users have 1 and only 1 favorite decade.\n",
      "✅ All 120 new users have 1 and only 1 favorite decade.\n"
     ]
    }
   ],
   "source": [
    "def check_validity(df_new_users, num_users):\n",
    "    # 🔍 Check if any user has been mistakenly assigned more than 1 favorite decade\n",
    "    favorite_decades_per_user = df_new_users.groupby('user_id')['decade'].nunique()\n",
    "    multiple_favorite_decades = favorite_decades_per_user[favorite_decades_per_user > 1]\n",
    "\n",
    "    # ✅ Verify that no user has more than 1 favorite decade\n",
    "    if multiple_favorite_decades.empty:\n",
    "        print(f\"✅ All {num_users} new users have 1 and only 1 favorite decade.\")\n",
    "    else:\n",
    "        print(f\"❌ These users have more than 1 favorite decade: {multiple_favorite_decades.index.tolist()}\")\n",
    "\n",
    "# Check validity for 40 new users\n",
    "check_validity(df_new_40, 40)\n",
    "\n",
    "# Check validity for 80 new users\n",
    "check_validity(df_new_80, 80)\n",
    "\n",
    "# Check validity for 120 new users\n",
    "check_validity(df_new_120, 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ First three columns of each dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Select the first three columns for each dataset\n",
    "columns_to_save = ['user_id', 'item_id', 'rating']\n",
    "\n",
    "# Extract and save the selected columns for each dataset\n",
    "df_40_40[columns_to_save].to_csv(\"df_40.csv\", index=False)\n",
    "df_40_80[columns_to_save].to_csv(\"df_80.csv\", index=False)\n",
    "df_40_120[columns_to_save].to_csv(\"df_120.csv\", index=False)\n",
    "\n",
    "print(\"✅ First three columns of each dataset saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting python-pptx\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (from python-pptx) (11.0.0)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
      "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting lxml>=3.1.0 (from python-pptx)\n",
      "  Downloading lxml-5.3.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (3.7 kB)\n",
      "Collecting typing-extensions>=4.9.0 (from python-pptx)\n",
      "  Downloading typing_extensions-4.13.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "Downloading lxml-5.3.1-cp39-cp39-macosx_10_9_universal2.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.13.0-py3-none-any.whl (45 kB)\n",
      "Downloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
      "Installing collected packages: XlsxWriter, typing-extensions, lxml, python-pptx\n",
      "Successfully installed XlsxWriter-3.2.2 lxml-5.3.1 python-pptx-1.0.2 typing-extensions-4.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-pptx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PowerPoint presentation created successfully: Impact_of_Adding_Users.pptx\n"
     ]
    }
   ],
   "source": [
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "\n",
    "\n",
    "# Create a new PowerPoint presentation\n",
    "prs = Presentation()\n",
    "\n",
    "# Define a title and content layout\n",
    "title_slide_layout = prs.slide_layouts[0]\n",
    "content_slide_layout = prs.slide_layouts[1]\n",
    "\n",
    "# 🎯 Slide 1: Introduction\n",
    "slide1 = prs.slides.add_slide(title_slide_layout)\n",
    "title1 = slide1.shapes.title\n",
    "subtitle1 = slide1.placeholders[1]\n",
    "\n",
    "title1.text = \"Impact of Adding New Users on Dataset\"\n",
    "subtitle1.text = \"Analyzing dataset size after adding 40, 80, and 120 new users.\\nEach user rates movies from their favorite decade.\"\n",
    "\n",
    "# 🎯 Slide 2: Scenario 1 – Adding 40 New Users\n",
    "slide2 = prs.slides.add_slide(content_slide_layout)\n",
    "title2, content2 = slide2.shapes.title, slide2.placeholders[1]\n",
    "\n",
    "title2.text = \"Scenario 1: Adding 40 New Users\"\n",
    "content2.text = (\n",
    "    \"✅ Users 944 to 948 rate movies from 1920 (2 movies each).\\n\"\n",
    "    \"✅ Users 949 to 953 rate movies from 1930 (29 movies each).\\n\"\n",
    "    \"✅ Users continue rating movies based on their favorite decade.\\n\"\n",
    "    \"✅ Total New Ratings = 8,405\\n\"\n",
    "    \"🔹 New Dataset Size: 108,405 rows.\"\n",
    ")\n",
    "\n",
    "# 🎯 Slide 3: Scenario 2 – Adding 80 New Users\n",
    "slide3 = prs.slides.add_slide(content_slide_layout)\n",
    "title3, content3 = slide3.shapes.title, slide3.placeholders[1]\n",
    "\n",
    "title3.text = \"Scenario 2: Adding 80 New Users\"\n",
    "content3.text = (\n",
    "    \"✅ 10 users per decade, rating movies from their favorite decade.\\n\"\n",
    "    \"✅ Total New Ratings = 16,810\\n\"\n",
    "    \"🔹 New Dataset Size: 116,810 rows.\"\n",
    ")\n",
    "\n",
    "# 🎯 Slide 4: Scenario 3 – Adding 120 New Users\n",
    "slide4 = prs.slides.add_slide(content_slide_layout)\n",
    "title4, content4 = slide4.shapes.title, slide4.placeholders[1]\n",
    "\n",
    "title4.text = \"Scenario 3: Adding 120 New Users\"\n",
    "content4.text = (\n",
    "    \"✅ 15 users per decade, rating movies from their favorite decade.\\n\"\n",
    "    \"✅ Total New Ratings = 25,215\\n\"\n",
    "    \"🔹 New Dataset Size: 125,215 rows.\"\n",
    ")\n",
    "\n",
    "# 🎯 Slide 5: Final Summary\n",
    "slide5 = prs.slides.add_slide(content_slide_layout)\n",
    "title5, content5 = slide5.shapes.title, slide5.placeholders[1]\n",
    "\n",
    "title5.text = \"Final Summary\"\n",
    "content5.text = (\n",
    "    \"🔹 40 Users: 8,405 new ratings → 108,405 rows\\n\"\n",
    "    \"🔹 80 Users: 16,810 new ratings → 116,810 rows\\n\"\n",
    "    \"🔹 120 Users: 25,215 new ratings → 125,215 rows\\n\"\n",
    "    \"✅ Adding more users increases the dataset size significantly.\"\n",
    ")\n",
    "\n",
    "# Save the PowerPoint presentation\n",
    "prs.save(\"Impact_of_Adding_Users.pptx\")\n",
    "\n",
    "print(\"✅ PowerPoint presentation created successfully: Impact_of_Adding_Users.pptx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
