{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.23.5 in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-surprise==1.1.0 in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (1.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (from scikit-surprise==1.1.0) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (from scikit-surprise==1.1.0) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (from scikit-surprise==1.1.0) (1.13.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-surprise==1.1.0) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-surprise==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and add the decade column by performing a join operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating  decade\n",
      "0      196      242       3  1990.0\n",
      "1      186      302       3  1990.0\n",
      "2       22      377       1  1990.0\n",
      "3      244       51       2  1990.0\n",
      "4      166      346       1  1990.0\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your local dataset directory\n",
    "dataset_path = \"../data/ml-100k\"\n",
    "\n",
    "# Load ratings data (assumes the file is 'u.data' in the ml-100k folder)\n",
    "df_ratings = pd.read_csv(f\"{dataset_path}/u.data\", sep='\\t', header=None, \n",
    "                         names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Convert item_id to integer\n",
    "df_ratings['item_id'] = df_ratings['item_id'].astype(int)\n",
    "\n",
    "# Define movie metadata columns based on u.item structure\n",
    "movie_columns = ['item_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
    "                 'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime',\n",
    "                 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
    "                 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "# Load movie metadata from local u.item file\n",
    "df_movies = pd.read_csv(f\"{dataset_path}/u.item\", sep='|', encoding='latin-1',\n",
    "                        names=movie_columns, usecols=['item_id', 'release_date'])\n",
    "\n",
    "# Convert item_id in df_movies to int\n",
    "df_movies['item_id'] = df_movies['item_id'].astype(int)\n",
    "\n",
    "# Merge ratings with movie release dates\n",
    "df_final = pd.merge(df_ratings, df_movies, on='item_id', how='left')\n",
    "\n",
    "# Drop timestamp as it's not needed\n",
    "df_final.drop(columns=['timestamp'], inplace=True)\n",
    "\n",
    "# Convert release_date to datetime, handling missing values\n",
    "df_final['release_date'] = pd.to_datetime(df_final['release_date'], errors='coerce')\n",
    "\n",
    "# Extract the year from release_date\n",
    "df_final['year'] = df_final['release_date'].dt.year\n",
    "\n",
    "# Create a new column 'decade' by rounding down the year to the nearest decade\n",
    "df_final['decade'] = (df_final['year'] // 10) * 10\n",
    "\n",
    "# Drop the 'year' and 'release_date' columns as they're no longer needed\n",
    "df_final.drop(columns=['year', 'release_date'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the final DataFrame\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df_final dataset as a CSV file in the current directory\n",
    "df_final.to_csv(\"../data/df_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Users Movie Count:\n",
      "user_id           940\n",
      "movies_watched    685\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df_final \n",
    "# Select 10 random unique users from the dataset\n",
    "random_users = np.random.choice(df['user_id'].unique(), 200, replace=False)\n",
    "\n",
    "# Count how many movies each user watched\n",
    "user_movie_counts = df[df['user_id'].isin(random_users)].groupby('user_id')['item_id'].count()\n",
    "\n",
    "# Convert to DataFrame for better display\n",
    "df_user_movie_counts = user_movie_counts.reset_index()\n",
    "df_user_movie_counts.columns = ['user_id', 'movies_watched']\n",
    "\n",
    "# Display the result\n",
    "print(\"Random Users Movie Count:\")\n",
    "print(df_user_movie_counts.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of movies watched by any user in the entire dataset: 737\n",
      "Minimum number of movies watched by any user in the entire dataset: 20\n"
     ]
    }
   ],
   "source": [
    "df = df_final  # Assuming df_final is the DataFrame you're working with\n",
    "\n",
    "# Count how many movies each user watched in the entire dataset\n",
    "user_movie_counts_all = df.groupby('user_id')['item_id'].count()\n",
    "\n",
    "# Get the maximum count of movies rated by any user in the entire dataset\n",
    "max_movie_count_all = user_movie_counts_all.max()\n",
    "min_movie_count_all = user_movie_counts_all.min()\n",
    "print(\"Maximum number of movies watched by any user in the entire dataset:\", max_movie_count_all)\n",
    "print(\"Minimum number of movies watched by any user in the entire dataset:\", min_movie_count_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting Movies Per Decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Decades Available: [1990. 1960. 1970. 1950. 1980. 1940. 1930. 1920.]\n",
      "\n",
      "Movies Per Decade:\n",
      "   decade  movie_count\n",
      "0  1920.0            2\n",
      "1  1930.0           29\n",
      "2  1940.0           45\n",
      "3  1950.0           54\n",
      "4  1960.0           43\n",
      "5  1970.0           53\n",
      "6  1980.0          107\n",
      "7  1990.0         1348\n",
      "\n",
      "Total Unique Movies Available: 1682\n",
      "Starting User ID for New Users: 944\n",
      "Columns: Index(['user_id', 'item_id', 'rating', 'decade'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Ensure df_final exists (Load your dataset if needed)\n",
    "# df_final = pd.read_csv(\"your_dataset.csv\")  # Uncomment if df_final is not loaded\n",
    "\n",
    "# Extract unique decades\n",
    "unique_decades = df_final['decade'].dropna().unique()\n",
    "\n",
    "# Extract unique item_ids and count total movies\n",
    "existing_item_ids = df_final['item_id'].unique()\n",
    "total_movies = df_final['item_id'].nunique()\n",
    "\n",
    "# Extract the last user ID in df_final and define a starting point for new users\n",
    "max_existing_user_id = df_final['user_id'].max()\n",
    "#min_existing_user_id = df_final['user_id'].min()\n",
    "num_new_users = 40\n",
    "new_user_start_id = max_existing_user_id + 1\n",
    "\n",
    "# Count movies per decade\n",
    "movies_per_decade = df_final.groupby('decade')['item_id'].nunique().reset_index(name='movie_count')\n",
    "print(\"Unique Decades Available:\", unique_decades)\n",
    "print(\"\\nMovies Per Decade:\")\n",
    "print(movies_per_decade)\n",
    "print(\"\\nTotal Unique Movies Available:\", total_movies)\n",
    "print(\"Starting User ID for New Users:\", new_user_start_id)\n",
    "print(\"Columns:\", df_final.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate User Ratings by Decade: For each user, count the number of movies they’ve rated in each of the 8 decades. You’ll end up with a 943 x 8 matrix where each row is a user, and each column is a decade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Code to compute user-decade diversity and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>1920.0</th>\n",
       "      <th>1930.0</th>\n",
       "      <th>1940.0</th>\n",
       "      <th>1950.0</th>\n",
       "      <th>1960.0</th>\n",
       "      <th>1970.0</th>\n",
       "      <th>1980.0</th>\n",
       "      <th>1990.0</th>\n",
       "      <th>1920_norm</th>\n",
       "      <th>1930_norm</th>\n",
       "      <th>1940_norm</th>\n",
       "      <th>1950_norm</th>\n",
       "      <th>1960_norm</th>\n",
       "      <th>1970_norm</th>\n",
       "      <th>1980_norm</th>\n",
       "      <th>1990_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>44</td>\n",
       "      <td>192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.033210</td>\n",
       "      <td>0.066421</td>\n",
       "      <td>0.162362</td>\n",
       "      <td>0.708487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.183908</td>\n",
       "      <td>0.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.074766</td>\n",
       "      <td>0.261682</td>\n",
       "      <td>0.598131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>942</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.139241</td>\n",
       "      <td>0.481013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>943</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.154762</td>\n",
       "      <td>0.720238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  1920.0  1930.0  1940.0  1950.0  1960.0  1970.0  1980.0  1990.0  \\\n",
       "0          1       0       4       1       3       9      18      44     192   \n",
       "1          2       0       0       0       0       0       2       0      60   \n",
       "2          3       0       0       0       0       0       0       0      54   \n",
       "3          4       0       0       0       0       0       2       1      21   \n",
       "4          5       0       2       3       6       9      20      32     102   \n",
       "..       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "938      939       0       0       0       0       0       1       0      48   \n",
       "939      940       0       1       0       3       3       8      28      64   \n",
       "940      941       0       0       0       0       0       0       0      22   \n",
       "941      942       0       3       7       6       9       5      11      38   \n",
       "942      943       0       1       0       3       7      10      26     121   \n",
       "\n",
       "     1920_norm  1930_norm  1940_norm  1950_norm  1960_norm  1970_norm  \\\n",
       "0          0.0   0.014760   0.003690   0.011070   0.033210   0.066421   \n",
       "1          0.0   0.000000   0.000000   0.000000   0.000000   0.032258   \n",
       "2          0.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3          0.0   0.000000   0.000000   0.000000   0.000000   0.083333   \n",
       "4          0.0   0.011494   0.017241   0.034483   0.051724   0.114943   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "938        0.0   0.000000   0.000000   0.000000   0.000000   0.020408   \n",
       "939        0.0   0.009346   0.000000   0.028037   0.028037   0.074766   \n",
       "940        0.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "941        0.0   0.037975   0.088608   0.075949   0.113924   0.063291   \n",
       "942        0.0   0.005952   0.000000   0.017857   0.041667   0.059524   \n",
       "\n",
       "     1980_norm  1990_norm  \n",
       "0     0.162362   0.708487  \n",
       "1     0.000000   0.967742  \n",
       "2     0.000000   1.000000  \n",
       "3     0.041667   0.875000  \n",
       "4     0.183908   0.586207  \n",
       "..         ...        ...  \n",
       "938   0.000000   0.979592  \n",
       "939   0.261682   0.598131  \n",
       "940   0.000000   1.000000  \n",
       "941   0.139241   0.481013  \n",
       "942   0.154762   0.720238  \n",
       "\n",
       "[943 rows x 17 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Count number of ratings per user per decade\n",
    "user_decade_counts = df_final.groupby(['user_id', 'decade']).size().unstack(fill_value=0)\n",
    "\n",
    "# Step 2: Normalize counts so each user's row sums to 1\n",
    "user_decade_normalized = user_decade_counts.div(user_decade_counts.sum(axis=1), axis=0)\n",
    "\n",
    "# Step 3: Rename columns to indicate normalization\n",
    "user_decade_normalized.columns = [f'{int(c)}_norm' for c in user_decade_normalized.columns]\n",
    "\n",
    "# Step 4: Merge raw counts with normalized values\n",
    "user_decade_merged = pd.concat([user_decade_counts, user_decade_normalized], axis=1).reset_index()\n",
    "\n",
    "# Step 5: Preview the result\n",
    "#print(user_decade_merged.head())\n",
    "user_decade_merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user segmentation based on rating diversity across movie decades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id   entropy  cluster\n",
      "0        1  0.965269        1\n",
      "1        2  0.142506        0\n",
      "2        3  0.000000        0\n",
      "3        4  0.456334        0\n",
      "4        5  1.263807        2\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Step 1: Get counts of ratings per user per decade\n",
    "user_decade_counts = df_final.groupby(['user_id', 'decade']).size().unstack(fill_value=0)\n",
    "\n",
    "# Step 2: Normalize counts to get distribution (row-wise)\n",
    "user_decade_dist = user_decade_counts.div(user_decade_counts.sum(axis=1), axis=0)\n",
    "\n",
    "# Step 3: Calculate entropy (diversity) for each user\n",
    "user_entropy = user_decade_dist.apply(lambda x: entropy(x), axis=1).to_frame(name='entropy')\n",
    "user_entropy.reset_index(inplace=True)\n",
    "\n",
    "# Step 4: Clustering into 3 groups\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "user_entropy['cluster'] = kmeans.fit_predict(user_entropy[['entropy']])\n",
    "\n",
    "# Step 5: Optional — sort clusters by average entropy for interpretation\n",
    "cluster_order = user_entropy.groupby('cluster')['entropy'].mean().sort_values().index\n",
    "entropy_cluster_map = {old: new for new, old in enumerate(cluster_order)}\n",
    "user_entropy['cluster'] = user_entropy['cluster'].map(entropy_cluster_map)\n",
    "\n",
    "# Show sample result\n",
    "print(user_entropy.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>entropy</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.263807</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.501209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.531251</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.299553</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.588313</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>928</td>\n",
       "      <td>1.195612</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>929</td>\n",
       "      <td>1.711779</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>932</td>\n",
       "      <td>1.820856</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>934</td>\n",
       "      <td>1.570135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>942</td>\n",
       "      <td>1.583434</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id   entropy  cluster\n",
       "4          5  1.263807        2\n",
       "5          6  1.501209        2\n",
       "6          7  1.531251        2\n",
       "8          9  1.299553        2\n",
       "9         10  1.588313        2\n",
       "..       ...       ...      ...\n",
       "927      928  1.195612        2\n",
       "928      929  1.711779        2\n",
       "931      932  1.820856        2\n",
       "933      934  1.570135        2\n",
       "941      942  1.583434        2\n",
       "\n",
       "[303 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_entropy[user_entropy[\"cluster\"] ==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users per cluster:\n",
      " cluster\n",
      "0    353\n",
      "1    287\n",
      "2    303\n",
      "Name: count, dtype: int64\n",
      "\n",
      "15 example user_ids per cluster:\n",
      "Cluster 0: [462, 839, 359, 45, 510, 111, 63, 919, 410, 728, 525, 227, 677, 284, 614]\n",
      "Cluster 1: [430, 758, 727, 457, 606, 174, 886, 268, 219, 684, 605, 665, 11, 323, 87]\n",
      "Cluster 2: [641, 28, 876, 924, 202, 318, 561, 412, 843, 123, 524, 738, 535, 452, 474]\n"
     ]
    }
   ],
   "source": [
    "# 1. Count of users per cluster\n",
    "user_counts = user_entropy['cluster'].value_counts().sort_index()\n",
    "print(\"Users per cluster:\\n\", user_counts)\n",
    "\n",
    "# 2. Get 10 example user_ids per cluster\n",
    "example_users = user_entropy.groupby('cluster')['user_id'].apply(\n",
    "    lambda x: x.sample(15, random_state=11)\n",
    ").reset_index()  # keep the cluster column\n",
    "print(\"\\n15 example user_ids per cluster:\")\n",
    "for cluster in sorted(example_users['cluster'].unique()):\n",
    "    users = example_users[example_users['cluster'] == cluster]['user_id'].tolist()\n",
    "    print(f\"Cluster {cluster}: {users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cluster 0:\n",
      " user_id        941\n",
      "num_ratings    435\n",
      "dtype: int64\n",
      "\n",
      "cluster 1:\n",
      " user_id        943\n",
      "num_ratings    737\n",
      "dtype: int64\n",
      "\n",
      "cluster 2:\n",
      " user_id        942\n",
      "num_ratings    540\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Get user_ids from Cluster 0 (low entropy)\n",
    "cluster_0_users = user_entropy[user_entropy['cluster'] == 0]['user_id']\n",
    "cluster_1_users = user_entropy[user_entropy['cluster'] == 1]['user_id']\n",
    "cluster_2_users = user_entropy[user_entropy['cluster'] == 2]['user_id']\n",
    "\n",
    "# Step 2: Filter original df_final for only those users\n",
    "cluster_0_ratings = df_final[df_final['user_id'].isin(cluster_0_users)]\n",
    "cluster_1_ratings = df_final[df_final['user_id'].isin(cluster_1_users)]\n",
    "cluster_2_ratings = df_final[df_final['user_id'].isin(cluster_2_users)]\n",
    "\n",
    "# Step 3: Count ratings per user\n",
    "ratings_per_user_cluster_0 = cluster_0_ratings.groupby('user_id').size().reset_index(name='num_ratings')\n",
    "ratings_per_user_cluster_1 = cluster_1_ratings.groupby('user_id').size().reset_index(name='num_ratings')\n",
    "ratings_per_user_cluster_2 = cluster_2_ratings.groupby('user_id').size().reset_index(name='num_ratings')\n",
    "\n",
    "# Step 4: Preview the result\n",
    "print(\"\\ncluster 0:\\n\", ratings_per_user_cluster_0.max())\n",
    "print(\"\\ncluster 1:\\n\", ratings_per_user_cluster_1.max())\n",
    "print(\"\\ncluster 2:\\n\", ratings_per_user_cluster_2.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_id 728 belongs to cluster: 2\n"
     ]
    }
   ],
   "source": [
    "# Find the cluster for user_id == 728\n",
    "user_cluster_728 = user_entropy[user_entropy['user_id'] == 942]['cluster'].values[0]\n",
    "\n",
    "# Print the result\n",
    "print(f\"User_id 728 belongs to cluster: {user_cluster_728}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('..result/clusters/cluster_0_users.csv',\n",
       " '../result/data/cluster_1_users.csv',\n",
       " '../result/data/cluster_2_users.csv')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Get user clusters\n",
    "user_clusters = user_entropy[['user_id', 'cluster']]\n",
    "\n",
    "# Step 2: Count number of ratings per user\n",
    "user_rating_counts = df_final.groupby('user_id').size().reset_index(name='num_ratings')\n",
    "\n",
    "# Step 3: Merge counts with cluster labels\n",
    "user_info = pd.merge(user_clusters, user_rating_counts, on='user_id')\n",
    "\n",
    "# Step 4: Split into three DataFrames by cluster\n",
    "cluster_0_df = user_info[user_info['cluster'] == 0][['user_id', 'num_ratings']]\n",
    "cluster_1_df = user_info[user_info['cluster'] == 1][['user_id', 'num_ratings']]\n",
    "cluster_2_df = user_info[user_info['cluster'] == 2][['user_id', 'num_ratings']]\n",
    "\n",
    "# Step 5: Save to CSV\n",
    "cluster_0_df.to_csv(\"../cluster_0_users.csv\", index=False)\n",
    "cluster_1_df.to_csv(\"../cluster_1_users.csv\", index=False)\n",
    "cluster_2_df.to_csv(\"../cluster_2_users.csv\", index=False)\n",
    "\n",
    "\"..result/clusters/cluster_0_users.csv\", \"../result/data/cluster_1_users.csv\", \"../result/data/cluster_2_users.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating biased datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_users_dataset(num_new_users, users_per_decade, start_user_id, df_final):\n",
    "    # List to store new user data\n",
    "    new_users_data = []\n",
    "    \n",
    "    # Define fixed decades\n",
    "    decades = [1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990]\n",
    "\n",
    "    # ✅ Loop to create new users\n",
    "    for i in range(num_new_users):\n",
    "        user_id = start_user_id + i  # Generate unique user ID\n",
    "        \n",
    "        # Handle case when index exceeds available decades\n",
    "        if i // users_per_decade >= len(decades):\n",
    "            favorite_decade = decades[-1]  # Assign the last available decade if overflow\n",
    "        else:\n",
    "            favorite_decade = decades[i // users_per_decade]  # Assign a favorite decade for the user\n",
    "\n",
    "        # 🎥 Get all movies from the selected favorite decade\n",
    "        movies_from_fav_decade = df_final[df_final['decade'] == favorite_decade]['item_id'].unique()\n",
    "\n",
    "        # 🎯 Assign a rating of 5.0 only for movies in the favorite decade\n",
    "        for item_id in movies_from_fav_decade:\n",
    "            new_users_data.append([user_id, item_id, 5.0, favorite_decade])\n",
    "\n",
    "    # ✅ Convert new users' data into a DataFrame\n",
    "    df_new_users = pd.DataFrame(new_users_data, columns=['user_id', 'item_id', 'rating', 'decade'])\n",
    "\n",
    "    # 🔄 Merge the new users' data with the original dataset\n",
    "    df_merged = pd.concat([df_final, df_new_users], ignore_index=True)\n",
    "\n",
    "    print(f\"✅ New dataset generated for {num_new_users} users with {users_per_decade} users per decade.\")\n",
    "    print(f\"🔹 New dataset size: {df_merged.shape}\")\n",
    "    \n",
    "    return df_merged, df_new_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Initial number of rows in the original dataset: 100000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Count initial rows in the original dataset\n",
    "initial_rows = df_final.shape[0]\n",
    "print(f\"✅ Initial number of rows in the original dataset: {initial_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ New dataset generated for 40 users with 5 users per decade.\n",
      "🔹 New dataset size: (108405, 4)\n",
      "✅ New dataset generated for 80 users with 10 users per decade.\n",
      "🔹 New dataset size: (116810, 4)\n",
      "✅ New dataset generated for 120 users with 15 users per decade.\n",
      "🔹 New dataset size: (125215, 4)\n"
     ]
    }
   ],
   "source": [
    "# Generate dataset for 40 new users (5 users per decade)\n",
    "df_40_40, df_new_40 = create_new_users_dataset(40, 5, 944, df_final)\n",
    "\n",
    "# Generate dataset for 80 new users (10 users per decade)\n",
    "df_40_80, df_new_80 = create_new_users_dataset(80, 10, 944, df_final)\n",
    "\n",
    "# Generate dataset for 120 new users (15 users per decade)\n",
    "df_40_120, df_new_120 = create_new_users_dataset(120, 15, 944, df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All 40 new users have 1 and only 1 favorite decade.\n",
      "✅ All 80 new users have 1 and only 1 favorite decade.\n",
      "✅ All 120 new users have 1 and only 1 favorite decade.\n"
     ]
    }
   ],
   "source": [
    "def check_validity(df_new_users, num_users):\n",
    "    # 🔍 Check if any user has been mistakenly assigned more than 1 favorite decade\n",
    "    favorite_decades_per_user = df_new_users.groupby('user_id')['decade'].nunique()\n",
    "    multiple_favorite_decades = favorite_decades_per_user[favorite_decades_per_user > 1]\n",
    "\n",
    "    # ✅ Verify that no user has more than 1 favorite decade\n",
    "    if multiple_favorite_decades.empty:\n",
    "        print(f\"✅ All {num_users} new users have 1 and only 1 favorite decade.\")\n",
    "    else:\n",
    "        print(f\"❌ These users have more than 1 favorite decade: {multiple_favorite_decades.index.tolist()}\")\n",
    "\n",
    "# Check validity for 40 new users\n",
    "check_validity(df_new_40, 40)\n",
    "\n",
    "# Check validity for 80 new users\n",
    "check_validity(df_new_80, 80)\n",
    "\n",
    "# Check validity for 120 new users\n",
    "check_validity(df_new_120, 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ First three columns of each dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Select the first three columns for each dataset\n",
    "columns_to_save = ['user_id', 'item_id', 'rating']\n",
    "\n",
    "# Extract and save the selected columns for each dataset\n",
    "df_40_40[columns_to_save].to_csv(\"df_40.csv\", index=False)\n",
    "df_40_80[columns_to_save].to_csv(\"df_80.csv\", index=False)\n",
    "df_40_120[columns_to_save].to_csv(\"df_120.csv\", index=False)\n",
    "\n",
    "print(\"✅ First three columns of each dataset saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1M"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
