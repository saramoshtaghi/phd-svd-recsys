{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47774.38s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-surprise in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (1.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (from scikit-surprise) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/saramoshtaghi/Library/Python/3.9/lib/python/site-packages (from scikit-surprise) (1.13.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv(f\"{data_path}/final_svd_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rating",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ea7a6d54-8aed-4888-be52-6ab8b5b46354",
       "rows": [
        [
         "count",
         "5970537.0"
        ],
        [
         "mean",
         "3.9196665224585328"
        ],
        [
         "std",
         "0.9910472682840205"
        ],
        [
         "min",
         "1.0"
        ],
        [
         "25%",
         "3.0"
        ],
        [
         "50%",
         "4.0"
        ],
        [
         "75%",
         "5.0"
        ],
        [
         "max",
         "5.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/plain": [
       "count    5.970537e+06\n",
       "mean     3.919667e+00\n",
       "std      9.910473e-01\n",
       "min      1.000000e+00\n",
       "25%      3.000000e+00\n",
       "50%      4.000000e+00\n",
       "75%      5.000000e+00\n",
       "max      5.000000e+00\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'book_id', 'rating', 'decade'], dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [76], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m reader \u001b[38;5;241m=\u001b[39m Reader(rating_scale\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load data into Surprise format\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m data \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mload_from_df(df_final[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]], reader)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Split into train and test sets\u001b[39;00m\n\u001b[1;32m     14\u001b[0m trainset, testset \u001b[38;5;241m=\u001b[39m train_test_split(data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/surprise/dataset.py:167\u001b[0m, in \u001b[0;36mDataset.load_from_df\u001b[0;34m(cls, df, reader)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_df\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, reader):\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a dataset from a pandas dataframe.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    Use this if you want to use a custom dataset that is stored in a pandas\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m            specified.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDatasetAutoFolds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/surprise/dataset.py:262\u001b[0m, in \u001b[0;36mDatasetAutoFolds.__init__\u001b[0;34m(self, ratings_file, reader, df)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m df\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_ratings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    263\u001b[0m         (uid, iid, \u001b[38;5;28mfloat\u001b[39m(r), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    265\u001b[0m     ]\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify ratings file or dataframe.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/surprise/dataset.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m df\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_ratings \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 263\u001b[0m         (uid, iid, \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    265\u001b[0m     ]\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify ratings file or dataframe.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# ---------------------\n",
    "# Load dataset\n",
    "# ---------------------\n",
    "df_final = pd.read_csv(\"df_original.csv\")  # Ensure the file is in the same directory\n",
    "\n",
    "# Optional: Convert user_id and book_id to strings (Surprise handles strings better)\n",
    "df_final['user_id'] = df_final['user_id'].astype(str)\n",
    "df_final['book_id'] = df_final['book_id'].astype(str)\n",
    "\n",
    "# ---------------------\n",
    "# Prepare Surprise Dataset\n",
    "# ---------------------\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_final[['user_id', 'book_id', 'rating']], reader)\n",
    "\n",
    "# Split into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# ---------------------\n",
    "# Train SVD model\n",
    "# ---------------------\n",
    "svd = SVD(n_factors=100, random_state=42)\n",
    "svd.fit(trainset)\n",
    "\n",
    "# ---------------------\n",
    "# Evaluate RMSE\n",
    "# ---------------------\n",
    "predictions = svd.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "\n",
    "# ---------------------\n",
    "# Generate Top-25 Recommendations per User\n",
    "# ---------------------\n",
    "all_user_ids = df_final['user_id'].unique()\n",
    "all_book_ids = df_final['book_id'].unique()\n",
    "\n",
    "user_recommendations = {}\n",
    "\n",
    "print(\"Generating recommendations...\")\n",
    "for i, user_id in enumerate(all_user_ids):\n",
    "    rated_books = df_final[df_final['user_id'] == user_id]['book_id'].tolist()\n",
    "    unseen_books = [book for book in all_book_ids if book not in rated_books]\n",
    "    \n",
    "    preds = [(book, svd.predict(user_id, book).est) for book in unseen_books]\n",
    "    top_preds = sorted(preds, key=lambda x: x[1], reverse=True)[:25]\n",
    "    \n",
    "    user_recommendations[user_id] = [book for book, _ in top_preds]\n",
    "    \n",
    "    if i % 500 == 0:\n",
    "        print(f\"Processed {i}/{len(all_user_ids)} users\")\n",
    "\n",
    "# ---------------------\n",
    "# Save Recommendations to CSV\n",
    "# ---------------------\n",
    "with open('user_recommendations.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['user_id', 'recommended_books'])\n",
    "    for user_id, books in user_recommendations.items():\n",
    "        writer.writerow([user_id, ','.join(map(str, books))])\n",
    "\n",
    "# ---------------------\n",
    "# Save RMSE to a text file\n",
    "# ---------------------\n",
    "with open('svd_rmse.txt', 'w') as f:\n",
    "    f.write(f\"RMSE: {rmse:.4f}\\n\")\n",
    "\n",
    "# ---------------------\n",
    "# Optional: Load and display a preview\n",
    "# ---------------------\n",
    "df_recommendations = pd.read_csv('user_recommendations.csv')\n",
    "print(\"\\nSample recommendations:\")\n",
    "print(df_recommendations.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
