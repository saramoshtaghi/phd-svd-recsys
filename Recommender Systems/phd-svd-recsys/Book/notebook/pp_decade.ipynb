{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books.csv shape: (10000, 23)\n",
      "ratings.csv shape: (5976479, 3)\n",
      "to_read.csv shape: (912705, 2)\n",
      "book_tags.csv shape: (999912, 3)\n",
      "tags.csv shape: (34252, 2)\n",
      "\n",
      "Books sample:\n",
      "   book_id  goodreads_book_id  best_book_id  work_id  books_count       isbn  \\\n",
      "0        1            2767052       2767052  2792775          272  439023483   \n",
      "1        2                  3             3  4640799          491  439554934   \n",
      "2        3              41865         41865  3212258          226  316015849   \n",
      "3        4               2657          2657  3275794          487   61120081   \n",
      "4        5               4671          4671   245494         1356  743273567   \n",
      "\n",
      "         isbn13                      authors  original_publication_year  \\\n",
      "0  9.780439e+12              Suzanne Collins                     2008.0   \n",
      "1  9.780440e+12  J.K. Rowling, Mary GrandPr√©                     1997.0   \n",
      "2  9.780316e+12              Stephenie Meyer                     2005.0   \n",
      "3  9.780061e+12                   Harper Lee                     1960.0   \n",
      "4  9.780743e+12          F. Scott Fitzgerald                     1925.0   \n",
      "\n",
      "                             original_title  ... ratings_count  \\\n",
      "0                          The Hunger Games  ...       4780653   \n",
      "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
      "2                                  Twilight  ...       3866839   \n",
      "3                     To Kill a Mockingbird  ...       3198671   \n",
      "4                          The Great Gatsby  ...       2683664   \n",
      "\n",
      "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
      "0            4942365                   155254      66715     127936   \n",
      "1            4800065                    75867      75504     101676   \n",
      "2            3916824                    95009     456191     436802   \n",
      "3            3340896                    72586      60427     117415   \n",
      "4            2773745                    51992      86236     197621   \n",
      "\n",
      "   ratings_3  ratings_4  ratings_5  \\\n",
      "0     560092    1481305    2706317   \n",
      "1     455024    1156318    3011543   \n",
      "2     793319     875073    1355439   \n",
      "3     446835    1001952    1714267   \n",
      "4     606158     936012     947718   \n",
      "\n",
      "                                           image_url  \\\n",
      "0  https://images.gr-assets.com/books/1447303603m...   \n",
      "1  https://images.gr-assets.com/books/1474154022m...   \n",
      "2  https://images.gr-assets.com/books/1361039443m...   \n",
      "3  https://images.gr-assets.com/books/1361975680m...   \n",
      "4  https://images.gr-assets.com/books/1490528560m...   \n",
      "\n",
      "                                     small_image_url  \n",
      "0  https://images.gr-assets.com/books/1447303603s...  \n",
      "1  https://images.gr-assets.com/books/1474154022s...  \n",
      "2  https://images.gr-assets.com/books/1361039443s...  \n",
      "3  https://images.gr-assets.com/books/1361975680s...  \n",
      "4  https://images.gr-assets.com/books/1490528560s...  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Ratings sample:\n",
      "   user_id  book_id  rating\n",
      "0        1      258       5\n",
      "1        2     4081       4\n",
      "2        2      260       5\n",
      "3        2     9296       5\n",
      "4        2     2318       3\n",
      "\n",
      "To-Read sample:\n",
      "   user_id  book_id\n",
      "0        9        8\n",
      "1       15      398\n",
      "2       15      275\n",
      "3       37     7173\n",
      "4       34      380\n",
      "\n",
      "Book Tags sample:\n",
      "   goodreads_book_id  tag_id   count\n",
      "0                  1   30574  167697\n",
      "1                  1   11305   37174\n",
      "2                  1   11557   34173\n",
      "3                  1    8717   12986\n",
      "4                  1   33114   12716\n",
      "\n",
      "Tags sample:\n",
      "   tag_id tag_name\n",
      "0       0        -\n",
      "1       1     --1-\n",
      "2       2    --10-\n",
      "3       3    --12-\n",
      "4       4   --122-\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define your local data path\n",
    "data_path = '../data/goodbooks-10k'  # adjust path if needed\n",
    "\n",
    "# Load all available CSV files\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "ratings = pd.read_csv(os.path.join(data_path, 'ratings.csv'))\n",
    "to_read = pd.read_csv(os.path.join(data_path, 'to_read.csv'))\n",
    "book_tags = pd.read_csv(os.path.join(data_path, 'book_tags.csv'))\n",
    "tags = pd.read_csv(os.path.join(data_path, 'tags.csv'))\n",
    "\n",
    "# Quick verification:\n",
    "print(f\"books.csv shape: {books.shape}\")\n",
    "print(f\"ratings.csv shape: {ratings.shape}\")\n",
    "print(f\"to_read.csv shape: {to_read.shape}\")\n",
    "print(f\"book_tags.csv shape: {book_tags.shape}\")\n",
    "print(f\"tags.csv shape: {tags.shape}\")\n",
    "\n",
    "# Preview few rows from each file:\n",
    "print(\"\\nBooks sample:\")\n",
    "print(books.head())\n",
    "\n",
    "print(\"\\nRatings sample:\")\n",
    "print(ratings.head())\n",
    "\n",
    "print(\"\\nTo-Read sample:\")\n",
    "print(to_read.head())\n",
    "\n",
    "print(\"\\nBook Tags sample:\")\n",
    "print(book_tags.head())\n",
    "\n",
    "print(\"\\nTags sample:\")\n",
    "print(tags.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Load books.csv\n",
    "# data_path = '../data/goodbooks-10k'\n",
    "# books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "\n",
    "# # Total number of books\n",
    "# total_books = len(books)\n",
    "\n",
    "# # Total number of unique languages (excluding NaN)\n",
    "# unique_languages = books['language_code'].nunique()\n",
    "\n",
    "# # Number of books with missing language_code\n",
    "# missing_languages = books['language_code'].isnull().sum()\n",
    "\n",
    "# # Count number of books per language\n",
    "# books_per_language = books['language_code'].value_counts()\n",
    "\n",
    "# # Full list of languages\n",
    "# languages_list = books['language_code'].dropna().unique()\n",
    "\n",
    "# # Print summary\n",
    "# print(f\"Total number of books: {total_books}\")\n",
    "# print(f\"Total unique languages: {unique_languages}\")\n",
    "# print(f\"Number of books missing language info: {missing_languages}\\n\")\n",
    "\n",
    "# print(\"Number of books per language:\")\n",
    "# print(books_per_language)\n",
    "\n",
    "# print(\"\\nList of languages:\")\n",
    "# print(languages_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total books after cleaning: 9979\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load books.csv\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "\n",
    "# Drop books where publication year is missing\n",
    "books = books.dropna(subset=['original_publication_year'])\n",
    "\n",
    "# Convert year to integer for consistency\n",
    "books['original_publication_year'] = books['original_publication_year'].astype(int)\n",
    "\n",
    "# Verify\n",
    "print(f\"Total books after cleaning: {len(books)}\")\n",
    "\n",
    "# Save the cleaned dataframe (replacing the original file)\n",
    "books.to_csv(os.path.join(data_path, 'books.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random sample of books:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "goodreads_book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "best_book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "books_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "isbn",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "isbn13",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "original_publication_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "original_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "language_code",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "average_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ratings_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_ratings_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_text_reviews_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "small_image_url",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "68c1995e-1af8-49bb-896a-91383554dd6a",
       "rows": [
        [
         "2534",
         "2537",
         "6406018",
         "6406018",
         "6594903",
         "15",
         "759530017",
         "9780759530010.0",
         "Atsushi Ohkubo",
         "2004",
         "„ÇΩ„Ç¶„É´„Ç§„Éº„Çø„Éº 1",
         "Soul Eater, Vol. 01 (Soul Eater, #1)",
         "en-US",
         "4.3",
         "34289",
         "34473",
         "354",
         "532",
         "1299",
         "4899",
         "8255",
         "19488",
         "https://images.gr-assets.com/books/1443900841m/6406018.jpg",
         "https://images.gr-assets.com/books/1443900841s/6406018.jpg"
        ],
        [
         "1672",
         "1675",
         "5187",
         "5187",
         "3234420",
         "18",
         "385265700",
         "9780385265710.0",
         "Jane Hamilton",
         "1988",
         "The Book of Ruth",
         "The Book of Ruth",
         "en-US",
         "3.82",
         "56842",
         "57244",
         "1139",
         "1246",
         "3447",
         "15031",
         "22252",
         "15268",
         "https://s.gr-assets.com/assets/nophoto/book/111x148-bcc042a9c91a29c1d680899eff700a03.png",
         "https://s.gr-assets.com/assets/nophoto/book/50x75-a91bf249278a81aabab721ef782c4a74.png"
        ],
        [
         "4740",
         "4748",
         "206309",
         "206309",
         "1138219",
         "47",
         "786866020",
         "9780786866020.0",
         "Stephen C. Lundin, Harry Paul, John Christensen, Kenneth H. Blanchard",
         "1996",
         "Fish! A Remarkable Way to Boost Morale and Improve Results",
         "Fish: A Proven Way to Boost Morale and Improve Results",
         "eng",
         "3.92",
         "19405",
         "20340",
         "770",
         "466",
         "1291",
         "4735",
         "6684",
         "7164",
         "https://images.gr-assets.com/books/1393219562m/206309.jpg",
         "https://images.gr-assets.com/books/1393219562s/206309.jpg"
        ],
        [
         "1077",
         "1080",
         "12294652",
         "12294652",
         "17271423",
         "33",
         "803736991",
         "9780803736990.0",
         "Huntley Fitzpatrick",
         "2012",
         "My Life Next Door ",
         "My Life Next Door",
         "eng",
         "4.02",
         "102012",
         "108389",
         "8327",
         "2477",
         "5584",
         "21074",
         "37209",
         "42045",
         "https://images.gr-assets.com/books/1394240144m/12294652.jpg",
         "https://images.gr-assets.com/books/1394240144s/12294652.jpg"
        ],
        [
         "8932",
         "8950",
         "72148",
         "72148",
         "865487",
         "47",
         "747589372",
         "9780747589370.0",
         "William  Boyd",
         "2006",
         "Restless",
         "Restless",
         "eng",
         "3.84",
         "9308",
         "11228",
         "1051",
         "128",
         "532",
         "2862",
         "5202",
         "2504",
         "https://images.gr-assets.com/books/1330951946m/72148.jpg",
         "https://images.gr-assets.com/books/1330951946s/72148.jpg"
        ],
        [
         "8790",
         "8808",
         "8575295",
         "30123413",
         "13444179",
         "27",
         null,
         null,
         "Amanda Hocking",
         "2010",
         "Wisdom",
         "Wisdom (My Blood Approves, #4)",
         "eng",
         "4.04",
         "12933",
         "15399",
         "597",
         "235",
         "758",
         "3150",
         "5321",
         "5935",
         "https://images.gr-assets.com/books/1282281680m/8575295.jpg",
         "https://images.gr-assets.com/books/1282281680s/8575295.jpg"
        ],
        [
         "6235",
         "6247",
         "13545345",
         "13545345",
         "17381882",
         "51",
         "085707685X",
         "9780857076850.0",
         "Rachel Ren√©e Russell",
         "2012",
         "Tales From a Not-So-Graceful Ice Princess",
         "Tales from a Not-So-Graceful Ice Princess (Dork Diaries, #4)",
         null,
         "4.38",
         "13618",
         "15518",
         "678",
         "297",
         "511",
         "1812",
         "3349",
         "9549",
         "https://images.gr-assets.com/books/1370064558m/13545345.jpg",
         "https://images.gr-assets.com/books/1370064558s/13545345.jpg"
        ],
        [
         "3604",
         "3608",
         "30271",
         "30271",
         "2963636",
         "34",
         "515139750",
         "9780515139750.0",
         "Laurell K. Hamilton",
         "2004",
         "Incubus Dreams (Anita Blake, Vampire Hunter, #12)",
         "Incubus Dreams (Anita Blake, Vampire Hunter, #12)",
         "eng",
         "3.78",
         "39200",
         "41654",
         "891",
         "1901",
         "4171",
         "9739",
         "11320",
         "14523",
         "https://images.gr-assets.com/books/1362831466m/30271.jpg",
         "https://images.gr-assets.com/books/1362831466s/30271.jpg"
        ],
        [
         "9481",
         "9500",
         "13056511",
         "13056511",
         "14240586",
         "46",
         "312656289",
         "9780312656290.0",
         "Alexandra Adornetto",
         "2012",
         "Heaven",
         "Heaven (Halo, #3)",
         "eng",
         "3.91",
         "14520",
         "15135",
         "1122",
         "778",
         "1164",
         "3011",
         "3894",
         "6288",
         "https://images.gr-assets.com/books/1332367132m/13056511.jpg",
         "https://images.gr-assets.com/books/1332367132s/13056511.jpg"
        ],
        [
         "1913",
         "1916",
         "232109",
         "232109",
         "2029611",
         "63",
         "380709244",
         "9780380709240.0",
         "Beverly Cleary, Louis Darling, Tracy Dockray",
         "1965",
         "The Mouse and the Motorcycle",
         "The Mouse and the Motorcycle (Ralph S. Mouse, #1)",
         "en-US",
         "3.9",
         "61754",
         "63725",
         "1419",
         "952",
         "3280",
         "17270",
         "21684",
         "20539",
         "https://images.gr-assets.com/books/1348990967m/232109.jpg",
         "https://images.gr-assets.com/books/1348990967s/232109.jpg"
        ]
       ],
       "shape": {
        "columns": 23,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>2537</td>\n",
       "      <td>6406018</td>\n",
       "      <td>6406018</td>\n",
       "      <td>6594903</td>\n",
       "      <td>15</td>\n",
       "      <td>759530017</td>\n",
       "      <td>9.780760e+12</td>\n",
       "      <td>Atsushi Ohkubo</td>\n",
       "      <td>2004</td>\n",
       "      <td>„ÇΩ„Ç¶„É´„Ç§„Éº„Çø„Éº 1</td>\n",
       "      <td>...</td>\n",
       "      <td>34289</td>\n",
       "      <td>34473</td>\n",
       "      <td>354</td>\n",
       "      <td>532</td>\n",
       "      <td>1299</td>\n",
       "      <td>4899</td>\n",
       "      <td>8255</td>\n",
       "      <td>19488</td>\n",
       "      <td>https://images.gr-assets.com/books/1443900841m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1443900841s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>1675</td>\n",
       "      <td>5187</td>\n",
       "      <td>5187</td>\n",
       "      <td>3234420</td>\n",
       "      <td>18</td>\n",
       "      <td>385265700</td>\n",
       "      <td>9.780385e+12</td>\n",
       "      <td>Jane Hamilton</td>\n",
       "      <td>1988</td>\n",
       "      <td>The Book of Ruth</td>\n",
       "      <td>...</td>\n",
       "      <td>56842</td>\n",
       "      <td>57244</td>\n",
       "      <td>1139</td>\n",
       "      <td>1246</td>\n",
       "      <td>3447</td>\n",
       "      <td>15031</td>\n",
       "      <td>22252</td>\n",
       "      <td>15268</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4740</th>\n",
       "      <td>4748</td>\n",
       "      <td>206309</td>\n",
       "      <td>206309</td>\n",
       "      <td>1138219</td>\n",
       "      <td>47</td>\n",
       "      <td>786866020</td>\n",
       "      <td>9.780787e+12</td>\n",
       "      <td>Stephen C. Lundin, Harry Paul, John Christense...</td>\n",
       "      <td>1996</td>\n",
       "      <td>Fish! A Remarkable Way to Boost Morale and Imp...</td>\n",
       "      <td>...</td>\n",
       "      <td>19405</td>\n",
       "      <td>20340</td>\n",
       "      <td>770</td>\n",
       "      <td>466</td>\n",
       "      <td>1291</td>\n",
       "      <td>4735</td>\n",
       "      <td>6684</td>\n",
       "      <td>7164</td>\n",
       "      <td>https://images.gr-assets.com/books/1393219562m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1393219562s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>1080</td>\n",
       "      <td>12294652</td>\n",
       "      <td>12294652</td>\n",
       "      <td>17271423</td>\n",
       "      <td>33</td>\n",
       "      <td>803736991</td>\n",
       "      <td>9.780804e+12</td>\n",
       "      <td>Huntley Fitzpatrick</td>\n",
       "      <td>2012</td>\n",
       "      <td>My Life Next Door</td>\n",
       "      <td>...</td>\n",
       "      <td>102012</td>\n",
       "      <td>108389</td>\n",
       "      <td>8327</td>\n",
       "      <td>2477</td>\n",
       "      <td>5584</td>\n",
       "      <td>21074</td>\n",
       "      <td>37209</td>\n",
       "      <td>42045</td>\n",
       "      <td>https://images.gr-assets.com/books/1394240144m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1394240144s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8932</th>\n",
       "      <td>8950</td>\n",
       "      <td>72148</td>\n",
       "      <td>72148</td>\n",
       "      <td>865487</td>\n",
       "      <td>47</td>\n",
       "      <td>747589372</td>\n",
       "      <td>9.780748e+12</td>\n",
       "      <td>William  Boyd</td>\n",
       "      <td>2006</td>\n",
       "      <td>Restless</td>\n",
       "      <td>...</td>\n",
       "      <td>9308</td>\n",
       "      <td>11228</td>\n",
       "      <td>1051</td>\n",
       "      <td>128</td>\n",
       "      <td>532</td>\n",
       "      <td>2862</td>\n",
       "      <td>5202</td>\n",
       "      <td>2504</td>\n",
       "      <td>https://images.gr-assets.com/books/1330951946m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1330951946s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8790</th>\n",
       "      <td>8808</td>\n",
       "      <td>8575295</td>\n",
       "      <td>30123413</td>\n",
       "      <td>13444179</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amanda Hocking</td>\n",
       "      <td>2010</td>\n",
       "      <td>Wisdom</td>\n",
       "      <td>...</td>\n",
       "      <td>12933</td>\n",
       "      <td>15399</td>\n",
       "      <td>597</td>\n",
       "      <td>235</td>\n",
       "      <td>758</td>\n",
       "      <td>3150</td>\n",
       "      <td>5321</td>\n",
       "      <td>5935</td>\n",
       "      <td>https://images.gr-assets.com/books/1282281680m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1282281680s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6235</th>\n",
       "      <td>6247</td>\n",
       "      <td>13545345</td>\n",
       "      <td>13545345</td>\n",
       "      <td>17381882</td>\n",
       "      <td>51</td>\n",
       "      <td>085707685X</td>\n",
       "      <td>9.780857e+12</td>\n",
       "      <td>Rachel Ren√©e Russell</td>\n",
       "      <td>2012</td>\n",
       "      <td>Tales From a Not-So-Graceful Ice Princess</td>\n",
       "      <td>...</td>\n",
       "      <td>13618</td>\n",
       "      <td>15518</td>\n",
       "      <td>678</td>\n",
       "      <td>297</td>\n",
       "      <td>511</td>\n",
       "      <td>1812</td>\n",
       "      <td>3349</td>\n",
       "      <td>9549</td>\n",
       "      <td>https://images.gr-assets.com/books/1370064558m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1370064558s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3604</th>\n",
       "      <td>3608</td>\n",
       "      <td>30271</td>\n",
       "      <td>30271</td>\n",
       "      <td>2963636</td>\n",
       "      <td>34</td>\n",
       "      <td>515139750</td>\n",
       "      <td>9.780515e+12</td>\n",
       "      <td>Laurell K. Hamilton</td>\n",
       "      <td>2004</td>\n",
       "      <td>Incubus Dreams (Anita Blake, Vampire Hunter, #12)</td>\n",
       "      <td>...</td>\n",
       "      <td>39200</td>\n",
       "      <td>41654</td>\n",
       "      <td>891</td>\n",
       "      <td>1901</td>\n",
       "      <td>4171</td>\n",
       "      <td>9739</td>\n",
       "      <td>11320</td>\n",
       "      <td>14523</td>\n",
       "      <td>https://images.gr-assets.com/books/1362831466m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1362831466s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9481</th>\n",
       "      <td>9500</td>\n",
       "      <td>13056511</td>\n",
       "      <td>13056511</td>\n",
       "      <td>14240586</td>\n",
       "      <td>46</td>\n",
       "      <td>312656289</td>\n",
       "      <td>9.780313e+12</td>\n",
       "      <td>Alexandra Adornetto</td>\n",
       "      <td>2012</td>\n",
       "      <td>Heaven</td>\n",
       "      <td>...</td>\n",
       "      <td>14520</td>\n",
       "      <td>15135</td>\n",
       "      <td>1122</td>\n",
       "      <td>778</td>\n",
       "      <td>1164</td>\n",
       "      <td>3011</td>\n",
       "      <td>3894</td>\n",
       "      <td>6288</td>\n",
       "      <td>https://images.gr-assets.com/books/1332367132m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1332367132s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>1916</td>\n",
       "      <td>232109</td>\n",
       "      <td>232109</td>\n",
       "      <td>2029611</td>\n",
       "      <td>63</td>\n",
       "      <td>380709244</td>\n",
       "      <td>9.780381e+12</td>\n",
       "      <td>Beverly Cleary, Louis Darling, Tracy Dockray</td>\n",
       "      <td>1965</td>\n",
       "      <td>The Mouse and the Motorcycle</td>\n",
       "      <td>...</td>\n",
       "      <td>61754</td>\n",
       "      <td>63725</td>\n",
       "      <td>1419</td>\n",
       "      <td>952</td>\n",
       "      <td>3280</td>\n",
       "      <td>17270</td>\n",
       "      <td>21684</td>\n",
       "      <td>20539</td>\n",
       "      <td>https://images.gr-assets.com/books/1348990967m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1348990967s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id  goodreads_book_id  best_book_id   work_id  books_count  \\\n",
       "2534     2537            6406018       6406018   6594903           15   \n",
       "1672     1675               5187          5187   3234420           18   \n",
       "4740     4748             206309        206309   1138219           47   \n",
       "1077     1080           12294652      12294652  17271423           33   \n",
       "8932     8950              72148         72148    865487           47   \n",
       "8790     8808            8575295      30123413  13444179           27   \n",
       "6235     6247           13545345      13545345  17381882           51   \n",
       "3604     3608              30271         30271   2963636           34   \n",
       "9481     9500           13056511      13056511  14240586           46   \n",
       "1913     1916             232109        232109   2029611           63   \n",
       "\n",
       "            isbn        isbn13  \\\n",
       "2534   759530017  9.780760e+12   \n",
       "1672   385265700  9.780385e+12   \n",
       "4740   786866020  9.780787e+12   \n",
       "1077   803736991  9.780804e+12   \n",
       "8932   747589372  9.780748e+12   \n",
       "8790         NaN           NaN   \n",
       "6235  085707685X  9.780857e+12   \n",
       "3604   515139750  9.780515e+12   \n",
       "9481   312656289  9.780313e+12   \n",
       "1913   380709244  9.780381e+12   \n",
       "\n",
       "                                                authors  \\\n",
       "2534                                     Atsushi Ohkubo   \n",
       "1672                                      Jane Hamilton   \n",
       "4740  Stephen C. Lundin, Harry Paul, John Christense...   \n",
       "1077                                Huntley Fitzpatrick   \n",
       "8932                                      William  Boyd   \n",
       "8790                                     Amanda Hocking   \n",
       "6235                               Rachel Ren√©e Russell   \n",
       "3604                                Laurell K. Hamilton   \n",
       "9481                                Alexandra Adornetto   \n",
       "1913       Beverly Cleary, Louis Darling, Tracy Dockray   \n",
       "\n",
       "      original_publication_year  \\\n",
       "2534                       2004   \n",
       "1672                       1988   \n",
       "4740                       1996   \n",
       "1077                       2012   \n",
       "8932                       2006   \n",
       "8790                       2010   \n",
       "6235                       2012   \n",
       "3604                       2004   \n",
       "9481                       2012   \n",
       "1913                       1965   \n",
       "\n",
       "                                         original_title  ... ratings_count  \\\n",
       "2534                                          „ÇΩ„Ç¶„É´„Ç§„Éº„Çø„Éº 1  ...         34289   \n",
       "1672                                   The Book of Ruth  ...         56842   \n",
       "4740  Fish! A Remarkable Way to Boost Morale and Imp...  ...         19405   \n",
       "1077                                 My Life Next Door   ...        102012   \n",
       "8932                                           Restless  ...          9308   \n",
       "8790                                             Wisdom  ...         12933   \n",
       "6235          Tales From a Not-So-Graceful Ice Princess  ...         13618   \n",
       "3604  Incubus Dreams (Anita Blake, Vampire Hunter, #12)  ...         39200   \n",
       "9481                                             Heaven  ...         14520   \n",
       "1913                       The Mouse and the Motorcycle  ...         61754   \n",
       "\n",
       "     work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "2534              34473                      354        532       1299   \n",
       "1672              57244                     1139       1246       3447   \n",
       "4740              20340                      770        466       1291   \n",
       "1077             108389                     8327       2477       5584   \n",
       "8932              11228                     1051        128        532   \n",
       "8790              15399                      597        235        758   \n",
       "6235              15518                      678        297        511   \n",
       "3604              41654                      891       1901       4171   \n",
       "9481              15135                     1122        778       1164   \n",
       "1913              63725                     1419        952       3280   \n",
       "\n",
       "      ratings_3  ratings_4  ratings_5  \\\n",
       "2534       4899       8255      19488   \n",
       "1672      15031      22252      15268   \n",
       "4740       4735       6684       7164   \n",
       "1077      21074      37209      42045   \n",
       "8932       2862       5202       2504   \n",
       "8790       3150       5321       5935   \n",
       "6235       1812       3349       9549   \n",
       "3604       9739      11320      14523   \n",
       "9481       3011       3894       6288   \n",
       "1913      17270      21684      20539   \n",
       "\n",
       "                                              image_url  \\\n",
       "2534  https://images.gr-assets.com/books/1443900841m...   \n",
       "1672  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
       "4740  https://images.gr-assets.com/books/1393219562m...   \n",
       "1077  https://images.gr-assets.com/books/1394240144m...   \n",
       "8932  https://images.gr-assets.com/books/1330951946m...   \n",
       "8790  https://images.gr-assets.com/books/1282281680m...   \n",
       "6235  https://images.gr-assets.com/books/1370064558m...   \n",
       "3604  https://images.gr-assets.com/books/1362831466m...   \n",
       "9481  https://images.gr-assets.com/books/1332367132m...   \n",
       "1913  https://images.gr-assets.com/books/1348990967m...   \n",
       "\n",
       "                                        small_image_url  \n",
       "2534  https://images.gr-assets.com/books/1443900841s...  \n",
       "1672  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
       "4740  https://images.gr-assets.com/books/1393219562s...  \n",
       "1077  https://images.gr-assets.com/books/1394240144s...  \n",
       "8932  https://images.gr-assets.com/books/1330951946s...  \n",
       "8790  https://images.gr-assets.com/books/1282281680s...  \n",
       "6235  https://images.gr-assets.com/books/1370064558s...  \n",
       "3604  https://images.gr-assets.com/books/1362831466s...  \n",
       "9481  https://images.gr-assets.com/books/1332367132s...  \n",
       "1913  https://images.gr-assets.com/books/1348990967s...  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the cleaned books.csv\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "\n",
    "# Print first few rows\n",
    "# print(books.head())\n",
    "\n",
    "# Or print a random sample of 10 books\n",
    "print(\"\\nRandom sample of books:\")\n",
    "books.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique book IDs in ratings.csv: 10000\n",
      "Unique book IDs in books.csv: 9979\n"
     ]
    }
   ],
   "source": [
    "# Total unique book IDs in ratings file\n",
    "total_unique_books_in_ratings = ratings['book_id'].nunique()\n",
    "\n",
    "# Total unique book IDs in books file (metadata)\n",
    "total_unique_books_in_books = books['book_id'].nunique()\n",
    "\n",
    "print(f\"Unique book IDs in ratings.csv: {total_unique_books_in_ratings}\")\n",
    "print(f\"Unique book IDs in books.csv: {total_unique_books_in_books}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of titles with multiple publication years: 33\n",
      "\n",
      "Title: 'Salem's Lot\n",
      "Years: [1975, 2005]\n",
      "\n",
      "Title: Anatomy for the Artist\n",
      "Years: [1953, 2001]\n",
      "\n",
      "Title: Arcadia\n",
      "Years: [1993, 2012]\n",
      "\n",
      "Title: Are You My Mother?\n",
      "Years: [1960, 2012]\n",
      "\n",
      "Title: Bambi\n",
      "Years: [1923, 1941]\n",
      "\n",
      "Title: Between the Lines (Between the Lines, #1)\n",
      "Years: [2011, 2012]\n",
      "\n",
      "Title: Invisible\n",
      "Years: [2009, 2014]\n",
      "\n",
      "Title: Leviathan\n",
      "Years: [1651, 1992]\n",
      "\n",
      "Title: Monster\n",
      "Years: [1999, 2005]\n",
      "\n",
      "Title: One Flew Over the Cuckoo's Nest\n",
      "Years: [1962, 1970]\n"
     ]
    }
   ],
   "source": [
    "# Group by title and collect all unique years per title\n",
    "title_years = books.groupby('title')['original_publication_year'].unique()\n",
    "\n",
    "# Filter only titles that have more than 1 unique year\n",
    "multiple_year_titles = title_years[title_years.apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Print count\n",
    "print(f\"Number of titles with multiple publication years: {len(multiple_year_titles)}\")\n",
    "\n",
    "# Print sample (first 10 titles)\n",
    "for title, years in multiple_year_titles.head(10).items():\n",
    "    print(f\"\\nTitle: {title}\")\n",
    "    print(f\"Years: {sorted(years)}\")\n",
    "\n",
    "# Total unique book IDs in ratings file\n",
    "total_unique_books_in_ratings = ratings['book_id'].nunique()\n",
    "\n",
    "# Total unique book IDs in books file (metadata)\n",
    "total_unique_books_in_books = books['book_id'].nunique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total ratings from summary: 5970537\n",
      "Total number of ratings from ratings.csv: 5976479\n",
      "Unique books per decade and total ratings:\n",
      "    decade  unique_books  total_ratings\n",
      "0    -1750             1            730\n",
      "1     -770             1            756\n",
      "2     -750             2           3944\n",
      "3     -720             1           6301\n",
      "4     -560             1           1548\n",
      "..     ...           ...            ...\n",
      "78    1970           400         244194\n",
      "79    1980           704         443368\n",
      "80    1990          1360         847948\n",
      "81    2000          3121        1808808\n",
      "82    2010          3067        1268418\n",
      "\n",
      "[83 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "ratings = pd.read_csv(f\"{data_path}/ratings.csv\")\n",
    "\n",
    "# Create decade column and merge\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "merged_df = ratings.merge(books[['book_id', 'decade']], on='book_id')\n",
    "\n",
    "# Groupby decade: count unique books & total ratings\n",
    "summary = merged_df.groupby('decade').agg(\n",
    "    unique_books=('book_id', 'nunique'),\n",
    "    total_ratings=('rating', 'count')\n",
    ").reset_index().sort_values('decade')\n",
    "\n",
    "total_ratings_sum = summary['total_ratings'].sum()\n",
    "print(f\"Sum of total ratings from summary: {total_ratings_sum}\")\n",
    "\n",
    "total_ratings_actual = len(ratings)\n",
    "print(f\"Total number of ratings from ratings.csv: {total_ratings_actual}\")\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"Unique books per decade and total ratings:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of book_ids in ratings.csv not found in books.csv: 21\n"
     ]
    }
   ],
   "source": [
    "# How many unique book_ids exist in ratings but not in books\n",
    "missing_books = set(ratings['book_id']) - set(books['book_id'])\n",
    "print(f\"Number of book_ids in ratings.csv not found in books.csv: {len(missing_books)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing ratings count (from missing book_ids): 5942\n",
      "Gap between ratings.csv and merged summary: 5942\n",
      "Does it match? ‚úÖ YES\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "ratings = pd.read_csv(os.path.join(data_path, 'ratings.csv'))\n",
    "\n",
    "# Find book_ids that exist in ratings but not in books\n",
    "book_ids_in_books = set(books['book_id'])\n",
    "book_ids_in_ratings = set(ratings['book_id'])\n",
    "missing_book_ids = book_ids_in_ratings - book_ids_in_books\n",
    "\n",
    "# Get ratings corresponding to missing book_ids\n",
    "missing_ratings = ratings[ratings['book_id'].isin(missing_book_ids)]\n",
    "\n",
    "# Count how many ratings are missing\n",
    "missing_ratings_count = len(missing_ratings)\n",
    "\n",
    "print(f\"Missing ratings count (from missing book_ids): {missing_ratings_count}\")\n",
    "\n",
    "# Compare with gap\n",
    "total_ratings = len(ratings)\n",
    "ratings_after_merge = 5970537  # This is your merged sum above\n",
    "gap = total_ratings - ratings_after_merge\n",
    "\n",
    "print(f\"Gap between ratings.csv and merged summary: {gap}\")\n",
    "print(f\"Does it match? {'‚úÖ YES' if gap == missing_ratings_count else '‚ùå NO'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique books: 9979\n"
     ]
    }
   ],
   "source": [
    "total_books = books['book_id'].nunique()\n",
    "print(f\"Total unique books: {total_books}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ratings: 5976479\n"
     ]
    }
   ],
   "source": [
    "total_ratings = len(ratings)\n",
    "print(f\"Total ratings: {total_ratings}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books per decade:\n",
      "    decade  unique_books\n",
      "0    -1750             1\n",
      "1     -770             1\n",
      "2     -750             2\n",
      "3     -720             1\n",
      "4     -560             1\n",
      "..     ...           ...\n",
      "78    1970           400\n",
      "79    1980           704\n",
      "80    1990          1360\n",
      "81    2000          3121\n",
      "82    2010          3067\n",
      "\n",
      "[83 rows x 2 columns]\n",
      "\n",
      "Summation of books across decades: 9979\n"
     ]
    }
   ],
   "source": [
    "# Add decade\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "\n",
    "# Count books per decade (this is from full books.csv not merged one!)\n",
    "books_per_decade = books.groupby('decade')['book_id'].nunique().reset_index(name='unique_books')\n",
    "\n",
    "# Summation of books across decades\n",
    "total_books_from_decades = books_per_decade['unique_books'].sum()\n",
    "\n",
    "print(\"Books per decade:\")\n",
    "print(books_per_decade)\n",
    "print(f\"\\nSummation of books across decades: {total_books_from_decades}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted ratings: 5942\n",
      "Unique book_ids deleted: 21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "ratings = pd.read_csv(f\"{data_path}/ratings.csv\")\n",
    "\n",
    "# Filter ratings where book_id exists in books\n",
    "valid_book_ids = set(books['book_id'])\n",
    "ratings_clean = ratings[ratings['book_id'].isin(valid_book_ids)]\n",
    "\n",
    "# Calculate how many ratings were deleted\n",
    "deleted_ratings = len(ratings) - len(ratings_clean)\n",
    "\n",
    "# Calculate how many unique book_ids were deleted\n",
    "all_rated_book_ids = set(ratings['book_id'])\n",
    "deleted_book_ids = all_rated_book_ids - valid_book_ids\n",
    "deleted_book_ids_count = len(deleted_book_ids)\n",
    "\n",
    "# Report & overwrite\n",
    "print(f\"Deleted ratings: {deleted_ratings}\")\n",
    "print(f\"Unique book_ids deleted: {deleted_book_ids_count}\")\n",
    "\n",
    "ratings_clean.to_csv(f\"{data_path}/ratings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique book_ids in books.csv: 9979\n",
      "Total unique book_ids in ratings.csv: 9979\n",
      "Total ratings: 5970537\n",
      "\n",
      "Books per decade:\n",
      "    decade  unique_books_per_decade\n",
      "0    -1750                        1\n",
      "1     -770                        1\n",
      "2     -750                        2\n",
      "3     -720                        1\n",
      "4     -560                        1\n",
      "..     ...                      ...\n",
      "78    1970                      400\n",
      "79    1980                      704\n",
      "80    1990                     1360\n",
      "81    2000                     3121\n",
      "82    2010                     3067\n",
      "\n",
      "[83 rows x 2 columns]\n",
      "\n",
      "Summation of books across decades: 9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9979"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load cleaned data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "ratings = pd.read_csv(f\"{data_path}/ratings.csv\")\n",
    "\n",
    "# 1Ô∏è‚É£ Count unique book_id in books.csv\n",
    "unique_books_in_books = books['book_id'].nunique()\n",
    "print(f\"Total unique book_ids in books.csv: {unique_books_in_books}\")\n",
    "\n",
    "# 2Ô∏è‚É£ Count unique book_id in ratings.csv\n",
    "unique_books_in_ratings = ratings['book_id'].nunique()\n",
    "print(f\"Total unique book_ids in ratings.csv: {unique_books_in_ratings}\")\n",
    "\n",
    "# 3Ô∏è‚É£ Count total ratings\n",
    "total_ratings = len(ratings)\n",
    "print(f\"Total ratings: {total_ratings}\")\n",
    "\n",
    "# 4Ô∏è‚É£ Compute decade column\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "\n",
    "# 5Ô∏è‚É£ Count number of unique books per decade\n",
    "books_per_decade = books.groupby('decade')['book_id'].nunique().reset_index(name='unique_books_per_decade')\n",
    "books_per_decade = books_per_decade.sort_values('decade')\n",
    "\n",
    "print(\"\\nBooks per decade:\")\n",
    "print(books_per_decade)\n",
    "\n",
    "# 6Ô∏è‚É£ Verify summation of books across decades\n",
    "total_books_from_decades = books_per_decade['unique_books_per_decade'].sum()\n",
    "print(f\"\\nSummation of books across decades: {total_books_from_decades}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_per_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   decade_grouped  unique_books_per_decade\n",
      "0            1920                       89\n",
      "1            1930                      121\n",
      "2            1940                      155\n",
      "3            1950                      210\n",
      "4            1960                      272\n",
      "5            1970                      400\n",
      "6            1980                      704\n",
      "7            1990                     1360\n",
      "8            2000                     3121\n",
      "9            2010                     3067\n",
      "10  Ancient Books                      480\n",
      "\n",
      "Total books after grouping: 9979\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load cleaned data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "\n",
    "# Create decade column\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "\n",
    "# Replace decades before 1920 with 'Ancient Books'\n",
    "books['decade_grouped'] = books['decade'].apply(lambda x: 'Ancient Books' if x < 1920 else int(x))\n",
    "\n",
    "# Count unique book_ids per grouped decade\n",
    "books_per_decade = books.groupby('decade_grouped')['book_id'].nunique().reset_index(name='unique_books_per_decade')\n",
    "\n",
    "# Sort (Ancient Books first, then by decade)\n",
    "books_per_decade['decade_grouped'] = books_per_decade['decade_grouped'].astype(str)\n",
    "books_per_decade = books_per_decade.sort_values(by='decade_grouped')\n",
    "\n",
    "# Print result\n",
    "print(books_per_decade)\n",
    "\n",
    "# Verify sum still equals total books\n",
    "total_books_from_decades = books_per_decade['unique_books_per_decade'].sum()\n",
    "print(f\"\\nTotal books after grouping: {total_books_from_decades}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  book_id  rating decade\n",
      "0        1      258       5   2000\n",
      "1        2     4081       4   2000\n",
      "2        2      260       5   1930\n",
      "3        2     9296       5   1970\n",
      "4        2     2318       3   1990\n",
      "\n",
      "Final dataset shape: (5970537, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load cleaned data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "ratings = pd.read_csv(f\"{data_path}/ratings.csv\")\n",
    "\n",
    "# Step 1: Create decade column and group into Ancient Books\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "books['decade_grouped'] = books['decade'].apply(lambda x: 'Ancient Books' if x < 1920 else int(x))\n",
    "\n",
    "# Step 2: Merge ratings with books (attach decade info)\n",
    "merged_df = ratings.merge(books[['book_id', 'decade_grouped']], on='book_id', how='left')\n",
    "\n",
    "# Step 3: Rename columns for clarity\n",
    "final_df = merged_df.rename(columns={'decade_grouped': 'decade'})\n",
    "\n",
    "# Step 4: Reorder columns\n",
    "final_df = final_df[['user_id', 'book_id', 'rating', 'decade']]\n",
    "\n",
    "# Step 5: Save final dataset\n",
    "final_df.to_csv(f\"{data_path}/final_svd_dataset.csv\", index=False)\n",
    "\n",
    "# Print sample and shape for verification\n",
    "print(final_df.head())\n",
    "print(f\"\\nFinal dataset shape: {final_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    53424.000000\n",
      "mean       111.757581\n",
      "std         26.075621\n",
      "min         19.000000\n",
      "25%         96.000000\n",
      "50%        111.000000\n",
      "75%        128.000000\n",
      "max        200.000000\n",
      "Name: rating, dtype: float64\n",
      "\n",
      "Users with fewest ratings:\n",
      "user_id\n",
      "34590    19\n",
      "32128    20\n",
      "43675    20\n",
      "51725    21\n",
      "42736    21\n",
      "40753    21\n",
      "37640    22\n",
      "34099    22\n",
      "50918    22\n",
      "25856    22\n",
      "Name: rating, dtype: int64\n",
      "\n",
      "Total number of unique users: 53424\n",
      "Total number of unique books: 9979\n",
      "Minimum number of ratings per user: 19\n",
      "Maximum number of ratings per user: 200\n",
      "Average number of ratings per user: 111.76\n",
      "\n",
      "Average rating score per user:\n",
      "count    53424.000000\n",
      "mean         3.928487\n",
      "std          0.449549\n",
      "min          1.000000\n",
      "25%          3.633663\n",
      "50%          3.920455\n",
      "75%          4.223236\n",
      "max          5.000000\n",
      "Name: rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load your cleaned final dataset\n",
    "data_path = '../data/goodbooks-10k'\n",
    "final_df = pd.read_csv(f\"{data_path}/final_svd_dataset.csv\")\n",
    "\n",
    "# Count number of ratings per user\n",
    "reviews_per_user = final_df.groupby('user_id')['rating'].count()\n",
    "\n",
    "# Average rating per user\n",
    "average_rating_per_user = final_df.groupby('user_id')['rating'].mean()\n",
    "\n",
    "# Print basic stats\n",
    "print(reviews_per_user.describe())\n",
    "\n",
    "# Print users with fewest ratings\n",
    "print(\"\\nUsers with fewest ratings:\")\n",
    "print(reviews_per_user.sort_values().head(10))\n",
    "\n",
    "# Count unique users and books\n",
    "unique_users = final_df['user_id'].nunique()\n",
    "unique_books = final_df['book_id'].nunique()\n",
    "\n",
    "print(f\"\\nTotal number of unique users: {unique_users}\")\n",
    "print(f\"Total number of unique books: {unique_books}\")\n",
    "\n",
    "# Get min/max ratings per user\n",
    "min_ratings = reviews_per_user.min()\n",
    "max_ratings = reviews_per_user.max()\n",
    "avg_ratings_per_user = reviews_per_user.mean()\n",
    "\n",
    "print(f\"Minimum number of ratings per user: {min_ratings}\")\n",
    "print(f\"Maximum number of ratings per user: {max_ratings}\")\n",
    "print(f\"Average number of ratings per user: {avg_ratings_per_user:.2f}\")\n",
    "\n",
    "# Print basic stats for average *rating scores* per user\n",
    "print(\"\\nAverage rating score per user:\")\n",
    "print(average_rating_per_user.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "decade_grouped",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unique_books_per_decade",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "183dc727-dc34-49f5-b57a-da3e18b3d636",
       "rows": [
        [
         "0",
         "1920",
         "89"
        ],
        [
         "1",
         "1930",
         "121"
        ],
        [
         "2",
         "1940",
         "155"
        ],
        [
         "3",
         "1950",
         "210"
        ],
        [
         "4",
         "1960",
         "272"
        ],
        [
         "5",
         "1970",
         "400"
        ],
        [
         "6",
         "1980",
         "704"
        ],
        [
         "7",
         "1990",
         "1360"
        ],
        [
         "8",
         "2000",
         "3121"
        ],
        [
         "9",
         "2010",
         "3067"
        ],
        [
         "10",
         "Ancient Books",
         "480"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decade_grouped</th>\n",
       "      <th>unique_books_per_decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1920</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1930</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1940</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1970</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1980</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1990</td>\n",
       "      <td>1360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000</td>\n",
       "      <td>3121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010</td>\n",
       "      <td>3067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ancient Books</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   decade_grouped  unique_books_per_decade\n",
       "0            1920                       89\n",
       "1            1930                      121\n",
       "2            1940                      155\n",
       "3            1950                      210\n",
       "4            1960                      272\n",
       "5            1970                      400\n",
       "6            1980                      704\n",
       "7            1990                     1360\n",
       "8            2000                     3121\n",
       "9            2010                     3067\n",
       "10  Ancient Books                      480"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_per_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "decade",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "70394ea7-44cd-4fa6-8afc-3122652bd2de",
       "rows": [
        [
         "0",
         "1",
         "258",
         "5",
         "2000"
        ],
        [
         "1",
         "2",
         "4081",
         "4",
         "2000"
        ],
        [
         "2",
         "2",
         "260",
         "5",
         "1930"
        ],
        [
         "3",
         "2",
         "9296",
         "5",
         "1970"
        ],
        [
         "4",
         "2",
         "2318",
         "3",
         "1990"
        ],
        [
         "5",
         "2",
         "26",
         "4",
         "2000"
        ],
        [
         "6",
         "2",
         "315",
         "3",
         "1990"
        ],
        [
         "7",
         "2",
         "33",
         "4",
         "1990"
        ],
        [
         "8",
         "2",
         "301",
         "5",
         "Ancient Books"
        ],
        [
         "9",
         "2",
         "2686",
         "5",
         "2000"
        ],
        [
         "10",
         "2",
         "3753",
         "5",
         "2000"
        ],
        [
         "11",
         "2",
         "8519",
         "5",
         "1970"
        ],
        [
         "12",
         "4",
         "70",
         "4",
         "1980"
        ],
        [
         "13",
         "4",
         "264",
         "3",
         "1920"
        ],
        [
         "14",
         "4",
         "388",
         "4",
         "1980"
        ],
        [
         "15",
         "4",
         "18",
         "5",
         "1990"
        ],
        [
         "16",
         "4",
         "27",
         "5",
         "2000"
        ],
        [
         "17",
         "4",
         "21",
         "5",
         "2000"
        ],
        [
         "18",
         "4",
         "2",
         "5",
         "1990"
        ],
        [
         "19",
         "4",
         "23",
         "5",
         "1990"
        ],
        [
         "20",
         "4",
         "24",
         "5",
         "2000"
        ],
        [
         "21",
         "4",
         "964",
         "4",
         "1970"
        ],
        [
         "22",
         "4",
         "103",
         "5",
         "Ancient Books"
        ],
        [
         "23",
         "4",
         "255",
         "2",
         "1950"
        ],
        [
         "24",
         "4",
         "35",
         "5",
         "1980"
        ],
        [
         "25",
         "4",
         "287",
         "3",
         "1940"
        ],
        [
         "26",
         "4",
         "337",
         "4",
         "1990"
        ],
        [
         "27",
         "4",
         "26",
         "3",
         "2000"
        ],
        [
         "28",
         "4",
         "84",
         "4",
         "1990"
        ],
        [
         "29",
         "4",
         "58",
         "4",
         "Ancient Books"
        ],
        [
         "30",
         "4",
         "1117",
         "3",
         "1990"
        ],
        [
         "31",
         "4",
         "660",
         "3",
         "1980"
        ],
        [
         "32",
         "4",
         "111",
         "2",
         "2000"
        ],
        [
         "33",
         "4",
         "5",
         "4",
         "1920"
        ],
        [
         "34",
         "4",
         "413",
         "4",
         "Ancient Books"
        ],
        [
         "35",
         "4",
         "8",
         "4",
         "1950"
        ],
        [
         "36",
         "4",
         "2172",
         "4",
         "1960"
        ],
        [
         "37",
         "4",
         "65",
         "4",
         "1960"
        ],
        [
         "38",
         "4",
         "297",
         "4",
         "1960"
        ],
        [
         "39",
         "4",
         "45",
         "4",
         "2000"
        ],
        [
         "40",
         "4",
         "113",
         "4",
         "1960"
        ],
        [
         "41",
         "4",
         "325",
         "5",
         "1980"
        ],
        [
         "42",
         "4",
         "476",
         "3",
         "1970"
        ],
        [
         "43",
         "6",
         "6351",
         "4",
         "2000"
        ],
        [
         "44",
         "8",
         "2732",
         "5",
         "Ancient Books"
        ],
        [
         "45",
         "8",
         "1432",
         "3",
         "Ancient Books"
        ],
        [
         "46",
         "8",
         "479",
         "4",
         "Ancient Books"
        ],
        [
         "47",
         "8",
         "3020",
         "5",
         "Ancient Books"
        ],
        [
         "48",
         "8",
         "6195",
         "4",
         "1920"
        ],
        [
         "49",
         "8",
         "614",
         "4",
         "1920"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5970537
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970532</th>\n",
       "      <td>49925</td>\n",
       "      <td>510</td>\n",
       "      <td>5</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970533</th>\n",
       "      <td>49925</td>\n",
       "      <td>528</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970534</th>\n",
       "      <td>49925</td>\n",
       "      <td>722</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970535</th>\n",
       "      <td>49925</td>\n",
       "      <td>949</td>\n",
       "      <td>5</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970536</th>\n",
       "      <td>49925</td>\n",
       "      <td>1023</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5970537 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  book_id  rating decade\n",
       "0              1      258       5   2000\n",
       "1              2     4081       4   2000\n",
       "2              2      260       5   1930\n",
       "3              2     9296       5   1970\n",
       "4              2     2318       3   1990\n",
       "...          ...      ...     ...    ...\n",
       "5970532    49925      510       5   1990\n",
       "5970533    49925      528       4   1990\n",
       "5970534    49925      722       4   1990\n",
       "5970535    49925      949       5   1990\n",
       "5970536    49925     1023       4   1990\n",
       "\n",
       "[5970537 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
