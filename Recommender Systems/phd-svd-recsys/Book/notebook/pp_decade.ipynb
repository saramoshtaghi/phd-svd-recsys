{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books.csv shape: (10000, 23)\n",
      "ratings.csv shape: (5976479, 3)\n",
      "to_read.csv shape: (912705, 2)\n",
      "book_tags.csv shape: (999912, 3)\n",
      "tags.csv shape: (34252, 2)\n",
      "\n",
      "Books sample:\n",
      "   book_id  goodreads_book_id  best_book_id  work_id  books_count       isbn  \\\n",
      "0        1            2767052       2767052  2792775          272  439023483   \n",
      "1        2                  3             3  4640799          491  439554934   \n",
      "2        3              41865         41865  3212258          226  316015849   \n",
      "3        4               2657          2657  3275794          487   61120081   \n",
      "4        5               4671          4671   245494         1356  743273567   \n",
      "\n",
      "         isbn13                      authors  original_publication_year  \\\n",
      "0  9.780439e+12              Suzanne Collins                     2008.0   \n",
      "1  9.780440e+12  J.K. Rowling, Mary GrandPré                     1997.0   \n",
      "2  9.780316e+12              Stephenie Meyer                     2005.0   \n",
      "3  9.780061e+12                   Harper Lee                     1960.0   \n",
      "4  9.780743e+12          F. Scott Fitzgerald                     1925.0   \n",
      "\n",
      "                             original_title  ... ratings_count  \\\n",
      "0                          The Hunger Games  ...       4780653   \n",
      "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
      "2                                  Twilight  ...       3866839   \n",
      "3                     To Kill a Mockingbird  ...       3198671   \n",
      "4                          The Great Gatsby  ...       2683664   \n",
      "\n",
      "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
      "0            4942365                   155254      66715     127936   \n",
      "1            4800065                    75867      75504     101676   \n",
      "2            3916824                    95009     456191     436802   \n",
      "3            3340896                    72586      60427     117415   \n",
      "4            2773745                    51992      86236     197621   \n",
      "\n",
      "   ratings_3  ratings_4  ratings_5  \\\n",
      "0     560092    1481305    2706317   \n",
      "1     455024    1156318    3011543   \n",
      "2     793319     875073    1355439   \n",
      "3     446835    1001952    1714267   \n",
      "4     606158     936012     947718   \n",
      "\n",
      "                                           image_url  \\\n",
      "0  https://images.gr-assets.com/books/1447303603m...   \n",
      "1  https://images.gr-assets.com/books/1474154022m...   \n",
      "2  https://images.gr-assets.com/books/1361039443m...   \n",
      "3  https://images.gr-assets.com/books/1361975680m...   \n",
      "4  https://images.gr-assets.com/books/1490528560m...   \n",
      "\n",
      "                                     small_image_url  \n",
      "0  https://images.gr-assets.com/books/1447303603s...  \n",
      "1  https://images.gr-assets.com/books/1474154022s...  \n",
      "2  https://images.gr-assets.com/books/1361039443s...  \n",
      "3  https://images.gr-assets.com/books/1361975680s...  \n",
      "4  https://images.gr-assets.com/books/1490528560s...  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Ratings sample:\n",
      "   user_id  book_id  rating\n",
      "0        1      258       5\n",
      "1        2     4081       4\n",
      "2        2      260       5\n",
      "3        2     9296       5\n",
      "4        2     2318       3\n",
      "\n",
      "To-Read sample:\n",
      "   user_id  book_id\n",
      "0        9        8\n",
      "1       15      398\n",
      "2       15      275\n",
      "3       37     7173\n",
      "4       34      380\n",
      "\n",
      "Book Tags sample:\n",
      "   goodreads_book_id  tag_id   count\n",
      "0                  1   30574  167697\n",
      "1                  1   11305   37174\n",
      "2                  1   11557   34173\n",
      "3                  1    8717   12986\n",
      "4                  1   33114   12716\n",
      "\n",
      "Tags sample:\n",
      "   tag_id tag_name\n",
      "0       0        -\n",
      "1       1     --1-\n",
      "2       2    --10-\n",
      "3       3    --12-\n",
      "4       4   --122-\n"
     ]
    }
   ],
   "source": [
    "# Define your local data path\n",
    "data_path = '../data/goodbooks-10k'  # adjust path if needed\n",
    "\n",
    "# Load all available CSV files\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "ratings = pd.read_csv(os.path.join(data_path, 'ratings.csv'))\n",
    "to_read = pd.read_csv(os.path.join(data_path, 'to_read.csv'))\n",
    "book_tags = pd.read_csv(os.path.join(data_path, 'book_tags.csv'))\n",
    "tags = pd.read_csv(os.path.join(data_path, 'tags.csv'))\n",
    "\n",
    "# Quick verification:\n",
    "print(f\"books.csv shape: {books.shape}\")\n",
    "print(f\"ratings.csv shape: {ratings.shape}\")\n",
    "print(f\"to_read.csv shape: {to_read.shape}\")\n",
    "print(f\"book_tags.csv shape: {book_tags.shape}\")\n",
    "print(f\"tags.csv shape: {tags.shape}\")\n",
    "\n",
    "# Preview few rows from each file:\n",
    "print(\"\\nBooks sample:\")\n",
    "print(books.head())\n",
    "\n",
    "print(\"\\nRatings sample:\")\n",
    "print(ratings.head())\n",
    "\n",
    "print(\"\\nTo-Read sample:\")\n",
    "print(to_read.head())\n",
    "\n",
    "print(\"\\nBook Tags sample:\")\n",
    "print(book_tags.head())\n",
    "\n",
    "print(\"\\nTags sample:\")\n",
    "print(tags.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Load books.csv\n",
    "# data_path = '../data/goodbooks-10k'\n",
    "# books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "\n",
    "# # Total number of books\n",
    "# total_books = len(books)\n",
    "\n",
    "# # Total number of unique languages (excluding NaN)\n",
    "# unique_languages = books['language_code'].nunique()\n",
    "\n",
    "# # Number of books with missing language_code\n",
    "# missing_languages = books['language_code'].isnull().sum()\n",
    "\n",
    "# # Count number of books per language\n",
    "# books_per_language = books['language_code'].value_counts()\n",
    "\n",
    "# # Full list of languages\n",
    "# languages_list = books['language_code'].dropna().unique()\n",
    "\n",
    "# # Print summary\n",
    "# print(f\"Total number of books: {total_books}\")\n",
    "# print(f\"Total unique languages: {unique_languages}\")\n",
    "# print(f\"Number of books missing language info: {missing_languages}\\n\")\n",
    "\n",
    "# print(\"Number of books per language:\")\n",
    "# print(books_per_language)\n",
    "\n",
    "# print(\"\\nList of languages:\")\n",
    "# print(languages_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total books after cleaning: 9979\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load books.csv\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "\n",
    "# Drop books where publication year is missing\n",
    "books = books.dropna(subset=['original_publication_year'])\n",
    "\n",
    "# Convert year to integer for consistency\n",
    "books['original_publication_year'] = books['original_publication_year'].astype(int)\n",
    "\n",
    "# Verify\n",
    "print(f\"Total books after cleaning: {len(books)}\")\n",
    "\n",
    "# Save the cleaned dataframe (replacing the original file)\n",
    "books.to_csv(os.path.join(data_path, 'books.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random sample of books:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "goodreads_book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "best_book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "books_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "isbn",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "isbn13",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "original_publication_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "original_title",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "language_code",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "average_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ratings_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_ratings_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_text_reviews_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "small_image_url",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "cc070dfa-598f-443c-a65d-d19bab4ec871",
       "rows": [
        [
         "5592",
         "5602",
         "22540125",
         "22540125",
         "26217310",
         "55",
         "1476792496",
         "9781476792490.0",
         "Anna Todd",
         "2013",
         "After We Collided",
         "After We Collided (After, #2)",
         "eng",
         "3.73",
         "16338",
         "24827",
         "1795",
         "1619",
         "2520",
         "5459",
         "6492",
         "8737",
         "https://images.gr-assets.com/books/1416788471m/22540125.jpg",
         "https://images.gr-assets.com/books/1416788471s/22540125.jpg"
        ],
        [
         "1996",
         "1999",
         "249",
         "249",
         "543143",
         "205",
         "802131786",
         "9780802131780.0",
         "Henry Miller",
         "1934",
         "Tropic of Cancer",
         "Tropic of Cancer",
         "eng",
         "3.71",
         "45518",
         "49701",
         "2526",
         "2313",
         "4591",
         "12278",
         "16494",
         "14025",
         "https://images.gr-assets.com/books/1408753140m/249.jpg",
         "https://images.gr-assets.com/books/1408753140s/249.jpg"
        ],
        [
         "317",
         "319",
         "8755776",
         "8755776",
         "13629058",
         "101",
         "1442416866",
         "9781442416860.0",
         "Cassandra Clare",
         "2012",
         "City of Lost Souls",
         "City of Lost Souls (The Mortal Instruments, #5)",
         "eng",
         "4.3",
         "300553",
         "327869",
         "16639",
         "3341",
         "10329",
         "43333",
         "97947",
         "172919",
         "https://images.gr-assets.com/books/1460477703m/8755776.jpg",
         "https://images.gr-assets.com/books/1460477703s/8755776.jpg"
        ],
        [
         "7353",
         "7368",
         "17158513",
         "17158513",
         "23581952",
         "20",
         null,
         null,
         "C.S. Pacat",
         "2015",
         "Prince's Gambit",
         "Captive Prince: Volume Two (Captive Prince, #2)",
         "eng",
         "4.51",
         "15899",
         "22196",
         "2897",
         "135",
         "352",
         "1640",
         "6059",
         "14010",
         "https://images.gr-assets.com/books/1356027904m/17158513.jpg",
         "https://images.gr-assets.com/books/1356027904s/17158513.jpg"
        ],
        [
         "194",
         "195",
         "2728527",
         "2728527",
         "2754161",
         "116",
         "385340990",
         "9780385340990.0",
         "Mary Ann Shaffer, Annie Barrows",
         "2008",
         "The Guernsey Literary and Potato Peel Pie Society",
         "The Guernsey Literary and Potato Peel Pie Society",
         "eng",
         "4.12",
         "393626",
         "423672",
         "39853",
         "7190",
         "17250",
         "68942",
         "155107",
         "175183",
         "https://images.gr-assets.com/books/1351979318m/2728527.jpg",
         "https://images.gr-assets.com/books/1351979318s/2728527.jpg"
        ],
        [
         "7341",
         "7356",
         "16218778",
         "16218778",
         "23326865",
         "15",
         "544025830",
         "9780544025840.0",
         "Kimberly Rae Miller",
         "2013",
         null,
         "Coming Clean",
         "en-US",
         "3.88",
         "10002",
         "14943",
         "1406",
         "260",
         "670",
         "3640",
         "6333",
         "4040",
         "https://images.gr-assets.com/books/1381962759m/16218778.jpg",
         "https://images.gr-assets.com/books/1381962759s/16218778.jpg"
        ],
        [
         "9235",
         "9254",
         "68530",
         "68530",
         "6418603",
         "66",
         "60935782",
         "9780060935790.0",
         "Bernard Cornwell",
         "2002",
         "Vagabond",
         "Vagabond (The Grail Quest, #2)",
         "en-US",
         "4.09",
         "9680",
         "11666",
         "343",
         "36",
         "272",
         "2246",
         "5169",
         "3943",
         "https://images.gr-assets.com/books/1407707722m/68530.jpg",
         "https://images.gr-assets.com/books/1407707722s/68530.jpg"
        ],
        [
         "7598",
         "7614",
         "77736",
         "77736",
         "1913024",
         "34",
         "671875965",
         "9780671875960.0",
         "David Weber",
         "1994",
         "The Short Victorious War",
         "The Short Victorious War (Honor Harrington, #3)",
         null,
         "4.16",
         "14563",
         "16376",
         "336",
         "76",
         "305",
         "2836",
         "6814",
         "6345",
         "https://images.gr-assets.com/books/1321561719m/77736.jpg",
         "https://images.gr-assets.com/books/1321561719s/77736.jpg"
        ],
        [
         "1661",
         "1664",
         "18521",
         "18521",
         "1315615",
         "340",
         "141183535",
         "9780141183530.0",
         "Virginia Woolf",
         "1929",
         "A Room of One's Own",
         "A Room of One's Own",
         "eng",
         "4.1",
         "59868",
         "71968",
         "3573",
         "1097",
         "3031",
         "12558",
         "26448",
         "28834",
         "https://images.gr-assets.com/books/1327883012m/18521.jpg",
         "https://images.gr-assets.com/books/1327883012s/18521.jpg"
        ],
        [
         "5668",
         "5679",
         "10889279",
         "10889279",
         "15805031",
         "11",
         "140123206X",
         "9781401232060.0",
         "Scott Snyder, Jock, Francesco Francavilla, Jared K. Fletcher, Sal Cipriano, David   Baron",
         "2011",
         "Batman: The Black Mirror",
         "Batman: The Black Mirror",
         "eng",
         "4.29",
         "15625",
         "16366",
         "686",
         "183",
         "466",
         "2226",
         "5070",
         "8421",
         "https://images.gr-assets.com/books/1503127212m/10889279.jpg",
         "https://images.gr-assets.com/books/1503127212s/10889279.jpg"
        ]
       ],
       "shape": {
        "columns": 23,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5592</th>\n",
       "      <td>5602</td>\n",
       "      <td>22540125</td>\n",
       "      <td>22540125</td>\n",
       "      <td>26217310</td>\n",
       "      <td>55</td>\n",
       "      <td>1476792496</td>\n",
       "      <td>9.781477e+12</td>\n",
       "      <td>Anna Todd</td>\n",
       "      <td>2013</td>\n",
       "      <td>After We Collided</td>\n",
       "      <td>...</td>\n",
       "      <td>16338</td>\n",
       "      <td>24827</td>\n",
       "      <td>1795</td>\n",
       "      <td>1619</td>\n",
       "      <td>2520</td>\n",
       "      <td>5459</td>\n",
       "      <td>6492</td>\n",
       "      <td>8737</td>\n",
       "      <td>https://images.gr-assets.com/books/1416788471m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1416788471s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1999</td>\n",
       "      <td>249</td>\n",
       "      <td>249</td>\n",
       "      <td>543143</td>\n",
       "      <td>205</td>\n",
       "      <td>802131786</td>\n",
       "      <td>9.780802e+12</td>\n",
       "      <td>Henry Miller</td>\n",
       "      <td>1934</td>\n",
       "      <td>Tropic of Cancer</td>\n",
       "      <td>...</td>\n",
       "      <td>45518</td>\n",
       "      <td>49701</td>\n",
       "      <td>2526</td>\n",
       "      <td>2313</td>\n",
       "      <td>4591</td>\n",
       "      <td>12278</td>\n",
       "      <td>16494</td>\n",
       "      <td>14025</td>\n",
       "      <td>https://images.gr-assets.com/books/1408753140m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1408753140s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>319</td>\n",
       "      <td>8755776</td>\n",
       "      <td>8755776</td>\n",
       "      <td>13629058</td>\n",
       "      <td>101</td>\n",
       "      <td>1442416866</td>\n",
       "      <td>9.781442e+12</td>\n",
       "      <td>Cassandra Clare</td>\n",
       "      <td>2012</td>\n",
       "      <td>City of Lost Souls</td>\n",
       "      <td>...</td>\n",
       "      <td>300553</td>\n",
       "      <td>327869</td>\n",
       "      <td>16639</td>\n",
       "      <td>3341</td>\n",
       "      <td>10329</td>\n",
       "      <td>43333</td>\n",
       "      <td>97947</td>\n",
       "      <td>172919</td>\n",
       "      <td>https://images.gr-assets.com/books/1460477703m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1460477703s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353</th>\n",
       "      <td>7368</td>\n",
       "      <td>17158513</td>\n",
       "      <td>17158513</td>\n",
       "      <td>23581952</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C.S. Pacat</td>\n",
       "      <td>2015</td>\n",
       "      <td>Prince's Gambit</td>\n",
       "      <td>...</td>\n",
       "      <td>15899</td>\n",
       "      <td>22196</td>\n",
       "      <td>2897</td>\n",
       "      <td>135</td>\n",
       "      <td>352</td>\n",
       "      <td>1640</td>\n",
       "      <td>6059</td>\n",
       "      <td>14010</td>\n",
       "      <td>https://images.gr-assets.com/books/1356027904m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1356027904s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>195</td>\n",
       "      <td>2728527</td>\n",
       "      <td>2728527</td>\n",
       "      <td>2754161</td>\n",
       "      <td>116</td>\n",
       "      <td>385340990</td>\n",
       "      <td>9.780385e+12</td>\n",
       "      <td>Mary Ann Shaffer, Annie Barrows</td>\n",
       "      <td>2008</td>\n",
       "      <td>The Guernsey Literary and Potato Peel Pie Society</td>\n",
       "      <td>...</td>\n",
       "      <td>393626</td>\n",
       "      <td>423672</td>\n",
       "      <td>39853</td>\n",
       "      <td>7190</td>\n",
       "      <td>17250</td>\n",
       "      <td>68942</td>\n",
       "      <td>155107</td>\n",
       "      <td>175183</td>\n",
       "      <td>https://images.gr-assets.com/books/1351979318m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1351979318s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7341</th>\n",
       "      <td>7356</td>\n",
       "      <td>16218778</td>\n",
       "      <td>16218778</td>\n",
       "      <td>23326865</td>\n",
       "      <td>15</td>\n",
       "      <td>544025830</td>\n",
       "      <td>9.780544e+12</td>\n",
       "      <td>Kimberly Rae Miller</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10002</td>\n",
       "      <td>14943</td>\n",
       "      <td>1406</td>\n",
       "      <td>260</td>\n",
       "      <td>670</td>\n",
       "      <td>3640</td>\n",
       "      <td>6333</td>\n",
       "      <td>4040</td>\n",
       "      <td>https://images.gr-assets.com/books/1381962759m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1381962759s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9235</th>\n",
       "      <td>9254</td>\n",
       "      <td>68530</td>\n",
       "      <td>68530</td>\n",
       "      <td>6418603</td>\n",
       "      <td>66</td>\n",
       "      <td>60935782</td>\n",
       "      <td>9.780061e+12</td>\n",
       "      <td>Bernard Cornwell</td>\n",
       "      <td>2002</td>\n",
       "      <td>Vagabond</td>\n",
       "      <td>...</td>\n",
       "      <td>9680</td>\n",
       "      <td>11666</td>\n",
       "      <td>343</td>\n",
       "      <td>36</td>\n",
       "      <td>272</td>\n",
       "      <td>2246</td>\n",
       "      <td>5169</td>\n",
       "      <td>3943</td>\n",
       "      <td>https://images.gr-assets.com/books/1407707722m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1407707722s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>7614</td>\n",
       "      <td>77736</td>\n",
       "      <td>77736</td>\n",
       "      <td>1913024</td>\n",
       "      <td>34</td>\n",
       "      <td>671875965</td>\n",
       "      <td>9.780672e+12</td>\n",
       "      <td>David Weber</td>\n",
       "      <td>1994</td>\n",
       "      <td>The Short Victorious War</td>\n",
       "      <td>...</td>\n",
       "      <td>14563</td>\n",
       "      <td>16376</td>\n",
       "      <td>336</td>\n",
       "      <td>76</td>\n",
       "      <td>305</td>\n",
       "      <td>2836</td>\n",
       "      <td>6814</td>\n",
       "      <td>6345</td>\n",
       "      <td>https://images.gr-assets.com/books/1321561719m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1321561719s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>1664</td>\n",
       "      <td>18521</td>\n",
       "      <td>18521</td>\n",
       "      <td>1315615</td>\n",
       "      <td>340</td>\n",
       "      <td>141183535</td>\n",
       "      <td>9.780141e+12</td>\n",
       "      <td>Virginia Woolf</td>\n",
       "      <td>1929</td>\n",
       "      <td>A Room of One's Own</td>\n",
       "      <td>...</td>\n",
       "      <td>59868</td>\n",
       "      <td>71968</td>\n",
       "      <td>3573</td>\n",
       "      <td>1097</td>\n",
       "      <td>3031</td>\n",
       "      <td>12558</td>\n",
       "      <td>26448</td>\n",
       "      <td>28834</td>\n",
       "      <td>https://images.gr-assets.com/books/1327883012m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1327883012s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>5679</td>\n",
       "      <td>10889279</td>\n",
       "      <td>10889279</td>\n",
       "      <td>15805031</td>\n",
       "      <td>11</td>\n",
       "      <td>140123206X</td>\n",
       "      <td>9.781401e+12</td>\n",
       "      <td>Scott Snyder, Jock, Francesco Francavilla, Jar...</td>\n",
       "      <td>2011</td>\n",
       "      <td>Batman: The Black Mirror</td>\n",
       "      <td>...</td>\n",
       "      <td>15625</td>\n",
       "      <td>16366</td>\n",
       "      <td>686</td>\n",
       "      <td>183</td>\n",
       "      <td>466</td>\n",
       "      <td>2226</td>\n",
       "      <td>5070</td>\n",
       "      <td>8421</td>\n",
       "      <td>https://images.gr-assets.com/books/1503127212m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1503127212s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id  goodreads_book_id  best_book_id   work_id  books_count  \\\n",
       "5592     5602           22540125      22540125  26217310           55   \n",
       "1996     1999                249           249    543143          205   \n",
       "317       319            8755776       8755776  13629058          101   \n",
       "7353     7368           17158513      17158513  23581952           20   \n",
       "194       195            2728527       2728527   2754161          116   \n",
       "7341     7356           16218778      16218778  23326865           15   \n",
       "9235     9254              68530         68530   6418603           66   \n",
       "7598     7614              77736         77736   1913024           34   \n",
       "1661     1664              18521         18521   1315615          340   \n",
       "5668     5679           10889279      10889279  15805031           11   \n",
       "\n",
       "            isbn        isbn13  \\\n",
       "5592  1476792496  9.781477e+12   \n",
       "1996   802131786  9.780802e+12   \n",
       "317   1442416866  9.781442e+12   \n",
       "7353         NaN           NaN   \n",
       "194    385340990  9.780385e+12   \n",
       "7341   544025830  9.780544e+12   \n",
       "9235    60935782  9.780061e+12   \n",
       "7598   671875965  9.780672e+12   \n",
       "1661   141183535  9.780141e+12   \n",
       "5668  140123206X  9.781401e+12   \n",
       "\n",
       "                                                authors  \\\n",
       "5592                                          Anna Todd   \n",
       "1996                                       Henry Miller   \n",
       "317                                     Cassandra Clare   \n",
       "7353                                         C.S. Pacat   \n",
       "194                     Mary Ann Shaffer, Annie Barrows   \n",
       "7341                                Kimberly Rae Miller   \n",
       "9235                                   Bernard Cornwell   \n",
       "7598                                        David Weber   \n",
       "1661                                     Virginia Woolf   \n",
       "5668  Scott Snyder, Jock, Francesco Francavilla, Jar...   \n",
       "\n",
       "      original_publication_year  \\\n",
       "5592                       2013   \n",
       "1996                       1934   \n",
       "317                        2012   \n",
       "7353                       2015   \n",
       "194                        2008   \n",
       "7341                       2013   \n",
       "9235                       2002   \n",
       "7598                       1994   \n",
       "1661                       1929   \n",
       "5668                       2011   \n",
       "\n",
       "                                         original_title  ... ratings_count  \\\n",
       "5592                                  After We Collided  ...         16338   \n",
       "1996                                   Tropic of Cancer  ...         45518   \n",
       "317                                  City of Lost Souls  ...        300553   \n",
       "7353                                    Prince's Gambit  ...         15899   \n",
       "194   The Guernsey Literary and Potato Peel Pie Society  ...        393626   \n",
       "7341                                                NaN  ...         10002   \n",
       "9235                                           Vagabond  ...          9680   \n",
       "7598                           The Short Victorious War  ...         14563   \n",
       "1661                                A Room of One's Own  ...         59868   \n",
       "5668                           Batman: The Black Mirror  ...         15625   \n",
       "\n",
       "     work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "5592              24827                     1795       1619       2520   \n",
       "1996              49701                     2526       2313       4591   \n",
       "317              327869                    16639       3341      10329   \n",
       "7353              22196                     2897        135        352   \n",
       "194              423672                    39853       7190      17250   \n",
       "7341              14943                     1406        260        670   \n",
       "9235              11666                      343         36        272   \n",
       "7598              16376                      336         76        305   \n",
       "1661              71968                     3573       1097       3031   \n",
       "5668              16366                      686        183        466   \n",
       "\n",
       "      ratings_3  ratings_4  ratings_5  \\\n",
       "5592       5459       6492       8737   \n",
       "1996      12278      16494      14025   \n",
       "317       43333      97947     172919   \n",
       "7353       1640       6059      14010   \n",
       "194       68942     155107     175183   \n",
       "7341       3640       6333       4040   \n",
       "9235       2246       5169       3943   \n",
       "7598       2836       6814       6345   \n",
       "1661      12558      26448      28834   \n",
       "5668       2226       5070       8421   \n",
       "\n",
       "                                              image_url  \\\n",
       "5592  https://images.gr-assets.com/books/1416788471m...   \n",
       "1996  https://images.gr-assets.com/books/1408753140m...   \n",
       "317   https://images.gr-assets.com/books/1460477703m...   \n",
       "7353  https://images.gr-assets.com/books/1356027904m...   \n",
       "194   https://images.gr-assets.com/books/1351979318m...   \n",
       "7341  https://images.gr-assets.com/books/1381962759m...   \n",
       "9235  https://images.gr-assets.com/books/1407707722m...   \n",
       "7598  https://images.gr-assets.com/books/1321561719m...   \n",
       "1661  https://images.gr-assets.com/books/1327883012m...   \n",
       "5668  https://images.gr-assets.com/books/1503127212m...   \n",
       "\n",
       "                                        small_image_url  \n",
       "5592  https://images.gr-assets.com/books/1416788471s...  \n",
       "1996  https://images.gr-assets.com/books/1408753140s...  \n",
       "317   https://images.gr-assets.com/books/1460477703s...  \n",
       "7353  https://images.gr-assets.com/books/1356027904s...  \n",
       "194   https://images.gr-assets.com/books/1351979318s...  \n",
       "7341  https://images.gr-assets.com/books/1381962759s...  \n",
       "9235  https://images.gr-assets.com/books/1407707722s...  \n",
       "7598  https://images.gr-assets.com/books/1321561719s...  \n",
       "1661  https://images.gr-assets.com/books/1327883012s...  \n",
       "5668  https://images.gr-assets.com/books/1503127212s...  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the cleaned books.csv\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "\n",
    "# Print first few rows\n",
    "# print(books.head())\n",
    "\n",
    "# Or print a random sample of 10 books\n",
    "print(\"\\nRandom sample of books:\")\n",
    "books.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nausea' 'Being and Nothingness' 'No Exit and Three Other Plays'\n",
      " 'No Exit' 'The Wall' 'Existentialism Is a Humanism'\n",
      " 'The Wretched of the Earth']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the books.csv file\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "\n",
    "# Define common variations of J.K. Rowling's name\n",
    "name_variations = [ 'sartre', 'sarter']\n",
    "\n",
    "# Combine into a regex pattern for case-insensitive search\n",
    "pattern = '|'.join(name_variations)\n",
    "\n",
    "# Search for rows where the 'author' column contains any of the variations\n",
    "rowling_books = books[books['authors'].str.lower().str.contains(pattern, na=False)]\n",
    "\n",
    "# Display result\n",
    "print(rowling_books['title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique authors: 4653\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the books.csv file\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "\n",
    "# Count unique authors\n",
    "unique_authors = books['authors'].nunique()\n",
    "\n",
    "# Print the count\n",
    "print(f\"Number of unique authors: {unique_authors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6148       عقاید یک دلقک\n",
      "6759        رباعيات خيام\n",
      "7469              سینوهه\n",
      "7623       درخت زیبای من\n",
      "8319    ماهی سیاه کوچولو\n",
      "8864       سمفونی مردگان\n",
      "9837            هشت کتاب\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define Persian language variations\n",
    "persian_lang_variants = ['per', 'persian', 'fa']\n",
    "\n",
    "# Filter rows where language column matches any variant (case-insensitive)\n",
    "persian_books = books[books['language_code'].str.lower().isin(persian_lang_variants)]\n",
    "# Show only the book titles\n",
    "print(persian_books['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique book IDs in ratings.csv: 10000\n",
      "Unique book IDs in books.csv: 9979\n"
     ]
    }
   ],
   "source": [
    "# Total unique book IDs in ratings file\n",
    "total_unique_books_in_ratings = ratings['book_id'].nunique()\n",
    "\n",
    "# Total unique book IDs in books file (metadata)\n",
    "total_unique_books_in_books = books['book_id'].nunique()\n",
    "\n",
    "print(f\"Unique book IDs in ratings.csv: {total_unique_books_in_ratings}\")\n",
    "print(f\"Unique book IDs in books.csv: {total_unique_books_in_books}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of titles with multiple publication years: 33\n",
      "\n",
      "Title: 'Salem's Lot\n",
      "Years: [1975, 2005]\n",
      "\n",
      "Title: Anatomy for the Artist\n",
      "Years: [1953, 2001]\n",
      "\n",
      "Title: Arcadia\n",
      "Years: [1993, 2012]\n",
      "\n",
      "Title: Are You My Mother?\n",
      "Years: [1960, 2012]\n",
      "\n",
      "Title: Bambi\n",
      "Years: [1923, 1941]\n",
      "\n",
      "Title: Between the Lines (Between the Lines, #1)\n",
      "Years: [2011, 2012]\n",
      "\n",
      "Title: Invisible\n",
      "Years: [2009, 2014]\n",
      "\n",
      "Title: Leviathan\n",
      "Years: [1651, 1992]\n",
      "\n",
      "Title: Monster\n",
      "Years: [1999, 2005]\n",
      "\n",
      "Title: One Flew Over the Cuckoo's Nest\n",
      "Years: [1962, 1970]\n"
     ]
    }
   ],
   "source": [
    "# Group by title and collect all unique years per title\n",
    "title_years = books.groupby('title')['original_publication_year'].unique()\n",
    "\n",
    "# Filter only titles that have more than 1 unique year\n",
    "multiple_year_titles = title_years[title_years.apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Print count\n",
    "print(f\"Number of titles with multiple publication years: {len(multiple_year_titles)}\")\n",
    "\n",
    "# Print sample (first 10 titles)\n",
    "for title, years in multiple_year_titles.head(10).items():\n",
    "    print(f\"\\nTitle: {title}\")\n",
    "    print(f\"Years: {sorted(years)}\")\n",
    "\n",
    "# Total unique book IDs in ratings file\n",
    "total_unique_books_in_ratings = ratings['book_id'].nunique()\n",
    "\n",
    "# Total unique book IDs in books file (metadata)\n",
    "total_unique_books_in_books = books['book_id'].nunique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total ratings from summary: 5970537\n",
      "Total number of ratings from ratings.csv: 5976479\n",
      "Unique books per decade and total ratings:\n",
      "    decade  unique_books  total_ratings\n",
      "0    -1750             1            730\n",
      "1     -770             1            756\n",
      "2     -750             2           3944\n",
      "3     -720             1           6301\n",
      "4     -560             1           1548\n",
      "..     ...           ...            ...\n",
      "78    1970           400         244194\n",
      "79    1980           704         443368\n",
      "80    1990          1360         847948\n",
      "81    2000          3121        1808808\n",
      "82    2010          3067        1268418\n",
      "\n",
      "[83 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "ratings = pd.read_csv(f\"{data_path}/ratings.csv\")\n",
    "\n",
    "# Create decade column and merge\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "merged_df = ratings.merge(books[['book_id', 'decade']], on='book_id')\n",
    "\n",
    "# Groupby decade: count unique books & total ratings\n",
    "summary = merged_df.groupby('decade').agg(\n",
    "    unique_books=('book_id', 'nunique'),\n",
    "    total_ratings=('rating', 'count')\n",
    ").reset_index().sort_values('decade')\n",
    "\n",
    "total_ratings_sum = summary['total_ratings'].sum()\n",
    "print(f\"Sum of total ratings from summary: {total_ratings_sum}\")\n",
    "\n",
    "total_ratings_actual = len(ratings)\n",
    "print(f\"Total number of ratings from ratings.csv: {total_ratings_actual}\")\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"Unique books per decade and total ratings:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of book_ids in ratings.csv not found in books.csv: 21\n"
     ]
    }
   ],
   "source": [
    "# How many unique book_ids exist in ratings but not in books\n",
    "missing_books = set(ratings['book_id']) - set(books['book_id'])\n",
    "print(f\"Number of book_ids in ratings.csv not found in books.csv: {len(missing_books)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing ratings count (from missing book_ids): 5942\n",
      "Gap between ratings.csv and merged summary: 5942\n",
      "Does it match? ✅ YES\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "ratings = pd.read_csv(os.path.join(data_path, 'ratings.csv'))\n",
    "\n",
    "# Find book_ids that exist in ratings but not in books\n",
    "book_ids_in_books = set(books['book_id'])\n",
    "book_ids_in_ratings = set(ratings['book_id'])\n",
    "missing_book_ids = book_ids_in_ratings - book_ids_in_books\n",
    "\n",
    "# Get ratings corresponding to missing book_ids\n",
    "missing_ratings = ratings[ratings['book_id'].isin(missing_book_ids)]\n",
    "\n",
    "# Count how many ratings are missing\n",
    "missing_ratings_count = len(missing_ratings)\n",
    "\n",
    "print(f\"Missing ratings count (from missing book_ids): {missing_ratings_count}\")\n",
    "\n",
    "# Compare with gap\n",
    "total_ratings = len(ratings)\n",
    "ratings_after_merge = 5970537  # This is your merged sum above\n",
    "gap = total_ratings - ratings_after_merge\n",
    "\n",
    "print(f\"Gap between ratings.csv and merged summary: {gap}\")\n",
    "print(f\"Does it match? {'✅ YES' if gap == missing_ratings_count else '❌ NO'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique books: 9979\n"
     ]
    }
   ],
   "source": [
    "total_books = books['book_id'].nunique()\n",
    "print(f\"Total unique books: {total_books}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ratings: 5976479\n"
     ]
    }
   ],
   "source": [
    "total_ratings = len(ratings)\n",
    "print(f\"Total ratings: {total_ratings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books per decade:\n",
      "    decade  unique_books\n",
      "0    -1750             1\n",
      "1     -770             1\n",
      "2     -750             2\n",
      "3     -720             1\n",
      "4     -560             1\n",
      "..     ...           ...\n",
      "78    1970           400\n",
      "79    1980           704\n",
      "80    1990          1360\n",
      "81    2000          3121\n",
      "82    2010          3067\n",
      "\n",
      "[83 rows x 2 columns]\n",
      "\n",
      "Summation of books across decades: 9979\n"
     ]
    }
   ],
   "source": [
    "# Add decade\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "\n",
    "# Count books per decade (this is from full books.csv not merged one!)\n",
    "books_per_decade = books.groupby('decade')['book_id'].nunique().reset_index(name='unique_books')\n",
    "\n",
    "# Summation of books across decades\n",
    "total_books_from_decades = books_per_decade['unique_books'].sum()\n",
    "\n",
    "print(\"Books per decade:\")\n",
    "print(books_per_decade)\n",
    "print(f\"\\nSummation of books across decades: {total_books_from_decades}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted ratings: 5942\n",
      "Unique book_ids deleted: 21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "ratings = pd.read_csv(f\"{data_path}/ratings.csv\")\n",
    "\n",
    "# Filter ratings where book_id exists in books\n",
    "valid_book_ids = set(books['book_id'])\n",
    "ratings_clean = ratings[ratings['book_id'].isin(valid_book_ids)]\n",
    "\n",
    "# Calculate how many ratings were deleted\n",
    "deleted_ratings = len(ratings) - len(ratings_clean)\n",
    "\n",
    "# Calculate how many unique book_ids were deleted\n",
    "all_rated_book_ids = set(ratings['book_id'])\n",
    "deleted_book_ids = all_rated_book_ids - valid_book_ids\n",
    "deleted_book_ids_count = len(deleted_book_ids)\n",
    "\n",
    "# Report & overwrite\n",
    "print(f\"Deleted ratings: {deleted_ratings}\")\n",
    "print(f\"Unique book_ids deleted: {deleted_book_ids_count}\")\n",
    "\n",
    "ratings_clean.to_csv(f\"{data_path}/ratings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique book_ids in books.csv: 9979\n",
      "Total unique book_ids in ratings.csv: 9979\n",
      "Total ratings: 5970537\n",
      "\n",
      "Books per decade:\n",
      "    decade  unique_books_per_decade\n",
      "0    -1750                        1\n",
      "1     -770                        1\n",
      "2     -750                        2\n",
      "3     -720                        1\n",
      "4     -560                        1\n",
      "..     ...                      ...\n",
      "78    1970                      400\n",
      "79    1980                      704\n",
      "80    1990                     1360\n",
      "81    2000                     3121\n",
      "82    2010                     3067\n",
      "\n",
      "[83 rows x 2 columns]\n",
      "\n",
      "Summation of books across decades: 9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9979"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load cleaned data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "ratings = pd.read_csv(f\"{data_path}/ratings.csv\")\n",
    "\n",
    "# 1️⃣ Count unique book_id in books.csv\n",
    "unique_books_in_books = books['book_id'].nunique()\n",
    "print(f\"Total unique book_ids in books.csv: {unique_books_in_books}\")\n",
    "\n",
    "# 2️⃣ Count unique book_id in ratings.csv\n",
    "unique_books_in_ratings = ratings['book_id'].nunique()\n",
    "print(f\"Total unique book_ids in ratings.csv: {unique_books_in_ratings}\")\n",
    "\n",
    "# 3️⃣ Count total ratings\n",
    "total_ratings = len(ratings)\n",
    "print(f\"Total ratings: {total_ratings}\")\n",
    "\n",
    "# 4️⃣ Compute decade column\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "\n",
    "# 5️⃣ Count number of unique books per decade\n",
    "books_per_decade = books.groupby('decade')['book_id'].nunique().reset_index(name='unique_books_per_decade')\n",
    "books_per_decade = books_per_decade.sort_values('decade')\n",
    "\n",
    "print(\"\\nBooks per decade:\")\n",
    "print(books_per_decade)\n",
    "\n",
    "# 6️⃣ Verify summation of books across decades\n",
    "total_books_from_decades = books_per_decade['unique_books_per_decade'].sum()\n",
    "print(f\"\\nSummation of books across decades: {total_books_from_decades}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_per_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   decade_grouped  unique_books_per_decade\n",
      "0            1920                       89\n",
      "1            1930                      121\n",
      "2            1940                      155\n",
      "3            1950                      210\n",
      "4            1960                      272\n",
      "5            1970                      400\n",
      "6            1980                      704\n",
      "7            1990                     1360\n",
      "8            2000                     3121\n",
      "9            2010                     3067\n",
      "10  Ancient Books                      480\n",
      "\n",
      "Total books after grouping: 9979\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load cleaned data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "\n",
    "# Create decade column\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "\n",
    "# Replace decades before 1920 with 'Ancient Books'\n",
    "books['decade_grouped'] = books['decade'].apply(lambda x: 'Ancient Books' if x < 1920 else int(x))\n",
    "\n",
    "# Count unique book_ids per grouped decade\n",
    "books_per_decade = books.groupby('decade_grouped')['book_id'].nunique().reset_index(name='unique_books_per_decade')\n",
    "\n",
    "# Sort (Ancient Books first, then by decade)\n",
    "books_per_decade['decade_grouped'] = books_per_decade['decade_grouped'].astype(str)\n",
    "books_per_decade = books_per_decade.sort_values(by='decade_grouped')\n",
    "\n",
    "# Print result\n",
    "print(books_per_decade)\n",
    "\n",
    "# Verify sum still equals total books\n",
    "total_books_from_decades = books_per_decade['unique_books_per_decade'].sum()\n",
    "print(f\"\\nTotal books after grouping: {total_books_from_decades}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  book_id  rating decade\n",
      "0        1      258       5   2000\n",
      "1        2     4081       4   2000\n",
      "2        2      260       5   1930\n",
      "3        2     9296       5   1970\n",
      "4        2     2318       3   1990\n",
      "\n",
      "Final dataset shape: (5970537, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load cleaned data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "ratings = pd.read_csv(f\"{data_path}/ratings.csv\")\n",
    "\n",
    "# Step 1: Create decade column and group into Ancient Books\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "books['decade_grouped'] = books['decade'].apply(lambda x: 'Ancient Books' if x < 1920 else int(x))\n",
    "\n",
    "# Step 2: Merge ratings with books (attach decade info)\n",
    "merged_df = ratings.merge(books[['book_id', 'decade_grouped']], on='book_id', how='left')\n",
    "\n",
    "# Step 3: Rename columns for clarity\n",
    "final_df = merged_df.rename(columns={'decade_grouped': 'decade'})\n",
    "\n",
    "# Step 4: Reorder columns\n",
    "final_df = final_df[['user_id', 'book_id', 'rating', 'decade']]\n",
    "\n",
    "# Step 5: Save final dataset\n",
    "final_df.to_csv(f\"{data_path}/final_svd_dataset.csv\", index=False)\n",
    "\n",
    "# Print sample and shape for verification\n",
    "print(final_df.head())\n",
    "print(f\"\\nFinal dataset shape: {final_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    53424.000000\n",
      "mean       111.757581\n",
      "std         26.075621\n",
      "min         19.000000\n",
      "25%         96.000000\n",
      "50%        111.000000\n",
      "75%        128.000000\n",
      "max        200.000000\n",
      "Name: rating, dtype: float64\n",
      "\n",
      "Users with fewest ratings:\n",
      "user_id\n",
      "34590    19\n",
      "32128    20\n",
      "43675    20\n",
      "51725    21\n",
      "42736    21\n",
      "40753    21\n",
      "37640    22\n",
      "34099    22\n",
      "50918    22\n",
      "25856    22\n",
      "Name: rating, dtype: int64\n",
      "\n",
      "Total number of unique users: 53424\n",
      "Total number of unique books: 9979\n",
      "Minimum number of ratings per user: 19\n",
      "Maximum number of ratings per user: 200\n",
      "Average number of ratings per user: 111.76\n",
      "\n",
      "Average rating score per user:\n",
      "count    53424.000000\n",
      "mean         3.928487\n",
      "std          0.449549\n",
      "min          1.000000\n",
      "25%          3.633663\n",
      "50%          3.920455\n",
      "75%          4.223236\n",
      "max          5.000000\n",
      "Name: rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load your cleaned final dataset\n",
    "data_path = '../data/goodbooks-10k'\n",
    "final_df = pd.read_csv(f\"{data_path}/final_svd_dataset.csv\")\n",
    "\n",
    "# Count number of ratings per user\n",
    "reviews_per_user = final_df.groupby('user_id')['rating'].count()\n",
    "\n",
    "# Average rating per user\n",
    "average_rating_per_user = final_df.groupby('user_id')['rating'].mean()\n",
    "\n",
    "# Print basic stats\n",
    "print(reviews_per_user.describe())\n",
    "\n",
    "# Print users with fewest ratings\n",
    "print(\"\\nUsers with fewest ratings:\")\n",
    "print(reviews_per_user.sort_values().head(10))\n",
    "\n",
    "# Count unique users and books\n",
    "unique_users = final_df['user_id'].nunique()\n",
    "unique_books = final_df['book_id'].nunique()\n",
    "\n",
    "print(f\"\\nTotal number of unique users: {unique_users}\")\n",
    "print(f\"Total number of unique books: {unique_books}\")\n",
    "\n",
    "# Get min/max ratings per user\n",
    "min_ratings = reviews_per_user.min()\n",
    "max_ratings = reviews_per_user.max()\n",
    "avg_ratings_per_user = reviews_per_user.mean()\n",
    "\n",
    "print(f\"Minimum number of ratings per user: {min_ratings}\")\n",
    "print(f\"Maximum number of ratings per user: {max_ratings}\")\n",
    "print(f\"Average number of ratings per user: {avg_ratings_per_user:.2f}\")\n",
    "\n",
    "# Print basic stats for average *rating scores* per user\n",
    "print(\"\\nAverage rating score per user:\")\n",
    "print(average_rating_per_user.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "decade_grouped",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unique_books_per_decade",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "183dc727-dc34-49f5-b57a-da3e18b3d636",
       "rows": [
        [
         "0",
         "1920",
         "89"
        ],
        [
         "1",
         "1930",
         "121"
        ],
        [
         "2",
         "1940",
         "155"
        ],
        [
         "3",
         "1950",
         "210"
        ],
        [
         "4",
         "1960",
         "272"
        ],
        [
         "5",
         "1970",
         "400"
        ],
        [
         "6",
         "1980",
         "704"
        ],
        [
         "7",
         "1990",
         "1360"
        ],
        [
         "8",
         "2000",
         "3121"
        ],
        [
         "9",
         "2010",
         "3067"
        ],
        [
         "10",
         "Ancient Books",
         "480"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decade_grouped</th>\n",
       "      <th>unique_books_per_decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1920</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1930</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1940</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1970</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1980</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1990</td>\n",
       "      <td>1360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000</td>\n",
       "      <td>3121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010</td>\n",
       "      <td>3067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ancient Books</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   decade_grouped  unique_books_per_decade\n",
       "0            1920                       89\n",
       "1            1930                      121\n",
       "2            1940                      155\n",
       "3            1950                      210\n",
       "4            1960                      272\n",
       "5            1970                      400\n",
       "6            1980                      704\n",
       "7            1990                     1360\n",
       "8            2000                     3121\n",
       "9            2010                     3067\n",
       "10  Ancient Books                      480"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_per_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "decade",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "70394ea7-44cd-4fa6-8afc-3122652bd2de",
       "rows": [
        [
         "0",
         "1",
         "258",
         "5",
         "2000"
        ],
        [
         "1",
         "2",
         "4081",
         "4",
         "2000"
        ],
        [
         "2",
         "2",
         "260",
         "5",
         "1930"
        ],
        [
         "3",
         "2",
         "9296",
         "5",
         "1970"
        ],
        [
         "4",
         "2",
         "2318",
         "3",
         "1990"
        ],
        [
         "5",
         "2",
         "26",
         "4",
         "2000"
        ],
        [
         "6",
         "2",
         "315",
         "3",
         "1990"
        ],
        [
         "7",
         "2",
         "33",
         "4",
         "1990"
        ],
        [
         "8",
         "2",
         "301",
         "5",
         "Ancient Books"
        ],
        [
         "9",
         "2",
         "2686",
         "5",
         "2000"
        ],
        [
         "10",
         "2",
         "3753",
         "5",
         "2000"
        ],
        [
         "11",
         "2",
         "8519",
         "5",
         "1970"
        ],
        [
         "12",
         "4",
         "70",
         "4",
         "1980"
        ],
        [
         "13",
         "4",
         "264",
         "3",
         "1920"
        ],
        [
         "14",
         "4",
         "388",
         "4",
         "1980"
        ],
        [
         "15",
         "4",
         "18",
         "5",
         "1990"
        ],
        [
         "16",
         "4",
         "27",
         "5",
         "2000"
        ],
        [
         "17",
         "4",
         "21",
         "5",
         "2000"
        ],
        [
         "18",
         "4",
         "2",
         "5",
         "1990"
        ],
        [
         "19",
         "4",
         "23",
         "5",
         "1990"
        ],
        [
         "20",
         "4",
         "24",
         "5",
         "2000"
        ],
        [
         "21",
         "4",
         "964",
         "4",
         "1970"
        ],
        [
         "22",
         "4",
         "103",
         "5",
         "Ancient Books"
        ],
        [
         "23",
         "4",
         "255",
         "2",
         "1950"
        ],
        [
         "24",
         "4",
         "35",
         "5",
         "1980"
        ],
        [
         "25",
         "4",
         "287",
         "3",
         "1940"
        ],
        [
         "26",
         "4",
         "337",
         "4",
         "1990"
        ],
        [
         "27",
         "4",
         "26",
         "3",
         "2000"
        ],
        [
         "28",
         "4",
         "84",
         "4",
         "1990"
        ],
        [
         "29",
         "4",
         "58",
         "4",
         "Ancient Books"
        ],
        [
         "30",
         "4",
         "1117",
         "3",
         "1990"
        ],
        [
         "31",
         "4",
         "660",
         "3",
         "1980"
        ],
        [
         "32",
         "4",
         "111",
         "2",
         "2000"
        ],
        [
         "33",
         "4",
         "5",
         "4",
         "1920"
        ],
        [
         "34",
         "4",
         "413",
         "4",
         "Ancient Books"
        ],
        [
         "35",
         "4",
         "8",
         "4",
         "1950"
        ],
        [
         "36",
         "4",
         "2172",
         "4",
         "1960"
        ],
        [
         "37",
         "4",
         "65",
         "4",
         "1960"
        ],
        [
         "38",
         "4",
         "297",
         "4",
         "1960"
        ],
        [
         "39",
         "4",
         "45",
         "4",
         "2000"
        ],
        [
         "40",
         "4",
         "113",
         "4",
         "1960"
        ],
        [
         "41",
         "4",
         "325",
         "5",
         "1980"
        ],
        [
         "42",
         "4",
         "476",
         "3",
         "1970"
        ],
        [
         "43",
         "6",
         "6351",
         "4",
         "2000"
        ],
        [
         "44",
         "8",
         "2732",
         "5",
         "Ancient Books"
        ],
        [
         "45",
         "8",
         "1432",
         "3",
         "Ancient Books"
        ],
        [
         "46",
         "8",
         "479",
         "4",
         "Ancient Books"
        ],
        [
         "47",
         "8",
         "3020",
         "5",
         "Ancient Books"
        ],
        [
         "48",
         "8",
         "6195",
         "4",
         "1920"
        ],
        [
         "49",
         "8",
         "614",
         "4",
         "1920"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5970537
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970532</th>\n",
       "      <td>49925</td>\n",
       "      <td>510</td>\n",
       "      <td>5</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970533</th>\n",
       "      <td>49925</td>\n",
       "      <td>528</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970534</th>\n",
       "      <td>49925</td>\n",
       "      <td>722</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970535</th>\n",
       "      <td>49925</td>\n",
       "      <td>949</td>\n",
       "      <td>5</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970536</th>\n",
       "      <td>49925</td>\n",
       "      <td>1023</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5970537 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  book_id  rating decade\n",
       "0              1      258       5   2000\n",
       "1              2     4081       4   2000\n",
       "2              2      260       5   1930\n",
       "3              2     9296       5   1970\n",
       "4              2     2318       3   1990\n",
       "...          ...      ...     ...    ...\n",
       "5970532    49925      510       5   1990\n",
       "5970533    49925      528       4   1990\n",
       "5970534    49925      722       4   1990\n",
       "5970535    49925      949       5   1990\n",
       "5970536    49925     1023       4   1990\n",
       "\n",
       "[5970537 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
