{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books.csv shape: (10000, 23)\n",
      "ratings.csv shape: (5976479, 3)\n",
      "to_read.csv shape: (912705, 2)\n",
      "book_tags.csv shape: (999912, 3)\n",
      "tags.csv shape: (34252, 2)\n",
      "\n",
      "Books sample:\n",
      "   book_id  goodreads_book_id  best_book_id  work_id  books_count       isbn  \\\n",
      "0        1            2767052       2767052  2792775          272  439023483   \n",
      "1        2                  3             3  4640799          491  439554934   \n",
      "2        3              41865         41865  3212258          226  316015849   \n",
      "3        4               2657          2657  3275794          487   61120081   \n",
      "4        5               4671          4671   245494         1356  743273567   \n",
      "\n",
      "         isbn13                      authors  original_publication_year  \\\n",
      "0  9.780439e+12              Suzanne Collins                     2008.0   \n",
      "1  9.780440e+12  J.K. Rowling, Mary GrandPr√©                     1997.0   \n",
      "2  9.780316e+12              Stephenie Meyer                     2005.0   \n",
      "3  9.780061e+12                   Harper Lee                     1960.0   \n",
      "4  9.780743e+12          F. Scott Fitzgerald                     1925.0   \n",
      "\n",
      "                             original_title  ... ratings_count  \\\n",
      "0                          The Hunger Games  ...       4780653   \n",
      "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
      "2                                  Twilight  ...       3866839   \n",
      "3                     To Kill a Mockingbird  ...       3198671   \n",
      "4                          The Great Gatsby  ...       2683664   \n",
      "\n",
      "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
      "0            4942365                   155254      66715     127936   \n",
      "1            4800065                    75867      75504     101676   \n",
      "2            3916824                    95009     456191     436802   \n",
      "3            3340896                    72586      60427     117415   \n",
      "4            2773745                    51992      86236     197621   \n",
      "\n",
      "   ratings_3  ratings_4  ratings_5  \\\n",
      "0     560092    1481305    2706317   \n",
      "1     455024    1156318    3011543   \n",
      "2     793319     875073    1355439   \n",
      "3     446835    1001952    1714267   \n",
      "4     606158     936012     947718   \n",
      "\n",
      "                                           image_url  \\\n",
      "0  https://images.gr-assets.com/books/1447303603m...   \n",
      "1  https://images.gr-assets.com/books/1474154022m...   \n",
      "2  https://images.gr-assets.com/books/1361039443m...   \n",
      "3  https://images.gr-assets.com/books/1361975680m...   \n",
      "4  https://images.gr-assets.com/books/1490528560m...   \n",
      "\n",
      "                                     small_image_url  \n",
      "0  https://images.gr-assets.com/books/1447303603s...  \n",
      "1  https://images.gr-assets.com/books/1474154022s...  \n",
      "2  https://images.gr-assets.com/books/1361039443s...  \n",
      "3  https://images.gr-assets.com/books/1361975680s...  \n",
      "4  https://images.gr-assets.com/books/1490528560s...  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Ratings sample:\n",
      "   user_id  book_id  rating\n",
      "0        1      258       5\n",
      "1        2     4081       4\n",
      "2        2      260       5\n",
      "3        2     9296       5\n",
      "4        2     2318       3\n",
      "\n",
      "To-Read sample:\n",
      "   user_id  book_id\n",
      "0        9        8\n",
      "1       15      398\n",
      "2       15      275\n",
      "3       37     7173\n",
      "4       34      380\n",
      "\n",
      "Book Tags sample:\n",
      "   goodreads_book_id  tag_id   count\n",
      "0                  1   30574  167697\n",
      "1                  1   11305   37174\n",
      "2                  1   11557   34173\n",
      "3                  1    8717   12986\n",
      "4                  1   33114   12716\n",
      "\n",
      "Tags sample:\n",
      "   tag_id tag_name\n",
      "0       0        -\n",
      "1       1     --1-\n",
      "2       2    --10-\n",
      "3       3    --12-\n",
      "4       4   --122-\n"
     ]
    }
   ],
   "source": [
    "# Define your local data path\n",
    "data_path = '../data/goodbooks-10k'  # adjust path if needed\n",
    "\n",
    "# Load all available CSV files\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "ratings = pd.read_csv(os.path.join(data_path, 'ratings.csv'))\n",
    "to_read = pd.read_csv(os.path.join(data_path, 'to_read.csv'))\n",
    "book_tags = pd.read_csv(os.path.join(data_path, 'book_tags.csv'))\n",
    "tags = pd.read_csv(os.path.join(data_path, 'tags.csv'))\n",
    "\n",
    "# Quick verification:\n",
    "print(f\"books.csv shape: {books.shape}\")\n",
    "print(f\"ratings.csv shape: {ratings.shape}\")\n",
    "print(f\"to_read.csv shape: {to_read.shape}\")\n",
    "print(f\"book_tags.csv shape: {book_tags.shape}\")\n",
    "print(f\"tags.csv shape: {tags.shape}\")\n",
    "\n",
    "# Preview few rows from each file:\n",
    "print(\"\\nBooks sample:\")\n",
    "print(books.head())\n",
    "\n",
    "print(\"\\nRatings sample:\")\n",
    "print(ratings.head())\n",
    "\n",
    "print(\"\\nTo-Read sample:\")\n",
    "print(to_read.head())\n",
    "\n",
    "print(\"\\nBook Tags sample:\")\n",
    "print(book_tags.head())\n",
    "\n",
    "print(\"\\nTags sample:\")\n",
    "print(tags.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Load books.csv\n",
    "# data_path = '../data/goodbooks-10k'\n",
    "# books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "\n",
    "# # Total number of books\n",
    "# total_books = len(books)\n",
    "\n",
    "# # Total number of unique languages (excluding NaN)\n",
    "# unique_languages = books['language_code'].nunique()\n",
    "\n",
    "# # Number of books with missing language_code\n",
    "# missing_languages = books['language_code'].isnull().sum()\n",
    "\n",
    "# # Count number of books per language\n",
    "# books_per_language = books['language_code'].value_counts()\n",
    "\n",
    "# # Full list of languages\n",
    "# languages_list = books['language_code'].dropna().unique()\n",
    "\n",
    "# # Print summary\n",
    "# print(f\"Total number of books: {total_books}\")\n",
    "# print(f\"Total unique languages: {unique_languages}\")\n",
    "# print(f\"Number of books missing language info: {missing_languages}\\n\")\n",
    "\n",
    "# print(\"Number of books per language:\")\n",
    "# print(books_per_language)\n",
    "\n",
    "# print(\"\\nList of languages:\")\n",
    "# print(languages_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total books after cleaning: 9979\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load books.csv\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "\n",
    "# Drop books where publication year is missing\n",
    "books = books.dropna(subset=['original_publication_year'])\n",
    "\n",
    "# Convert year to integer for consistency\n",
    "books['original_publication_year'] = books['original_publication_year'].astype(int)\n",
    "\n",
    "# Verify\n",
    "print(f\"Total books after cleaning: {len(books)}\")\n",
    "\n",
    "# Save the cleaned dataframe (replacing the original file)\n",
    "books.to_csv(os.path.join(data_path, 'books.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random sample of books:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "goodreads_book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "best_book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "books_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "isbn",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "isbn13",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "original_publication_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "original_title",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "language_code",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "average_rating",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ratings_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_ratings_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_text_reviews_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings_5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "small_image_url",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "868f036f-006d-4d92-8a64-f7f90b0f0164",
       "rows": [
        [
         "2256",
         "2259",
         "17841",
         "17841",
         "11221066",
         "201",
         "015603297X",
         "9780156032970.0",
         "Umberto Eco, William Weaver",
         "1988",
         "Il pendolo di Foucault",
         "Foucault's Pendulum",
         "en-US",
         "3.89",
         "40829",
         "48898",
         "2649",
         "1633",
         "3603",
         "10343",
         "16318",
         "17001",
         "https://images.gr-assets.com/books/1396645125m/17841.jpg",
         "https://images.gr-assets.com/books/1396645125s/17841.jpg"
        ],
        [
         "1567",
         "1570",
         "7442",
         "7442",
         "208153",
         "45",
         "553380648",
         "9780553380640.0",
         "Tom Wolfe",
         "1968",
         "The Electric Kool-Aid Acid Test",
         "The Electric Kool-Aid Acid Test",
         "en-US",
         "3.92",
         "54848",
         "58254",
         "1529",
         "982",
         "3287",
         "13596",
         "21988",
         "18401",
         "https://s.gr-assets.com/assets/nophoto/book/111x148-bcc042a9c91a29c1d680899eff700a03.png",
         "https://s.gr-assets.com/assets/nophoto/book/50x75-a91bf249278a81aabab721ef782c4a74.png"
        ],
        [
         "7441",
         "7457",
         "9864913",
         "9864913",
         "14756358",
         "14",
         "014310425X",
         "9780143104250.0",
         "Devdutt Pattanaik",
         "2010",
         "Jaya: An Illustrated Retelling of the Mahabharata",
         "Jaya: An Illustrated Retelling of the Mahabharata",
         "eng",
         "4.2",
         "9534",
         "10597",
         "840",
         "82",
         "220",
         "1487",
         "4542",
         "4266",
         "https://images.gr-assets.com/books/1357361164m/9864913.jpg",
         "https://images.gr-assets.com/books/1357361164s/9864913.jpg"
        ],
        [
         "4939",
         "4949",
         "2659997",
         "2659997",
         "3340863",
         "35",
         "61628018",
         "9780061628020.0",
         "Elissa Wall, Lisa Pulitzer",
         "2008",
         "Stolen Innocence: My Story of Growing Up in a Polygamous Sect, Becoming a Teenage Bride, and Breaking Free of Warren Jeffs",
         "Stolen Innocence: My Story of Growing Up in a Polygamous Sect, Becoming a Teenage Bride, and Breaking Free of Warren Jeffs",
         null,
         "3.89",
         "19468",
         "21574",
         "1882",
         "191",
         "1069",
         "5804",
         "8373",
         "6137",
         "https://s.gr-assets.com/assets/nophoto/book/111x148-bcc042a9c91a29c1d680899eff700a03.png",
         "https://s.gr-assets.com/assets/nophoto/book/50x75-a91bf249278a81aabab721ef782c4a74.png"
        ],
        [
         "9697",
         "9718",
         "13414599",
         "13414599",
         "18713712",
         "25",
         "449014398",
         "9780449014390.0",
         "Gretchen Rubin, K√§the Mazur",
         "2012",
         "Happier at Home: Kiss More, Jump More, Abandon a Project, Read Samuel Johnson, and My Other Experiments in the Practice of Everyday Life",
         "Happier at Home: Kiss More, Jump More, Abandon a Project, Read Samuel Johnson, and My Other Experiments in the Practice of Everyday Life",
         "eng",
         "3.48",
         "6058",
         "12025",
         "1630",
         "372",
         "1563",
         "4144",
         "3844",
         "2102",
         "https://images.gr-assets.com/books/1344014249m/13414599.jpg",
         "https://images.gr-assets.com/books/1344014249s/13414599.jpg"
        ],
        [
         "9586",
         "9607",
         "81992",
         "81992",
         "1192005",
         "26",
         "1841493341",
         "9781841493340.0",
         "Charles Stross",
         "2003",
         "Singularity Sky",
         "Singularity Sky (Eschaton, #1)",
         "eng",
         "3.81",
         "9887",
         "11169",
         "442",
         "151",
         "687",
         "2924",
         "4749",
         "2658",
         "https://images.gr-assets.com/books/1446324638m/81992.jpg",
         "https://images.gr-assets.com/books/1446324638s/81992.jpg"
        ],
        [
         "8621",
         "8639",
         "15811520",
         "15811520",
         "21536784",
         "10",
         "1594205345",
         "9781594205350.0",
         "Charlie LeDuff",
         "2013",
         null,
         "Detroit: An American Autopsy",
         "eng",
         "3.95",
         "9860",
         "11103",
         "1692",
         "172",
         "499",
         "2343",
         "4785",
         "3304",
         "https://images.gr-assets.com/books/1350363602m/15811520.jpg",
         "https://images.gr-assets.com/books/1350363602s/15811520.jpg"
        ],
        [
         "2013",
         "2016",
         "4494917",
         "4494917",
         "4487466",
         "81",
         "593057058",
         "9780593057060.0",
         "Lee Child",
         "2009",
         "Gone Tomorrow",
         "Gone Tomorrow (Jack Reacher, #13)",
         "eng",
         "4.17",
         "51570",
         "59755",
         "2359",
         "411",
         "1270",
         "9698",
         "24969",
         "23407",
         "https://images.gr-assets.com/books/1328395497m/4494917.jpg",
         "https://images.gr-assets.com/books/1328395497s/4494917.jpg"
        ],
        [
         "1311",
         "1314",
         "22463",
         "22463",
         "481941",
         "1004",
         "785819118",
         "9780785819110.0",
         "Charles Darwin",
         "1859",
         "On the Origin of Species by Means of Natural Selection or the Preservation of Favoured Races in the Struggle for Life",
         "The Origin of Species",
         "eng",
         "3.97",
         "64162",
         "74056",
         "1729",
         "2513",
         "4297",
         "15150",
         "22868",
         "29228",
         "https://s.gr-assets.com/assets/nophoto/book/111x148-bcc042a9c91a29c1d680899eff700a03.png",
         "https://s.gr-assets.com/assets/nophoto/book/50x75-a91bf249278a81aabab721ef782c4a74.png"
        ],
        [
         "5019",
         "5029",
         "112675",
         "112675",
         "108493",
         "45",
         "64473627",
         "9780064473620.0",
         "Louise Rennison",
         "2001",
         "Knocked out by my nunga-nungas",
         "Knocked Out by My Nunga-Nungas (Confessions of Georgia Nicolson, #3)",
         "en-US",
         "3.97",
         "24077",
         "26587",
         "590",
         "400",
         "1362",
         "6431",
         "8864",
         "9530",
         "https://s.gr-assets.com/assets/nophoto/book/111x148-bcc042a9c91a29c1d680899eff700a03.png",
         "https://s.gr-assets.com/assets/nophoto/book/50x75-a91bf249278a81aabab721ef782c4a74.png"
        ]
       ],
       "shape": {
        "columns": 23,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>2259</td>\n",
       "      <td>17841</td>\n",
       "      <td>17841</td>\n",
       "      <td>11221066</td>\n",
       "      <td>201</td>\n",
       "      <td>015603297X</td>\n",
       "      <td>9.780156e+12</td>\n",
       "      <td>Umberto Eco, William Weaver</td>\n",
       "      <td>1988</td>\n",
       "      <td>Il pendolo di Foucault</td>\n",
       "      <td>...</td>\n",
       "      <td>40829</td>\n",
       "      <td>48898</td>\n",
       "      <td>2649</td>\n",
       "      <td>1633</td>\n",
       "      <td>3603</td>\n",
       "      <td>10343</td>\n",
       "      <td>16318</td>\n",
       "      <td>17001</td>\n",
       "      <td>https://images.gr-assets.com/books/1396645125m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1396645125s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>1570</td>\n",
       "      <td>7442</td>\n",
       "      <td>7442</td>\n",
       "      <td>208153</td>\n",
       "      <td>45</td>\n",
       "      <td>553380648</td>\n",
       "      <td>9.780553e+12</td>\n",
       "      <td>Tom Wolfe</td>\n",
       "      <td>1968</td>\n",
       "      <td>The Electric Kool-Aid Acid Test</td>\n",
       "      <td>...</td>\n",
       "      <td>54848</td>\n",
       "      <td>58254</td>\n",
       "      <td>1529</td>\n",
       "      <td>982</td>\n",
       "      <td>3287</td>\n",
       "      <td>13596</td>\n",
       "      <td>21988</td>\n",
       "      <td>18401</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7441</th>\n",
       "      <td>7457</td>\n",
       "      <td>9864913</td>\n",
       "      <td>9864913</td>\n",
       "      <td>14756358</td>\n",
       "      <td>14</td>\n",
       "      <td>014310425X</td>\n",
       "      <td>9.780143e+12</td>\n",
       "      <td>Devdutt Pattanaik</td>\n",
       "      <td>2010</td>\n",
       "      <td>Jaya: An Illustrated Retelling of the Mahabharata</td>\n",
       "      <td>...</td>\n",
       "      <td>9534</td>\n",
       "      <td>10597</td>\n",
       "      <td>840</td>\n",
       "      <td>82</td>\n",
       "      <td>220</td>\n",
       "      <td>1487</td>\n",
       "      <td>4542</td>\n",
       "      <td>4266</td>\n",
       "      <td>https://images.gr-assets.com/books/1357361164m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1357361164s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4939</th>\n",
       "      <td>4949</td>\n",
       "      <td>2659997</td>\n",
       "      <td>2659997</td>\n",
       "      <td>3340863</td>\n",
       "      <td>35</td>\n",
       "      <td>61628018</td>\n",
       "      <td>9.780062e+12</td>\n",
       "      <td>Elissa Wall, Lisa Pulitzer</td>\n",
       "      <td>2008</td>\n",
       "      <td>Stolen Innocence: My Story of Growing Up in a ...</td>\n",
       "      <td>...</td>\n",
       "      <td>19468</td>\n",
       "      <td>21574</td>\n",
       "      <td>1882</td>\n",
       "      <td>191</td>\n",
       "      <td>1069</td>\n",
       "      <td>5804</td>\n",
       "      <td>8373</td>\n",
       "      <td>6137</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9697</th>\n",
       "      <td>9718</td>\n",
       "      <td>13414599</td>\n",
       "      <td>13414599</td>\n",
       "      <td>18713712</td>\n",
       "      <td>25</td>\n",
       "      <td>449014398</td>\n",
       "      <td>9.780449e+12</td>\n",
       "      <td>Gretchen Rubin, K√§the Mazur</td>\n",
       "      <td>2012</td>\n",
       "      <td>Happier at Home: Kiss More, Jump More, Abandon...</td>\n",
       "      <td>...</td>\n",
       "      <td>6058</td>\n",
       "      <td>12025</td>\n",
       "      <td>1630</td>\n",
       "      <td>372</td>\n",
       "      <td>1563</td>\n",
       "      <td>4144</td>\n",
       "      <td>3844</td>\n",
       "      <td>2102</td>\n",
       "      <td>https://images.gr-assets.com/books/1344014249m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1344014249s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9586</th>\n",
       "      <td>9607</td>\n",
       "      <td>81992</td>\n",
       "      <td>81992</td>\n",
       "      <td>1192005</td>\n",
       "      <td>26</td>\n",
       "      <td>1841493341</td>\n",
       "      <td>9.781841e+12</td>\n",
       "      <td>Charles Stross</td>\n",
       "      <td>2003</td>\n",
       "      <td>Singularity Sky</td>\n",
       "      <td>...</td>\n",
       "      <td>9887</td>\n",
       "      <td>11169</td>\n",
       "      <td>442</td>\n",
       "      <td>151</td>\n",
       "      <td>687</td>\n",
       "      <td>2924</td>\n",
       "      <td>4749</td>\n",
       "      <td>2658</td>\n",
       "      <td>https://images.gr-assets.com/books/1446324638m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1446324638s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8621</th>\n",
       "      <td>8639</td>\n",
       "      <td>15811520</td>\n",
       "      <td>15811520</td>\n",
       "      <td>21536784</td>\n",
       "      <td>10</td>\n",
       "      <td>1594205345</td>\n",
       "      <td>9.781594e+12</td>\n",
       "      <td>Charlie LeDuff</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9860</td>\n",
       "      <td>11103</td>\n",
       "      <td>1692</td>\n",
       "      <td>172</td>\n",
       "      <td>499</td>\n",
       "      <td>2343</td>\n",
       "      <td>4785</td>\n",
       "      <td>3304</td>\n",
       "      <td>https://images.gr-assets.com/books/1350363602m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1350363602s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2016</td>\n",
       "      <td>4494917</td>\n",
       "      <td>4494917</td>\n",
       "      <td>4487466</td>\n",
       "      <td>81</td>\n",
       "      <td>593057058</td>\n",
       "      <td>9.780593e+12</td>\n",
       "      <td>Lee Child</td>\n",
       "      <td>2009</td>\n",
       "      <td>Gone Tomorrow</td>\n",
       "      <td>...</td>\n",
       "      <td>51570</td>\n",
       "      <td>59755</td>\n",
       "      <td>2359</td>\n",
       "      <td>411</td>\n",
       "      <td>1270</td>\n",
       "      <td>9698</td>\n",
       "      <td>24969</td>\n",
       "      <td>23407</td>\n",
       "      <td>https://images.gr-assets.com/books/1328395497m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1328395497s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1314</td>\n",
       "      <td>22463</td>\n",
       "      <td>22463</td>\n",
       "      <td>481941</td>\n",
       "      <td>1004</td>\n",
       "      <td>785819118</td>\n",
       "      <td>9.780786e+12</td>\n",
       "      <td>Charles Darwin</td>\n",
       "      <td>1859</td>\n",
       "      <td>On the Origin of Species by Means of Natural S...</td>\n",
       "      <td>...</td>\n",
       "      <td>64162</td>\n",
       "      <td>74056</td>\n",
       "      <td>1729</td>\n",
       "      <td>2513</td>\n",
       "      <td>4297</td>\n",
       "      <td>15150</td>\n",
       "      <td>22868</td>\n",
       "      <td>29228</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>5029</td>\n",
       "      <td>112675</td>\n",
       "      <td>112675</td>\n",
       "      <td>108493</td>\n",
       "      <td>45</td>\n",
       "      <td>64473627</td>\n",
       "      <td>9.780064e+12</td>\n",
       "      <td>Louise Rennison</td>\n",
       "      <td>2001</td>\n",
       "      <td>Knocked out by my nunga-nungas</td>\n",
       "      <td>...</td>\n",
       "      <td>24077</td>\n",
       "      <td>26587</td>\n",
       "      <td>590</td>\n",
       "      <td>400</td>\n",
       "      <td>1362</td>\n",
       "      <td>6431</td>\n",
       "      <td>8864</td>\n",
       "      <td>9530</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/50...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id  goodreads_book_id  best_book_id   work_id  books_count  \\\n",
       "2256     2259              17841         17841  11221066          201   \n",
       "1567     1570               7442          7442    208153           45   \n",
       "7441     7457            9864913       9864913  14756358           14   \n",
       "4939     4949            2659997       2659997   3340863           35   \n",
       "9697     9718           13414599      13414599  18713712           25   \n",
       "9586     9607              81992         81992   1192005           26   \n",
       "8621     8639           15811520      15811520  21536784           10   \n",
       "2013     2016            4494917       4494917   4487466           81   \n",
       "1311     1314              22463         22463    481941         1004   \n",
       "5019     5029             112675        112675    108493           45   \n",
       "\n",
       "            isbn        isbn13                      authors  \\\n",
       "2256  015603297X  9.780156e+12  Umberto Eco, William Weaver   \n",
       "1567   553380648  9.780553e+12                    Tom Wolfe   \n",
       "7441  014310425X  9.780143e+12            Devdutt Pattanaik   \n",
       "4939    61628018  9.780062e+12   Elissa Wall, Lisa Pulitzer   \n",
       "9697   449014398  9.780449e+12  Gretchen Rubin, K√§the Mazur   \n",
       "9586  1841493341  9.781841e+12               Charles Stross   \n",
       "8621  1594205345  9.781594e+12               Charlie LeDuff   \n",
       "2013   593057058  9.780593e+12                    Lee Child   \n",
       "1311   785819118  9.780786e+12               Charles Darwin   \n",
       "5019    64473627  9.780064e+12              Louise Rennison   \n",
       "\n",
       "      original_publication_year  \\\n",
       "2256                       1988   \n",
       "1567                       1968   \n",
       "7441                       2010   \n",
       "4939                       2008   \n",
       "9697                       2012   \n",
       "9586                       2003   \n",
       "8621                       2013   \n",
       "2013                       2009   \n",
       "1311                       1859   \n",
       "5019                       2001   \n",
       "\n",
       "                                         original_title  ... ratings_count  \\\n",
       "2256                             Il pendolo di Foucault  ...         40829   \n",
       "1567                    The Electric Kool-Aid Acid Test  ...         54848   \n",
       "7441  Jaya: An Illustrated Retelling of the Mahabharata  ...          9534   \n",
       "4939  Stolen Innocence: My Story of Growing Up in a ...  ...         19468   \n",
       "9697  Happier at Home: Kiss More, Jump More, Abandon...  ...          6058   \n",
       "9586                                    Singularity Sky  ...          9887   \n",
       "8621                                                NaN  ...          9860   \n",
       "2013                                      Gone Tomorrow  ...         51570   \n",
       "1311  On the Origin of Species by Means of Natural S...  ...         64162   \n",
       "5019                     Knocked out by my nunga-nungas  ...         24077   \n",
       "\n",
       "     work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "2256              48898                     2649       1633       3603   \n",
       "1567              58254                     1529        982       3287   \n",
       "7441              10597                      840         82        220   \n",
       "4939              21574                     1882        191       1069   \n",
       "9697              12025                     1630        372       1563   \n",
       "9586              11169                      442        151        687   \n",
       "8621              11103                     1692        172        499   \n",
       "2013              59755                     2359        411       1270   \n",
       "1311              74056                     1729       2513       4297   \n",
       "5019              26587                      590        400       1362   \n",
       "\n",
       "      ratings_3  ratings_4  ratings_5  \\\n",
       "2256      10343      16318      17001   \n",
       "1567      13596      21988      18401   \n",
       "7441       1487       4542       4266   \n",
       "4939       5804       8373       6137   \n",
       "9697       4144       3844       2102   \n",
       "9586       2924       4749       2658   \n",
       "8621       2343       4785       3304   \n",
       "2013       9698      24969      23407   \n",
       "1311      15150      22868      29228   \n",
       "5019       6431       8864       9530   \n",
       "\n",
       "                                              image_url  \\\n",
       "2256  https://images.gr-assets.com/books/1396645125m...   \n",
       "1567  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
       "7441  https://images.gr-assets.com/books/1357361164m...   \n",
       "4939  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
       "9697  https://images.gr-assets.com/books/1344014249m...   \n",
       "9586  https://images.gr-assets.com/books/1446324638m...   \n",
       "8621  https://images.gr-assets.com/books/1350363602m...   \n",
       "2013  https://images.gr-assets.com/books/1328395497m...   \n",
       "1311  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
       "5019  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
       "\n",
       "                                        small_image_url  \n",
       "2256  https://images.gr-assets.com/books/1396645125s...  \n",
       "1567  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
       "7441  https://images.gr-assets.com/books/1357361164s...  \n",
       "4939  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
       "9697  https://images.gr-assets.com/books/1344014249s...  \n",
       "9586  https://images.gr-assets.com/books/1446324638s...  \n",
       "8621  https://images.gr-assets.com/books/1350363602s...  \n",
       "2013  https://images.gr-assets.com/books/1328395497s...  \n",
       "1311  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
       "5019  https://s.gr-assets.com/assets/nophoto/book/50...  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the cleaned books.csv\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "\n",
    "# Print first few rows\n",
    "# print(books.head())\n",
    "\n",
    "# Or print a random sample of 10 books\n",
    "print(\"\\nRandom sample of books:\")\n",
    "books.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nausea' 'Being and Nothingness' 'No Exit and Three Other Plays'\n",
      " 'No Exit' 'The Wall' 'Existentialism Is a Humanism'\n",
      " 'The Wretched of the Earth']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the books.csv file\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "\n",
    "# Define common variations of J.K. Rowling's name\n",
    "name_variations = [ 'sartre', 'sarter']]\n",
    "\n",
    "# Combine into a regex pattern for case-insensitive search\n",
    "pattern = '|'.join(name_variations)\n",
    "\n",
    "# Search for rows where the 'author' column contains any of the variations\n",
    "rowling_books = books[books['authors'].str.lower().str.contains(pattern, na=False)]\n",
    "\n",
    "# Display result\n",
    "print(rowling_books['title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique authors: 4653\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the books.csv file\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "\n",
    "# Count unique authors\n",
    "unique_authors = books['authors'].nunique()\n",
    "\n",
    "# Print the count\n",
    "print(f\"Number of unique authors: {unique_authors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6148       ÿπŸÇÿß€åÿØ €å⁄© ÿØŸÑŸÇ⁄©\n",
      "6759        ÿ±ÿ®ÿßÿπŸäÿßÿ™ ÿÆŸäÿßŸÖ\n",
      "7469              ÿ≥€åŸÜŸàŸáŸá\n",
      "7623       ÿØÿ±ÿÆÿ™ ÿ≤€åÿ®ÿß€å ŸÖŸÜ\n",
      "8319    ŸÖÿßŸá€å ÿ≥€åÿßŸá ⁄©Ÿà⁄ÜŸàŸÑŸà\n",
      "8864       ÿ≥ŸÖŸÅŸàŸÜ€å ŸÖÿ±ÿØ⁄ØÿßŸÜ\n",
      "9837            Ÿáÿ¥ÿ™ ⁄©ÿ™ÿßÿ®\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define Persian language variations\n",
    "persian_lang_variants = ['per', 'persian', 'fa']\n",
    "\n",
    "# Filter rows where language column matches any variant (case-insensitive)\n",
    "persian_books = books[books['language_code'].str.lower().isin(persian_lang_variants)]\n",
    "# Show only the book titles\n",
    "print(persian_books['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique book IDs in ratings.csv: 10000\n",
      "Unique book IDs in books.csv: 9979\n"
     ]
    }
   ],
   "source": [
    "# Total unique book IDs in ratings file\n",
    "total_unique_books_in_ratings = ratings['book_id'].nunique()\n",
    "\n",
    "# Total unique book IDs in books file (metadata)\n",
    "total_unique_books_in_books = books['book_id'].nunique()\n",
    "\n",
    "print(f\"Unique book IDs in ratings.csv: {total_unique_books_in_ratings}\")\n",
    "print(f\"Unique book IDs in books.csv: {total_unique_books_in_books}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of titles with multiple publication years: 33\n",
      "\n",
      "Title: 'Salem's Lot\n",
      "Years: [1975, 2005]\n",
      "\n",
      "Title: Anatomy for the Artist\n",
      "Years: [1953, 2001]\n",
      "\n",
      "Title: Arcadia\n",
      "Years: [1993, 2012]\n",
      "\n",
      "Title: Are You My Mother?\n",
      "Years: [1960, 2012]\n",
      "\n",
      "Title: Bambi\n",
      "Years: [1923, 1941]\n",
      "\n",
      "Title: Between the Lines (Between the Lines, #1)\n",
      "Years: [2011, 2012]\n",
      "\n",
      "Title: Invisible\n",
      "Years: [2009, 2014]\n",
      "\n",
      "Title: Leviathan\n",
      "Years: [1651, 1992]\n",
      "\n",
      "Title: Monster\n",
      "Years: [1999, 2005]\n",
      "\n",
      "Title: One Flew Over the Cuckoo's Nest\n",
      "Years: [1962, 1970]\n"
     ]
    }
   ],
   "source": [
    "# Group by title and collect all unique years per title\n",
    "title_years = books.groupby('title')['original_publication_year'].unique()\n",
    "\n",
    "# Filter only titles that have more than 1 unique year\n",
    "multiple_year_titles = title_years[title_years.apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Print count\n",
    "print(f\"Number of titles with multiple publication years: {len(multiple_year_titles)}\")\n",
    "\n",
    "# Print sample (first 10 titles)\n",
    "for title, years in multiple_year_titles.head(10).items():\n",
    "    print(f\"\\nTitle: {title}\")\n",
    "    print(f\"Years: {sorted(years)}\")\n",
    "\n",
    "# Total unique book IDs in ratings file\n",
    "total_unique_books_in_ratings = ratings['book_id'].nunique()\n",
    "\n",
    "# Total unique book IDs in books file (metadata)\n",
    "total_unique_books_in_books = books['book_id'].nunique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total ratings from summary: 5970537\n",
      "Total number of ratings from ratings.csv: 5976479\n",
      "Unique books per decade and total ratings:\n",
      "    decade  unique_books  total_ratings\n",
      "0    -1750             1            730\n",
      "1     -770             1            756\n",
      "2     -750             2           3944\n",
      "3     -720             1           6301\n",
      "4     -560             1           1548\n",
      "..     ...           ...            ...\n",
      "78    1970           400         244194\n",
      "79    1980           704         443368\n",
      "80    1990          1360         847948\n",
      "81    2000          3121        1808808\n",
      "82    2010          3067        1268418\n",
      "\n",
      "[83 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "ratings = pd.read_csv(f\"{data_path}/ratings.csv\")\n",
    "\n",
    "# Create decade column and merge\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "merged_df = ratings.merge(books[['book_id', 'decade']], on='book_id')\n",
    "\n",
    "# Groupby decade: count unique books & total ratings\n",
    "summary = merged_df.groupby('decade').agg(\n",
    "    unique_books=('book_id', 'nunique'),\n",
    "    total_ratings=('rating', 'count')\n",
    ").reset_index().sort_values('decade')\n",
    "\n",
    "total_ratings_sum = summary['total_ratings'].sum()\n",
    "print(f\"Sum of total ratings from summary: {total_ratings_sum}\")\n",
    "\n",
    "total_ratings_actual = len(ratings)\n",
    "print(f\"Total number of ratings from ratings.csv: {total_ratings_actual}\")\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"Unique books per decade and total ratings:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of book_ids in ratings.csv not found in books.csv: 21\n"
     ]
    }
   ],
   "source": [
    "# How many unique book_ids exist in ratings but not in books\n",
    "missing_books = set(ratings['book_id']) - set(books['book_id'])\n",
    "print(f\"Number of book_ids in ratings.csv not found in books.csv: {len(missing_books)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing ratings count (from missing book_ids): 5942\n",
      "Gap between ratings.csv and merged summary: 5942\n",
      "Does it match? ‚úÖ YES\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(os.path.join(data_path, 'books.csv'))\n",
    "ratings = pd.read_csv(os.path.join(data_path, 'ratings.csv'))\n",
    "\n",
    "# Find book_ids that exist in ratings but not in books\n",
    "book_ids_in_books = set(books['book_id'])\n",
    "book_ids_in_ratings = set(ratings['book_id'])\n",
    "missing_book_ids = book_ids_in_ratings - book_ids_in_books\n",
    "\n",
    "# Get ratings corresponding to missing book_ids\n",
    "missing_ratings = ratings[ratings['book_id'].isin(missing_book_ids)]\n",
    "\n",
    "# Count how many ratings are missing\n",
    "missing_ratings_count = len(missing_ratings)\n",
    "\n",
    "print(f\"Missing ratings count (from missing book_ids): {missing_ratings_count}\")\n",
    "\n",
    "# Compare with gap\n",
    "total_ratings = len(ratings)\n",
    "ratings_after_merge = 5970537  # This is your merged sum above\n",
    "gap = total_ratings - ratings_after_merge\n",
    "\n",
    "print(f\"Gap between ratings.csv and merged summary: {gap}\")\n",
    "print(f\"Does it match? {'‚úÖ YES' if gap == missing_ratings_count else '‚ùå NO'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique books: 9979\n"
     ]
    }
   ],
   "source": [
    "total_books = books['book_id'].nunique()\n",
    "print(f\"Total unique books: {total_books}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ratings: 5976479\n"
     ]
    }
   ],
   "source": [
    "total_ratings = len(ratings)\n",
    "print(f\"Total ratings: {total_ratings}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books per decade:\n",
      "    decade  unique_books\n",
      "0    -1750             1\n",
      "1     -770             1\n",
      "2     -750             2\n",
      "3     -720             1\n",
      "4     -560             1\n",
      "..     ...           ...\n",
      "78    1970           400\n",
      "79    1980           704\n",
      "80    1990          1360\n",
      "81    2000          3121\n",
      "82    2010          3067\n",
      "\n",
      "[83 rows x 2 columns]\n",
      "\n",
      "Summation of books across decades: 9979\n"
     ]
    }
   ],
   "source": [
    "# Add decade\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "\n",
    "# Count books per decade (this is from full books.csv not merged one!)\n",
    "books_per_decade = books.groupby('decade')['book_id'].nunique().reset_index(name='unique_books')\n",
    "\n",
    "# Summation of books across decades\n",
    "total_books_from_decades = books_per_decade['unique_books'].sum()\n",
    "\n",
    "print(\"Books per decade:\")\n",
    "print(books_per_decade)\n",
    "print(f\"\\nSummation of books across decades: {total_books_from_decades}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted ratings: 5942\n",
      "Unique book_ids deleted: 21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "ratings = pd.read_csv(f\"{data_path}/ratings.csv\")\n",
    "\n",
    "# Filter ratings where book_id exists in books\n",
    "valid_book_ids = set(books['book_id'])\n",
    "ratings_clean = ratings[ratings['book_id'].isin(valid_book_ids)]\n",
    "\n",
    "# Calculate how many ratings were deleted\n",
    "deleted_ratings = len(ratings) - len(ratings_clean)\n",
    "\n",
    "# Calculate how many unique book_ids were deleted\n",
    "all_rated_book_ids = set(ratings['book_id'])\n",
    "deleted_book_ids = all_rated_book_ids - valid_book_ids\n",
    "deleted_book_ids_count = len(deleted_book_ids)\n",
    "\n",
    "# Report & overwrite\n",
    "print(f\"Deleted ratings: {deleted_ratings}\")\n",
    "print(f\"Unique book_ids deleted: {deleted_book_ids_count}\")\n",
    "\n",
    "ratings_clean.to_csv(f\"{data_path}/ratings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique book_ids in books.csv: 9979\n",
      "Total unique book_ids in ratings.csv: 9979\n",
      "Total ratings: 5970537\n",
      "\n",
      "Books per decade:\n",
      "    decade  unique_books_per_decade\n",
      "0    -1750                        1\n",
      "1     -770                        1\n",
      "2     -750                        2\n",
      "3     -720                        1\n",
      "4     -560                        1\n",
      "..     ...                      ...\n",
      "78    1970                      400\n",
      "79    1980                      704\n",
      "80    1990                     1360\n",
      "81    2000                     3121\n",
      "82    2010                     3067\n",
      "\n",
      "[83 rows x 2 columns]\n",
      "\n",
      "Summation of books across decades: 9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9979"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load cleaned data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "ratings = pd.read_csv(f\"{data_path}/ratings.csv\")\n",
    "\n",
    "# 1Ô∏è‚É£ Count unique book_id in books.csv\n",
    "unique_books_in_books = books['book_id'].nunique()\n",
    "print(f\"Total unique book_ids in books.csv: {unique_books_in_books}\")\n",
    "\n",
    "# 2Ô∏è‚É£ Count unique book_id in ratings.csv\n",
    "unique_books_in_ratings = ratings['book_id'].nunique()\n",
    "print(f\"Total unique book_ids in ratings.csv: {unique_books_in_ratings}\")\n",
    "\n",
    "# 3Ô∏è‚É£ Count total ratings\n",
    "total_ratings = len(ratings)\n",
    "print(f\"Total ratings: {total_ratings}\")\n",
    "\n",
    "# 4Ô∏è‚É£ Compute decade column\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "\n",
    "# 5Ô∏è‚É£ Count number of unique books per decade\n",
    "books_per_decade = books.groupby('decade')['book_id'].nunique().reset_index(name='unique_books_per_decade')\n",
    "books_per_decade = books_per_decade.sort_values('decade')\n",
    "\n",
    "print(\"\\nBooks per decade:\")\n",
    "print(books_per_decade)\n",
    "\n",
    "# 6Ô∏è‚É£ Verify summation of books across decades\n",
    "total_books_from_decades = books_per_decade['unique_books_per_decade'].sum()\n",
    "print(f\"\\nSummation of books across decades: {total_books_from_decades}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_per_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   decade_grouped  unique_books_per_decade\n",
      "0            1920                       89\n",
      "1            1930                      121\n",
      "2            1940                      155\n",
      "3            1950                      210\n",
      "4            1960                      272\n",
      "5            1970                      400\n",
      "6            1980                      704\n",
      "7            1990                     1360\n",
      "8            2000                     3121\n",
      "9            2010                     3067\n",
      "10  Ancient Books                      480\n",
      "\n",
      "Total books after grouping: 9979\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load cleaned data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "\n",
    "# Create decade column\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "\n",
    "# Replace decades before 1920 with 'Ancient Books'\n",
    "books['decade_grouped'] = books['decade'].apply(lambda x: 'Ancient Books' if x < 1920 else int(x))\n",
    "\n",
    "# Count unique book_ids per grouped decade\n",
    "books_per_decade = books.groupby('decade_grouped')['book_id'].nunique().reset_index(name='unique_books_per_decade')\n",
    "\n",
    "# Sort (Ancient Books first, then by decade)\n",
    "books_per_decade['decade_grouped'] = books_per_decade['decade_grouped'].astype(str)\n",
    "books_per_decade = books_per_decade.sort_values(by='decade_grouped')\n",
    "\n",
    "# Print result\n",
    "print(books_per_decade)\n",
    "\n",
    "# Verify sum still equals total books\n",
    "total_books_from_decades = books_per_decade['unique_books_per_decade'].sum()\n",
    "print(f\"\\nTotal books after grouping: {total_books_from_decades}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  book_id  rating decade\n",
      "0        1      258       5   2000\n",
      "1        2     4081       4   2000\n",
      "2        2      260       5   1930\n",
      "3        2     9296       5   1970\n",
      "4        2     2318       3   1990\n",
      "\n",
      "Final dataset shape: (5970537, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load cleaned data\n",
    "data_path = '../data/goodbooks-10k'\n",
    "books = pd.read_csv(f\"{data_path}/books.csv\")\n",
    "ratings = pd.read_csv(f\"{data_path}/ratings.csv\")\n",
    "\n",
    "# Step 1: Create decade column and group into Ancient Books\n",
    "books['decade'] = (books['original_publication_year'] // 10) * 10\n",
    "books['decade_grouped'] = books['decade'].apply(lambda x: 'Ancient Books' if x < 1920 else int(x))\n",
    "\n",
    "# Step 2: Merge ratings with books (attach decade info)\n",
    "merged_df = ratings.merge(books[['book_id', 'decade_grouped']], on='book_id', how='left')\n",
    "\n",
    "# Step 3: Rename columns for clarity\n",
    "final_df = merged_df.rename(columns={'decade_grouped': 'decade'})\n",
    "\n",
    "# Step 4: Reorder columns\n",
    "final_df = final_df[['user_id', 'book_id', 'rating', 'decade']]\n",
    "\n",
    "# Step 5: Save final dataset\n",
    "final_df.to_csv(f\"{data_path}/final_svd_dataset.csv\", index=False)\n",
    "\n",
    "# Print sample and shape for verification\n",
    "print(final_df.head())\n",
    "print(f\"\\nFinal dataset shape: {final_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    53424.000000\n",
      "mean       111.757581\n",
      "std         26.075621\n",
      "min         19.000000\n",
      "25%         96.000000\n",
      "50%        111.000000\n",
      "75%        128.000000\n",
      "max        200.000000\n",
      "Name: rating, dtype: float64\n",
      "\n",
      "Users with fewest ratings:\n",
      "user_id\n",
      "34590    19\n",
      "32128    20\n",
      "43675    20\n",
      "51725    21\n",
      "42736    21\n",
      "40753    21\n",
      "37640    22\n",
      "34099    22\n",
      "50918    22\n",
      "25856    22\n",
      "Name: rating, dtype: int64\n",
      "\n",
      "Total number of unique users: 53424\n",
      "Total number of unique books: 9979\n",
      "Minimum number of ratings per user: 19\n",
      "Maximum number of ratings per user: 200\n",
      "Average number of ratings per user: 111.76\n",
      "\n",
      "Average rating score per user:\n",
      "count    53424.000000\n",
      "mean         3.928487\n",
      "std          0.449549\n",
      "min          1.000000\n",
      "25%          3.633663\n",
      "50%          3.920455\n",
      "75%          4.223236\n",
      "max          5.000000\n",
      "Name: rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load your cleaned final dataset\n",
    "data_path = '../data/goodbooks-10k'\n",
    "final_df = pd.read_csv(f\"{data_path}/final_svd_dataset.csv\")\n",
    "\n",
    "# Count number of ratings per user\n",
    "reviews_per_user = final_df.groupby('user_id')['rating'].count()\n",
    "\n",
    "# Average rating per user\n",
    "average_rating_per_user = final_df.groupby('user_id')['rating'].mean()\n",
    "\n",
    "# Print basic stats\n",
    "print(reviews_per_user.describe())\n",
    "\n",
    "# Print users with fewest ratings\n",
    "print(\"\\nUsers with fewest ratings:\")\n",
    "print(reviews_per_user.sort_values().head(10))\n",
    "\n",
    "# Count unique users and books\n",
    "unique_users = final_df['user_id'].nunique()\n",
    "unique_books = final_df['book_id'].nunique()\n",
    "\n",
    "print(f\"\\nTotal number of unique users: {unique_users}\")\n",
    "print(f\"Total number of unique books: {unique_books}\")\n",
    "\n",
    "# Get min/max ratings per user\n",
    "min_ratings = reviews_per_user.min()\n",
    "max_ratings = reviews_per_user.max()\n",
    "avg_ratings_per_user = reviews_per_user.mean()\n",
    "\n",
    "print(f\"Minimum number of ratings per user: {min_ratings}\")\n",
    "print(f\"Maximum number of ratings per user: {max_ratings}\")\n",
    "print(f\"Average number of ratings per user: {avg_ratings_per_user:.2f}\")\n",
    "\n",
    "# Print basic stats for average *rating scores* per user\n",
    "print(\"\\nAverage rating score per user:\")\n",
    "print(average_rating_per_user.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "decade_grouped",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unique_books_per_decade",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "183dc727-dc34-49f5-b57a-da3e18b3d636",
       "rows": [
        [
         "0",
         "1920",
         "89"
        ],
        [
         "1",
         "1930",
         "121"
        ],
        [
         "2",
         "1940",
         "155"
        ],
        [
         "3",
         "1950",
         "210"
        ],
        [
         "4",
         "1960",
         "272"
        ],
        [
         "5",
         "1970",
         "400"
        ],
        [
         "6",
         "1980",
         "704"
        ],
        [
         "7",
         "1990",
         "1360"
        ],
        [
         "8",
         "2000",
         "3121"
        ],
        [
         "9",
         "2010",
         "3067"
        ],
        [
         "10",
         "Ancient Books",
         "480"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decade_grouped</th>\n",
       "      <th>unique_books_per_decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1920</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1930</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1940</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1970</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1980</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1990</td>\n",
       "      <td>1360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000</td>\n",
       "      <td>3121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010</td>\n",
       "      <td>3067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ancient Books</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   decade_grouped  unique_books_per_decade\n",
       "0            1920                       89\n",
       "1            1930                      121\n",
       "2            1940                      155\n",
       "3            1950                      210\n",
       "4            1960                      272\n",
       "5            1970                      400\n",
       "6            1980                      704\n",
       "7            1990                     1360\n",
       "8            2000                     3121\n",
       "9            2010                     3067\n",
       "10  Ancient Books                      480"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_per_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "book_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "decade",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "70394ea7-44cd-4fa6-8afc-3122652bd2de",
       "rows": [
        [
         "0",
         "1",
         "258",
         "5",
         "2000"
        ],
        [
         "1",
         "2",
         "4081",
         "4",
         "2000"
        ],
        [
         "2",
         "2",
         "260",
         "5",
         "1930"
        ],
        [
         "3",
         "2",
         "9296",
         "5",
         "1970"
        ],
        [
         "4",
         "2",
         "2318",
         "3",
         "1990"
        ],
        [
         "5",
         "2",
         "26",
         "4",
         "2000"
        ],
        [
         "6",
         "2",
         "315",
         "3",
         "1990"
        ],
        [
         "7",
         "2",
         "33",
         "4",
         "1990"
        ],
        [
         "8",
         "2",
         "301",
         "5",
         "Ancient Books"
        ],
        [
         "9",
         "2",
         "2686",
         "5",
         "2000"
        ],
        [
         "10",
         "2",
         "3753",
         "5",
         "2000"
        ],
        [
         "11",
         "2",
         "8519",
         "5",
         "1970"
        ],
        [
         "12",
         "4",
         "70",
         "4",
         "1980"
        ],
        [
         "13",
         "4",
         "264",
         "3",
         "1920"
        ],
        [
         "14",
         "4",
         "388",
         "4",
         "1980"
        ],
        [
         "15",
         "4",
         "18",
         "5",
         "1990"
        ],
        [
         "16",
         "4",
         "27",
         "5",
         "2000"
        ],
        [
         "17",
         "4",
         "21",
         "5",
         "2000"
        ],
        [
         "18",
         "4",
         "2",
         "5",
         "1990"
        ],
        [
         "19",
         "4",
         "23",
         "5",
         "1990"
        ],
        [
         "20",
         "4",
         "24",
         "5",
         "2000"
        ],
        [
         "21",
         "4",
         "964",
         "4",
         "1970"
        ],
        [
         "22",
         "4",
         "103",
         "5",
         "Ancient Books"
        ],
        [
         "23",
         "4",
         "255",
         "2",
         "1950"
        ],
        [
         "24",
         "4",
         "35",
         "5",
         "1980"
        ],
        [
         "25",
         "4",
         "287",
         "3",
         "1940"
        ],
        [
         "26",
         "4",
         "337",
         "4",
         "1990"
        ],
        [
         "27",
         "4",
         "26",
         "3",
         "2000"
        ],
        [
         "28",
         "4",
         "84",
         "4",
         "1990"
        ],
        [
         "29",
         "4",
         "58",
         "4",
         "Ancient Books"
        ],
        [
         "30",
         "4",
         "1117",
         "3",
         "1990"
        ],
        [
         "31",
         "4",
         "660",
         "3",
         "1980"
        ],
        [
         "32",
         "4",
         "111",
         "2",
         "2000"
        ],
        [
         "33",
         "4",
         "5",
         "4",
         "1920"
        ],
        [
         "34",
         "4",
         "413",
         "4",
         "Ancient Books"
        ],
        [
         "35",
         "4",
         "8",
         "4",
         "1950"
        ],
        [
         "36",
         "4",
         "2172",
         "4",
         "1960"
        ],
        [
         "37",
         "4",
         "65",
         "4",
         "1960"
        ],
        [
         "38",
         "4",
         "297",
         "4",
         "1960"
        ],
        [
         "39",
         "4",
         "45",
         "4",
         "2000"
        ],
        [
         "40",
         "4",
         "113",
         "4",
         "1960"
        ],
        [
         "41",
         "4",
         "325",
         "5",
         "1980"
        ],
        [
         "42",
         "4",
         "476",
         "3",
         "1970"
        ],
        [
         "43",
         "6",
         "6351",
         "4",
         "2000"
        ],
        [
         "44",
         "8",
         "2732",
         "5",
         "Ancient Books"
        ],
        [
         "45",
         "8",
         "1432",
         "3",
         "Ancient Books"
        ],
        [
         "46",
         "8",
         "479",
         "4",
         "Ancient Books"
        ],
        [
         "47",
         "8",
         "3020",
         "5",
         "Ancient Books"
        ],
        [
         "48",
         "8",
         "6195",
         "4",
         "1920"
        ],
        [
         "49",
         "8",
         "614",
         "4",
         "1920"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5970537
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970532</th>\n",
       "      <td>49925</td>\n",
       "      <td>510</td>\n",
       "      <td>5</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970533</th>\n",
       "      <td>49925</td>\n",
       "      <td>528</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970534</th>\n",
       "      <td>49925</td>\n",
       "      <td>722</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970535</th>\n",
       "      <td>49925</td>\n",
       "      <td>949</td>\n",
       "      <td>5</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970536</th>\n",
       "      <td>49925</td>\n",
       "      <td>1023</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5970537 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  book_id  rating decade\n",
       "0              1      258       5   2000\n",
       "1              2     4081       4   2000\n",
       "2              2      260       5   1930\n",
       "3              2     9296       5   1970\n",
       "4              2     2318       3   1990\n",
       "...          ...      ...     ...    ...\n",
       "5970532    49925      510       5   1990\n",
       "5970533    49925      528       4   1990\n",
       "5970534    49925      722       4   1990\n",
       "5970535    49925      949       5   1990\n",
       "5970536    49925     1023       4   1990\n",
       "\n",
       "[5970537 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
